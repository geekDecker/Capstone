{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Capstone_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMebBEeBSjBkJQZFlOsSqjk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6b3cada9df814b24b3bf21e284996a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5b3926014cd4a05b3527e9450516c36",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6e19563114c44c0a9ba495670c1fd689",
              "IPY_MODEL_b3fb45f4b76e406f89bab5f073684b26",
              "IPY_MODEL_b9bed4c4835d4caea59982b9f0ef764d"
            ]
          }
        },
        "e5b3926014cd4a05b3527e9450516c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e19563114c44c0a9ba495670c1fd689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4044246e8d3e4fb3993978d93a97977e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56345e301399474dbc25db5e10c1615a"
          }
        },
        "b3fb45f4b76e406f89bab5f073684b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_09d0edda77cc48cd9d02f3cccb6bfaa6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 384,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 384,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9cd27911c9304727929866b1b8193260"
          }
        },
        "b9bed4c4835d4caea59982b9f0ef764d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_03350e9f886949e2aa8bb84abe478150",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 384/384 [00:00&lt;00:00, 13.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d1ae3e3cca74f548e302af6ae7590d7"
          }
        },
        "4044246e8d3e4fb3993978d93a97977e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56345e301399474dbc25db5e10c1615a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09d0edda77cc48cd9d02f3cccb6bfaa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9cd27911c9304727929866b1b8193260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03350e9f886949e2aa8bb84abe478150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d1ae3e3cca74f548e302af6ae7590d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f0d0e5e413d454db183fdaf4cd91760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_680778c2424f4db08073ee0aedde31e9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eef3b14894cc46ebac7cb0296af9f80a",
              "IPY_MODEL_fcead20115454cb888d2527002b80c3b",
              "IPY_MODEL_8001868602344938af217c5a6e42c1c9"
            ]
          }
        },
        "680778c2424f4db08073ee0aedde31e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eef3b14894cc46ebac7cb0296af9f80a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6787c9ad08a146ca86575b8c8bae4964",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d48b89bb489c4c8ba905b7856df2b646"
          }
        },
        "fcead20115454cb888d2527002b80c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4307640ab0634682bd0d669512c687e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_31886f6dcff14bcfa018db4923fb738f"
          }
        },
        "8001868602344938af217c5a6e42c1c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e73716b1d54412d9bb42d624a9adae9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 633kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8088d0b014254023a9e5da2b89318285"
          }
        },
        "6787c9ad08a146ca86575b8c8bae4964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d48b89bb489c4c8ba905b7856df2b646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4307640ab0634682bd0d669512c687e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "31886f6dcff14bcfa018db4923fb738f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e73716b1d54412d9bb42d624a9adae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8088d0b014254023a9e5da2b89318285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "073868227c4d4a9a8f94ccaff648d0c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fed803b53ebf4575a7e08faa06d64e64",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_10c61a05cd244863b60f4fae65d78345",
              "IPY_MODEL_4693296d6a8f4b51a888cc8159091b6d",
              "IPY_MODEL_9e14ce64f0e54d7db3cecb96c278384f"
            ]
          }
        },
        "fed803b53ebf4575a7e08faa06d64e64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10c61a05cd244863b60f4fae65d78345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_565780b0323c4057bd98abf79ea49a35",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33f03fec816b4da5ba6b6b207e27cb62"
          }
        },
        "4693296d6a8f4b51a888cc8159091b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ac484dbe0e1040b486a50a7170edad44",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 327051810,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 327051810,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9275f1f28bab4cecb1756cc6e2c9b4d0"
          }
        },
        "9e14ce64f0e54d7db3cecb96c278384f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b67d12cbc08f4d3e8c2a183563d54c7d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 327M/327M [00:09&lt;00:00, 39.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1f6d0a151f8492e98218adf8f7c8fb5"
          }
        },
        "565780b0323c4057bd98abf79ea49a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33f03fec816b4da5ba6b6b207e27cb62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac484dbe0e1040b486a50a7170edad44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9275f1f28bab4cecb1756cc6e2c9b4d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b67d12cbc08f4d3e8c2a183563d54c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1f6d0a151f8492e98218adf8f7c8fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3acd4131f7b4eeba32f498dc4ac27f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_170b9b8c0b2c4fd2b2ac932647b0d2a3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9fa2138bfec94ddca88e3d2ee0dba4d9",
              "IPY_MODEL_3781a7b71d0b4bc189f96ce92c160a2d",
              "IPY_MODEL_359833458b554301b18213493e1223e6"
            ]
          }
        },
        "170b9b8c0b2c4fd2b2ac932647b0d2a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9fa2138bfec94ddca88e3d2ee0dba4d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_89895f0849e24fc98beabc5bf9128074",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6c2eb46d9524e128b6bd452a7884ce0"
          }
        },
        "3781a7b71d0b4bc189f96ce92c160a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_60208aa245a14626b6f5a220e3daba6b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 26,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 26,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af69b0575ff14e9ca96e7d08ddd6a64a"
          }
        },
        "359833458b554301b18213493e1223e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_30bc808ec34f402b8b1db54ff7ac7f43",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26.0/26.0 [00:00&lt;00:00, 991B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13b3ee84a2bd46bba6a912492a62542d"
          }
        },
        "89895f0849e24fc98beabc5bf9128074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6c2eb46d9524e128b6bd452a7884ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60208aa245a14626b6f5a220e3daba6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af69b0575ff14e9ca96e7d08ddd6a64a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30bc808ec34f402b8b1db54ff7ac7f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13b3ee84a2bd46bba6a912492a62542d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0497a2a67e394c30b5a47d941d515153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3e6e4280eedf4077a90de2fbed18cba9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_454d4cbcc0c14379a25580aada52945b",
              "IPY_MODEL_3ef0aa991b724add8a4db6bb0fde5532",
              "IPY_MODEL_453c8152631d4e0db2d332404f7b2f38"
            ]
          }
        },
        "3e6e4280eedf4077a90de2fbed18cba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "454d4cbcc0c14379a25580aada52945b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_56d55c6f0a984b1cb8dedac4a993051a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b82145de5372494f9ab63725d4025193"
          }
        },
        "3ef0aa991b724add8a4db6bb0fde5532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_376f8afc141347b1843fd58fa6f9e26d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1600,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1600,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_991c1acb21b241aca16fc1744b002e64"
          }
        },
        "453c8152631d4e0db2d332404f7b2f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3064160a45064fc9a7660140def19fdf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.60k/1.60k [00:00&lt;00:00, 52.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f1b1dbf825a464ca8c44ca514bd17f9"
          }
        },
        "56d55c6f0a984b1cb8dedac4a993051a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b82145de5372494f9ab63725d4025193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "376f8afc141347b1843fd58fa6f9e26d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "991c1acb21b241aca16fc1744b002e64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3064160a45064fc9a7660140def19fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f1b1dbf825a464ca8c44ca514bd17f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7eba9b43a2649cbaeab6574794f744e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3a3c698b9fea41a7849a2d9fabff5041",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_98abc9d6866747c5b0382e8175d694e9",
              "IPY_MODEL_15d45d8f399443d59fdd82cd203eb1d5",
              "IPY_MODEL_61a9f2d0c5fd4a00a084217c313d239a"
            ]
          }
        },
        "3a3c698b9fea41a7849a2d9fabff5041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98abc9d6866747c5b0382e8175d694e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_603b3c2d91b34d0b8be86fc7e432cd8a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f526c5a5e80d4e7d96cf6de3990f3de9"
          }
        },
        "15d45d8f399443d59fdd82cd203eb1d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7f15dd7804764802b7503846d5e6602f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898822,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898822,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4d96a2cb6c04504947b6cf4c3df8952"
          }
        },
        "61a9f2d0c5fd4a00a084217c313d239a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_206de7c5805744a99a8147af59059f3d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 1.27MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_352b24a34a3c42bcb271e91ca6b76a62"
          }
        },
        "603b3c2d91b34d0b8be86fc7e432cd8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f526c5a5e80d4e7d96cf6de3990f3de9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7f15dd7804764802b7503846d5e6602f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4d96a2cb6c04504947b6cf4c3df8952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "206de7c5805744a99a8147af59059f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "352b24a34a3c42bcb271e91ca6b76a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a91029969afe47bc88055da77464fede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e78e509d6b64e579544bb5c1ec50532",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_90af0857e2f041638896687689a5f6d2",
              "IPY_MODEL_254853d2fba441baba60661ce3b82a91",
              "IPY_MODEL_b5d64a4355b940dcbb9e0fa653425947"
            ]
          }
        },
        "8e78e509d6b64e579544bb5c1ec50532": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90af0857e2f041638896687689a5f6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d488baee32944bd7af2621c0ada6ec75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7687b88b8f854968949ece6fce039f10"
          }
        },
        "254853d2fba441baba60661ce3b82a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0706e77f6fb94dc891588ddf783e5011",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9418ac043e54c8aad7ae21b94a91ad1"
          }
        },
        "b5d64a4355b940dcbb9e0fa653425947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6dba31d2149243f0b60727a75be5baa6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.40MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_172fa4da648b47219cc54a45ff29b7d5"
          }
        },
        "d488baee32944bd7af2621c0ada6ec75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7687b88b8f854968949ece6fce039f10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0706e77f6fb94dc891588ddf783e5011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9418ac043e54c8aad7ae21b94a91ad1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6dba31d2149243f0b60727a75be5baa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "172fa4da648b47219cc54a45ff29b7d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b3646b526814cc3824360dfe340de66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_933ab246230e40c2a5621c4991c5e6b2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff051c719214490487c81b17716cc4e8",
              "IPY_MODEL_2d0557a4bf0540d08e4bf143cb409e13",
              "IPY_MODEL_f2e017b7f35b4fb6aae6dd93133e1635"
            ]
          }
        },
        "933ab246230e40c2a5621c4991c5e6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff051c719214490487c81b17716cc4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_28b661505d624f73aa76122e3a1d5d01",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6b527ca34b04cb58f24970023ded77e"
          }
        },
        "2d0557a4bf0540d08e4bf143cb409e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d4f6ba53a27d4ce4875ae2cf866571bf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355863,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355863,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc41dfa478f14490ae9b2bf10c6f77b3"
          }
        },
        "f2e017b7f35b4fb6aae6dd93133e1635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d6815d57a2c141479af40e9b7fd4c362",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 2.90MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee58453af0424d1a8ec8d2b29d71e819"
          }
        },
        "28b661505d624f73aa76122e3a1d5d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6b527ca34b04cb58f24970023ded77e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4f6ba53a27d4ce4875ae2cf866571bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc41dfa478f14490ae9b2bf10c6f77b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6815d57a2c141479af40e9b7fd4c362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee58453af0424d1a8ec8d2b29d71e819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2c7ff66f8a44b5faeff6b82133d0705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a71da9027dd64ce2a6ceeb1a6dc5cc42",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_75268db943184524b620291aedd7d6aa",
              "IPY_MODEL_aaaca7fba9e449f9b79dca36407a1664",
              "IPY_MODEL_d9303146f6d34d04b183e88b33169e34"
            ]
          }
        },
        "a71da9027dd64ce2a6ceeb1a6dc5cc42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75268db943184524b620291aedd7d6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1f22dabbc6004990967da7448777296b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3278877db6f6428bab9809e269404d0b"
          }
        },
        "aaaca7fba9e449f9b79dca36407a1664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fe92083b89374349b888013ada18d88e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1018571383,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1018571383,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef2fcb6f8ab040568cb5933aee37cca3"
          }
        },
        "d9303146f6d34d04b183e88b33169e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ca43ed81e60047c4a08173567d9463a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.02G/1.02G [00:17&lt;00:00, 62.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad37d635e7d94ae2966ab2eeb86a9f55"
          }
        },
        "1f22dabbc6004990967da7448777296b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3278877db6f6428bab9809e269404d0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe92083b89374349b888013ada18d88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef2fcb6f8ab040568cb5933aee37cca3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca43ed81e60047c4a08173567d9463a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad37d635e7d94ae2966ab2eeb86a9f55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishnarevi/END2.0/blob/main/w2_Copy_of_Capstone_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ6oIhPQExDl"
      },
      "source": [
        "In this notebook, we show how we can take advantage of these recent advances to train a long form question answering system which takes in a question, fetches relevant passages from a document corpus, and writes a multi-sentence answer based on the question and retrieved passages.In particular, training embedding-based retrieval models to gather supporting evidence for open-domain questions is relatively new research area: the last few months have seen some significant progress in cases where direct supervision is available, or with extensive task-specific pretraining. Here, we show how our custom dataset allows us to train a dense retrieval system without access to either, making dense retrieval models more accessible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTqWP9ITEwE4"
      },
      "source": [
        "## 1.a - Preliminaries\n",
        "The implementation presented here relies on the Hugging Face 🤗transformers and 🤗nlp libraries. Wikipedia indexing relies on faiss for the dense version. You can get all of these by running:\n",
        "\n",
        "<!-- pip install elasticsearch -->\n",
        "pip install faiss_gpu\n",
        "pip install nlp\n",
        "pip install transformers\n",
        "<!-- \n",
        "wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.7.1-linux-x86_64.tar.gz\n",
        "tar -xzvf elasticsearch-7.7.1-linux-x86_64.tar.gz -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAsRpBK4DhS_",
        "outputId": "98636c3d-f862-4727-c4a9-9ff317239ec1"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 12 07:09:15 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u14eRYn09Kp",
        "outputId": "7b03339d-81a2-418c-eb54-92684ecb7aa7"
      },
      "source": [
        "!pip install faiss_gpu nlp transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss_gpu\n",
            "  Downloading faiss_gpu-1.7.1.post2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 89.7 MB 9.1 kB/s \n",
            "\u001b[?25hCollecting nlp\n",
            "  Downloading nlp-0.4.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 47.5 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.10.2-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 54.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from nlp) (0.3.4)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from nlp) (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from nlp) (3.0.12)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 90.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from nlp) (4.62.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nlp) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nlp) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from nlp) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp) (2021.5.30)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 61.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 68.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 66.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nlp) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->nlp) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->nlp) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: xxhash, tokenizers, sacremoses, pyyaml, huggingface-hub, transformers, nlp, faiss-gpu\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed faiss-gpu-1.7.1.post2 huggingface-hub-0.0.16 nlp-0.4.0 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.2 xxhash-2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VgSm5-serJa"
      },
      "source": [
        "import functools\n",
        "import math\n",
        "import os  # noqa: F401\n",
        "from random import choice, randint\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.checkpoint as checkpoint\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
        "from tqdm import tqdm\n",
        "\n",
        "import faiss  # noqa: F401\n",
        "import nlp  # noqa: F401\n",
        "import pandas as pd\n",
        "from transformers import AdamW, AutoModel, AutoModelForSeq2SeqLM, AutoTokenizer, get_linear_schedule_with_warmup\n",
        "import json"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ddm2PdNBlkvZ",
        "outputId": "19390c09-b89c-41da-99d2-a3ab00ea2c20"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xS7XbaolnKg"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/TSAI/Capstone_1')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EgAlp0clpW5"
      },
      "source": [
        "# from lfqa_utils import *"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzpLMu5SeE5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f26f025-188b-4cc2-fff5-2ae21b7267de"
      },
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "path = '/content/drive/MyDrive/TSAI/Capstone_1'\n",
        "os.chdir(path)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB1FubpEnOWG",
        "outputId": "d8218746-c079-46d2-a025-c838002945ef"
      },
      "source": [
        "folder = \"retriever_models\"\n",
        "# os.chdir(path)\n",
        "print(\"current dir is: %s\" % (os.getcwd()))\n",
        "\n",
        "if os.path.isdir(folder):\n",
        "    print(\"retriever_models directory exists\")\n",
        "else:\n",
        "    print(\"retriever_models directory Doesn't exists, creating one\")\n",
        "    os.mkdir(folder)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current dir is: /content/drive/MyDrive/TSAI/Capstone_1\n",
            "retriever_models directory exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faCLqxJImdZU",
        "outputId": "d993125f-9208-43cc-dda4-ee0f680b13e8"
      },
      "source": [
        "folder = \"seq2seq_models\"\n",
        "# os.chdir(path)\n",
        "print(\"current dir is: %s\" % (os.getcwd()))\n",
        "\n",
        "if os.path.isdir(folder):\n",
        "    print(\"seq2seq_models directory exists\")\n",
        "else:\n",
        "    print(\"seq2seq_models directory Doesn't exists, creating one\")\n",
        "    os.mkdir(folder)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current dir is: /content/drive/MyDrive/TSAI/Capstone_1\n",
            "seq2seq_models directory exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8v6YJLUleqY"
      },
      "source": [
        "with open(path+'/train_data.json') as f:\n",
        "        train = json.load(f)\n",
        "with open(path+'/test_data.json') as f:\n",
        "        test = json.load(f)\n",
        "with open(path+'/context_master.json') as f:\n",
        "        passage_snippets = json.load(f)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrV7bVHQeyfg",
        "outputId": "6e546ef5-3a48-4a97-84c5-ea98600d9943"
      },
      "source": [
        "train[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 1,\n",
              " 'x': 'Maxout Layer',\n",
              " 'y': 'The Maxout layer can be implemented as follows \\npython\\nclass Maxout(nn.Module):\\n def __init__(self, d_in, d_out, pool_size):\\n super().__init__()\\n self.d_in, self.d_out, self.pool_size = d_in, d_out, pool_size\\n self.lin = nn.Linear(d_in, d_out * pool_size)\\n def forward(self, inputs):\\n shape = list(inputs.size())\\n shape[-1] = self.d_out\\n shape.append(self.pool_size)\\n max_dim = len(shape) - 1\\n out = self.lin(inputs)\\n m, i = out.view(*shape).max(max_dim)\\n return m\\n',\n",
              " 'z': 'For ones who need Maxout, I changed the above code to make it work. \\npython\\nclass Maxout(nn.Module):\\n def __init__(self, d_in, d_out, pool_size):\\n super().__init__()\\n self.d_in, self.d_out, self.pool_size = d_in, d_out, pool_size\\n self.lin = nn.Linear(d_in, d_out * pool_size)\\n def forward(self, inputs):\\n shape = list(inputs.size())\\n shape[-1] = self.d_out\\n shape.append(self.pool_size)\\n max_dim = len(shape) - 1\\n out = self.lin(inputs)\\n m, i = out.view(*shape).max(max_dim)\\n return m\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsKLzwpWfQNQ",
        "outputId": "2be73280-592c-4b54-dffb-28551790a099"
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9140"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVg6eAz9e6aP",
        "outputId": "0b37e780-7be3-465c-a60b-606c66ef9709"
      },
      "source": [
        "test[100]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 101,\n",
              " 'x': 'What do Variable(tensor, requires_grad) return instead of Variables?',\n",
              " 'y': 'Tensors',\n",
              " 'z': 'The Variable API has been deprecated: Variables are no longer necessary to use autograd with tensors. Autograd automatically supports Tensors with requires_grad set to True. Below please find a quick guide on what has changed: Variable(tensor) and Variable(tensor, requires_grad) still work as expected, but they return Tensors instead of Variables. var.data is the same thing as tensor.data. Methods such as var.backward(), var.detach(), var.register_hook() now work on tensors with the same method names.'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZUuSCe1fSy_",
        "outputId": "922169fb-d88d-4325-c74b-206146efd9fb"
      },
      "source": [
        "len(test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2286"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dspIob65hT14"
      },
      "source": [
        "### Retrieving Support Documents with an ELI5-Trained Dense Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io61B76Fh7ro"
      },
      "source": [
        "The sparse retriever works by finding passages which feature the words from the query. However, it has no way to know a priori which of these words are more important in context, and seems to struggle with understanding the central theme of the query (human-perceived temperature).\n",
        "\n",
        "Thankfully, some recent works have taken advantage of advances in pre-trained contextual word representations to solve this problem. Models such as DPR or REALM for example learn to compute a vector representation of the query, as well as vector representations of Wikipedia passages in such a way that the passages that best answers a question maximize the dot product between the two representations. Retrieval is then reduced to a Maximum Inner Product Search, which can be executed efficiently using systems like FAISS.\n",
        "\n",
        "These successes are very encouraging for our Open-Domain Long Form QA application. However, our task and setup do not quite meet the requirements of either of either of these approaches. On the one hand, the DPR system is trained using gold passage annotations: most major QA dataset tell the system which Wikipedia passage contains the answer. Unfortunately, we do not have such annotations for the ELI5 data. On the other hand, while REALM is trained without passage supervision, it requires a pretty expensive pre-training step with an Inverse Cloze Task (100,000 steps with batch size 4096), and the ability to re-compute the embeddings of all Wikipedia passages regularly during training.\n",
        "\n",
        "In order to train a similar dense retrieval system at reduced cost without having access to gold passage annotation, we will have to take advantage of another unique feature of our dataset, namely the fact that the long form answers are quite similar in style to the Wikipedia passages we want to index. Our hypothesis then is that if we train a system to embed the questions and answers in our dataset in a way that allows us to easily match questions to answers, then using the answer embedder on Wikipedia passages should allow us to similarly match questions to supporting evidence from Wikipedia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PbDg4xciQn3"
      },
      "source": [
        "4.a - Contrastive Training with ELI5 In-Batch Negatives\n",
        "As mentioned above, we want to train a system to produce question and answer embeddings, such that the dot product between the representation of a question and any of its answers is greater than between it and answers of all of the other questions in the dataset.\n",
        "\n",
        "Unfortunately, actually comparing all questions to all answers before taking every single gradient step is computationally prohibitive: instead, we follow previous work in simply processing medium to large batches of question-answer pairs, and making sure that the dot product of a question with its answer is larger than with all other answers in the batch, and vice versa.\n",
        "\n",
        "We use a cross-entropy loss for the multinomial distribution over all of the answers (or questions) in a batch, and make use of PyTorch gradient checkpointing to be able to use large batches with limited GPU memory: you can find all implementation details in the RetrievalQAEmbedder class in eli5_utils.py.\n",
        "\n",
        "We use a single BERT-style pre-trained model to embed the questions and answers, and learn different projection matrices to bring both representations down to dimension 128: the projection matrices are trained from scratch as the sentence embedding model is fine-tuned. We found that the 8-layer distilled version of BERT from the Well-Read Students Learn Better paper performed as well or better as full BERT for a notable gain in computation speed: if you want an even faster model, that work provides pre-trained models spanning the full range of computation/accuracy trade-offs.\n",
        "\n",
        "The model can than be trained with the following code: with batch size 32/512 on a single 16GB GPU, you can run 10 training epochs in under 6 hours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJa0ofK7f65J"
      },
      "source": [
        "###############\n",
        "# retriever training\n",
        "###############\n",
        "class ELI5DatasetQARetriver(Dataset):\n",
        "    def __init__(self, examples_array, num_rows, extra_answer_threshold=2, min_answer_length=1, training=True, n_samples=None):\n",
        "        self.data = examples_array\n",
        "        self.answer_thres = extra_answer_threshold\n",
        "        self.min_length = min_answer_length\n",
        "        self.training = training\n",
        "        self.n_samples = num_rows if n_samples is None else n_samples\n",
        "        self.num_rows = num_rows\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "    def make_example(self, idx):\n",
        "        example = self.data[idx]\n",
        "        question = example[\"x\"]\n",
        "        answer = example[\"y\"]\n",
        "        return (question, answer)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.make_example(idx % self.num_rows)\n",
        "\n",
        "\n",
        "class RetrievalQAEmbedder(torch.nn.Module):\n",
        "    def __init__(self, sent_encoder, dim):\n",
        "        super(RetrievalQAEmbedder, self).__init__()\n",
        "        self.sent_encoder = sent_encoder\n",
        "        self.output_dim = 128\n",
        "        self.project_q = torch.nn.Linear(dim, self.output_dim, bias=False)\n",
        "        self.project_a = torch.nn.Linear(dim, self.output_dim, bias=False)\n",
        "        self.ce_loss = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "\n",
        "    def embed_sentences_checkpointed(self, input_ids, attention_mask, checkpoint_batch_size=-1):\n",
        "        # reproduces BERT forward pass with checkpointing\n",
        "        if checkpoint_batch_size < 0 or input_ids.shape[0] < checkpoint_batch_size:\n",
        "            return self.sent_encoder(input_ids, attention_mask=attention_mask)[1]\n",
        "        else:\n",
        "            # prepare implicit variables\n",
        "            device = input_ids.device\n",
        "            input_shape = input_ids.size()\n",
        "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "            head_mask = [None] * self.sent_encoder.config.num_hidden_layers\n",
        "            extended_attention_mask: torch.Tensor = self.sent_encoder.get_extended_attention_mask(\n",
        "                attention_mask, input_shape, device\n",
        "            )\n",
        "\n",
        "            # define function for checkpointing\n",
        "            def partial_encode(*inputs):\n",
        "                encoder_outputs = self.sent_encoder.encoder(inputs[0], attention_mask=inputs[1], head_mask=head_mask,)\n",
        "                sequence_output = encoder_outputs[0]\n",
        "                pooled_output = self.sent_encoder.pooler(sequence_output)\n",
        "                return pooled_output\n",
        "\n",
        "            # run embedding layer on everything at once\n",
        "            embedding_output = self.sent_encoder.embeddings(\n",
        "                input_ids=input_ids, position_ids=None, token_type_ids=token_type_ids, inputs_embeds=None\n",
        "            )\n",
        "            # run encoding and pooling on one mini-batch at a time\n",
        "            pooled_output_list = []\n",
        "            for b in range(math.ceil(input_ids.shape[0] / checkpoint_batch_size)):\n",
        "                b_embedding_output = embedding_output[b * checkpoint_batch_size : (b + 1) * checkpoint_batch_size]\n",
        "                b_attention_mask = extended_attention_mask[b * checkpoint_batch_size : (b + 1) * checkpoint_batch_size]\n",
        "                pooled_output = checkpoint.checkpoint(partial_encode, b_embedding_output, b_attention_mask)\n",
        "                pooled_output_list.append(pooled_output)\n",
        "            return torch.cat(pooled_output_list, dim=0)\n",
        "\n",
        "    def embed_questions(self, q_ids, q_mask, checkpoint_batch_size=-1):\n",
        "        q_reps = self.embed_sentences_checkpointed(q_ids, q_mask, checkpoint_batch_size)\n",
        "        return self.project_q(q_reps)\n",
        "\n",
        "    def embed_answers(self, a_ids, a_mask, checkpoint_batch_size=-1):\n",
        "        a_reps = self.embed_sentences_checkpointed(a_ids, a_mask, checkpoint_batch_size)\n",
        "        return self.project_a(a_reps)\n",
        "\n",
        "    def forward(self, q_ids, q_mask, a_ids, a_mask, checkpoint_batch_size=-1):\n",
        "        device = q_ids.device\n",
        "        q_reps = self.embed_questions(q_ids, q_mask, checkpoint_batch_size)\n",
        "        a_reps = self.embed_answers(a_ids, a_mask, checkpoint_batch_size)\n",
        "        compare_scores = torch.mm(q_reps, a_reps.t())#cosine similarity\n",
        "        loss_qa = self.ce_loss(compare_scores, torch.arange(compare_scores.shape[1]).to(device))#cross entrophy loss\n",
        "        loss_aq = self.ce_loss(compare_scores.t(), torch.arange(compare_scores.shape[0]).to(device))\n",
        "        loss = (loss_qa + loss_aq) / 2\n",
        "        return loss\n",
        "\n",
        "\n",
        "def make_qa_retriever_model(model_name=\"google/bert_uncased_L-8_H-512_A-8\", from_file=None, device=\"cuda\"):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    bert_model = AutoModel.from_pretrained(model_name).to(device)\n",
        "    # run bert_model on a dummy batch to get output dimension\n",
        "    d_ids = torch.LongTensor(\n",
        "        [[bert_model.config.bos_token_id if bert_model.config.bos_token_id is not None else 1]]\n",
        "    ).to(device)\n",
        "    d_mask = torch.LongTensor([[1]]).to(device)\n",
        "    sent_dim = bert_model(d_ids, attention_mask=d_mask)[1].shape[-1]\n",
        "    qa_embedder = RetrievalQAEmbedder(bert_model, sent_dim).to(device)\n",
        "    if from_file is not None:\n",
        "        param_dict = torch.load(from_file)  # has model weights, optimizer, and scheduler states\n",
        "        qa_embedder.load_state_dict(param_dict[\"model\"])\n",
        "    return tokenizer, qa_embedder\n",
        "\n",
        "\n",
        "def make_qa_retriever_batch(qa_list, tokenizer, max_len=128, device=\"cuda\"):\n",
        "    q_ls = [q for q, a in qa_list]\n",
        "    a_ls = [a for q, a in qa_list]\n",
        " \n",
        "    q_toks = tokenizer.batch_encode_plus(q_ls, max_length=max_len, pad_to_max_length=True)\n",
        "    \n",
        "    q_ids, q_mask = (torch.LongTensor(q_toks[\"input_ids\"]).to(device),torch.LongTensor(q_toks[\"attention_mask\"]).to(device),)\n",
        "    # print(len(a_ls))\n",
        "\n",
        "    a_toks = tokenizer.batch_encode_plus(a_ls, max_length=max_len, pad_to_max_length=True)\n",
        "    # TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]\n",
        "    # print(a_toks)\n",
        "    a_ids, a_mask = (\n",
        "        torch.LongTensor(a_toks[\"input_ids\"]).to(device),\n",
        "        torch.LongTensor(a_toks[\"attention_mask\"]).to(device),\n",
        "    )\n",
        "\n",
        "    return (q_ids, q_mask, a_ids, a_mask)\n",
        "\n",
        "\n",
        "def train_qa_retriever_epoch(model, dataset, tokenizer, optimizer, scheduler, args, e=0):\n",
        "    model.train()\n",
        "    # make iterator\n",
        "    train_sampler = RandomSampler(dataset)\n",
        "    model_collate_fn = functools.partial(\n",
        "        make_qa_retriever_batch, tokenizer=tokenizer, max_len=args.max_length, device=\"cuda\"\n",
        "    )\n",
        "    \n",
        "    data_loader = DataLoader(dataset, batch_size=args.batch_size, sampler=train_sampler, collate_fn=model_collate_fn)\n",
        "    epoch_iterator = tqdm(data_loader, desc=\"Iteration\", disable=True)\n",
        "    # print(next(iter(data_loader)).shape)\n",
        "    # accumulate loss since last print\n",
        "    loc_steps = 0\n",
        "    loc_loss = 0.0\n",
        "    st_time = time()\n",
        "    for step, batch in enumerate(epoch_iterator):\n",
        "        # print(\"q_ids\",q_ids.shape)\n",
        "        # print(\" q_mask,\", q_mask.shape)\n",
        "        # print(\"A_id\", a_ids.shape)\n",
        "        q_ids, q_mask, a_ids, a_mask = batch\n",
        "        pre_loss = model(q_ids, q_mask, a_ids, a_mask, checkpoint_batch_size=args.checkpoint_batch_size)\n",
        "        loss = pre_loss.sum()\n",
        "        # optimizer\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        model.zero_grad()\n",
        "        # some printing within the epoch\n",
        "        loc_loss += loss.item()\n",
        "        loc_steps += 1\n",
        "        if step % args.print_freq == 0 or step == 1:\n",
        "            print(\n",
        "                \"{:2d} {:5d} of {:5d} \\t L: {:.3f} \\t -- {:.3f}\".format(\n",
        "                    e, step, len(dataset) // args.batch_size, loc_loss / loc_steps, time() - st_time,\n",
        "                )\n",
        "            )\n",
        "            loc_loss = 0\n",
        "            loc_steps = 0\n",
        "\n",
        "\n",
        "# def train_qa_retriever_joint_epoch(model, dataset_list, tokenizer, optimizer, scheduler, args, e=0):\n",
        "#     model.train()\n",
        "#     model_collate_fn = functools.partial(\n",
        "#         make_qa_retriever_batch, tokenizer=tokenizer, max_len=args.max_length, device=\"cuda\"\n",
        "#     )\n",
        "#     # make iterator\n",
        "#     train_samplers = [RandomSampler(dataset) for dataset in dataset_list]\n",
        "#     data_loaders = [\n",
        "#         DataLoader(dataset, batch_size=args.batch_size, sampler=train_sampler, collate_fn=model_collate_fn)\n",
        "#         for dataset, train_sampler in zip(dataset_list, train_samplers)\n",
        "#     ]\n",
        "#     iterators = [iter(dloader) for dloader in data_loaders]\n",
        "#     joint_iter = zip(*iterators)\n",
        "#     # accumulate loss since last print\n",
        "#     loc_steps = 0\n",
        "#     loc_loss = 0.0\n",
        "#     st_time = time()\n",
        "#     for step, (batches,) in enumerate(zip(joint_iter)):\n",
        "#         for batch in batches:\n",
        "#             q_ids, q_mask, a_ids, a_mask = batch\n",
        "\n",
        "#             loss = model(q_ids, q_mask, a_ids, a_mask, checkpoint_batch_size=args.checkpoint_batch_size)\n",
        "#             # optimizer\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             scheduler.step()\n",
        "#             model.zero_grad()\n",
        "#             # some printing within the epoch\n",
        "#             loc_loss += loss.item()\n",
        "#             loc_steps += 1\n",
        "#         if step % args.print_freq == 0:\n",
        "#             print(\n",
        "#                 \"{:2d} {:5d} of {:5d} \\t L: {:.3f} \\t -- {:.3f}\".format(\n",
        "#                     e, step, len(dataset_list[0]) // args.batch_size, loc_loss / loc_steps, time() - st_time,\n",
        "#                 )\n",
        "#             )\n",
        "#             loc_loss = 0\n",
        "#             loc_steps = 0\n",
        "\n",
        "\n",
        "def evaluate_qa_retriever(model, dataset, tokenizer, args):\n",
        "    model.eval()\n",
        "    # make iterator\n",
        "    eval_sampler = SequentialSampler(dataset)\n",
        "    model_collate_fn = functools.partial(\n",
        "        make_qa_retriever_batch, tokenizer=tokenizer, max_len=args.max_length, device=\"cuda\"\n",
        "    )\n",
        "    data_loader = DataLoader(dataset, batch_size=args.batch_size, sampler=eval_sampler, collate_fn=model_collate_fn)\n",
        "    epoch_iterator = tqdm(data_loader, desc=\"Iteration\", disable=True)\n",
        "    tot_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "            q_ids, q_mask, a_ids, a_mask = batch\n",
        "            loss = model(q_ids, q_mask, a_ids, a_mask)\n",
        "            tot_loss += loss.item()\n",
        "        return tot_loss / (step + 1)\n",
        "\n",
        "\n",
        "def train_qa_retriever(qar_model, qar_tokenizer, qar_train_dset, qar_valid_dset, qar_args):\n",
        "    qar_optimizer = AdamW(qar_model.parameters(), lr=qar_args.learning_rate, eps=1e-8)\n",
        "    qar_scheduler = get_linear_schedule_with_warmup(\n",
        "        qar_optimizer,\n",
        "        num_warmup_steps=100,\n",
        "        num_training_steps=(qar_args.num_epochs + 1) * math.ceil(len(qar_train_dset) / qar_args.batch_size),\n",
        "    )\n",
        "    for e in range(qar_args.num_epochs):\n",
        "        train_qa_retriever_epoch(qar_model, qar_train_dset, qar_tokenizer, qar_optimizer, qar_scheduler, qar_args, e)\n",
        "        m_save_dict = {\n",
        "            \"model\": qar_model.state_dict(),\n",
        "            \"optimizer\": qar_optimizer.state_dict(),\n",
        "            \"scheduler\": qar_scheduler.state_dict(),\n",
        "        }\n",
        "        print(\"Saving model {}\".format(qar_args.model_save_name))\n",
        "        # torch.save(m_save_dict, \"{}_{}.pth\".format(qar_args.model_save_name, e))\n",
        "        eval_loss = evaluate_qa_retriever(qar_model, qar_valid_dset, qar_tokenizer, qar_args)\n",
        "        print(\"Evaluation loss epoch {:4d}: {:.3f}\".format(e, eval_loss))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301,
          "referenced_widgets": [
            "6b3cada9df814b24b3bf21e284996a27",
            "e5b3926014cd4a05b3527e9450516c36",
            "6e19563114c44c0a9ba495670c1fd689",
            "b3fb45f4b76e406f89bab5f073684b26",
            "b9bed4c4835d4caea59982b9f0ef764d",
            "4044246e8d3e4fb3993978d93a97977e",
            "56345e301399474dbc25db5e10c1615a",
            "09d0edda77cc48cd9d02f3cccb6bfaa6",
            "9cd27911c9304727929866b1b8193260",
            "03350e9f886949e2aa8bb84abe478150",
            "8d1ae3e3cca74f548e302af6ae7590d7",
            "3f0d0e5e413d454db183fdaf4cd91760",
            "680778c2424f4db08073ee0aedde31e9",
            "eef3b14894cc46ebac7cb0296af9f80a",
            "fcead20115454cb888d2527002b80c3b",
            "8001868602344938af217c5a6e42c1c9",
            "6787c9ad08a146ca86575b8c8bae4964",
            "d48b89bb489c4c8ba905b7856df2b646",
            "4307640ab0634682bd0d669512c687e4",
            "31886f6dcff14bcfa018db4923fb738f",
            "5e73716b1d54412d9bb42d624a9adae9",
            "8088d0b014254023a9e5da2b89318285",
            "073868227c4d4a9a8f94ccaff648d0c1",
            "fed803b53ebf4575a7e08faa06d64e64",
            "10c61a05cd244863b60f4fae65d78345",
            "4693296d6a8f4b51a888cc8159091b6d",
            "9e14ce64f0e54d7db3cecb96c278384f",
            "565780b0323c4057bd98abf79ea49a35",
            "33f03fec816b4da5ba6b6b207e27cb62",
            "ac484dbe0e1040b486a50a7170edad44",
            "9275f1f28bab4cecb1756cc6e2c9b4d0",
            "b67d12cbc08f4d3e8c2a183563d54c7d",
            "a1f6d0a151f8492e98218adf8f7c8fb5"
          ]
        },
        "id": "O30WJrHHhVcS",
        "outputId": "06ae62b1-3b2b-436f-e8e6-ce7df28c3ed7"
      },
      "source": [
        "# training arguments\n",
        "class ArgumentsQAR():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 512\n",
        "        self.max_length = 128\n",
        "        self.checkpoint_batch_size = 32\n",
        "        self.print_freq = 100\n",
        "        self.pretrained_model_name = \"google/bert_uncased_L-8_H-768_A-12\"\n",
        "        self.model_save_name = \"retriever_model_l-8_h-768_b-512-512\"\n",
        "        self.learning_rate = 2e-4\n",
        "        self.num_epochs =1\n",
        "\n",
        "qar_args = ArgumentsQAR()\n",
        "\n",
        "# prepare torch Dataset objects\n",
        "qar_train_dset = ELI5DatasetQARetriver(train,num_rows=len(train), training=True)\n",
        "qar_valid_dset = ELI5DatasetQARetriver(test,num_rows=len(test), training=False)\n",
        "\n",
        "# load pre-trained BERT and make model\n",
        "qar_tokenizer, qar_model = make_qa_retriever_model(\n",
        "        model_name=qar_args.pretrained_model_name,\n",
        "        from_file=None,\n",
        "        device=\"cuda\"\n",
        ")\n",
        "\n",
        "# train the model\n",
        "train_qa_retriever(qar_model, qar_tokenizer, qar_train_dset, qar_valid_dset, qar_args)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b3cada9df814b24b3bf21e284996a27",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/384 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f0d0e5e413d454db183fdaf4cd91760",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "073868227c4d4a9a8f94ccaff648d0c1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/327M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-8_H-768_A-12 were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0     0 of    17 \t L: 6.417 \t -- 16.878\n",
            " 0     1 of    17 \t L: 6.418 \t -- 33.808\n",
            "Saving model retriever_model_l-8_h-768_b-512-512\n",
            "Evaluation loss epoch    0: 5.872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nICkWOlSaSbN"
      },
      "source": [
        "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGh7wbrQunpO"
      },
      "source": [
        "Once the model is trained, it can be used to compute passage embeddings for all document corpus. The make_qa_dense_index method takes advantage of numpy memory-mapping, so embeddings are written directly to disk. Again with a single GPU, computing the full set of passage embeddings should take about 18 hours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haiyF2cgJh-k"
      },
      "source": [
        "# type(qar_model)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hR82BRPJh5g"
      },
      "source": [
        "# qar_model.save_pretrained('/content/drive/MyDrive/TSAI/Capstone_1/retriever_models/')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ILtJrEMJh00"
      },
      "source": [
        "# qar_model = AutoModel.from_pretrained('/content/').to('cuda')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6p7knHMJhwb"
      },
      "source": [
        "# type(qar)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPMv6noAFnCd"
      },
      "source": [
        "# type(qar_tokenizer)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eimv_jdPF89b"
      },
      "source": [
        "# qar_tokenizer.save_pretrained('/content/drive/MyDrive/TSAI/Capstone_1/ret_tokenizer/')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWCct9PoGUfb"
      },
      "source": [
        "# qar_tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/TSAI/Capstone_1qa_s2s_tokenizer/')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yK4na7_YUEW"
      },
      "source": [
        "\n",
        "###############\n",
        "# ELI5-trained retrieval model usage\n",
        "###############\n",
        "def embed_passages_for_retrieval(passages, tokenizer, qa_embedder, max_length=128, device=\"cuda\"):\n",
        "    a_toks = tokenizer.batch_encode_plus(passages, max_length=max_length, pad_to_max_length=True)\n",
        "    a_ids, a_mask = (\n",
        "        torch.LongTensor(a_toks[\"input_ids\"]).to(device),\n",
        "        torch.LongTensor(a_toks[\"attention_mask\"]).to(device),\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        a_reps = qa_embedder.embed_answers(a_ids, a_mask).cpu().type(torch.float)\n",
        "    return a_reps.numpy()\n",
        "def embed_questions_for_retrieval(q_ls, tokenizer, qa_embedder, device=\"cuda\"):\n",
        "    q_toks = tokenizer.batch_encode_plus(q_ls, max_length=128, pad_to_max_length=True)\n",
        "    q_ids, q_mask = (\n",
        "        torch.LongTensor(q_toks[\"input_ids\"]).to(device),\n",
        "        torch.LongTensor(q_toks[\"attention_mask\"]).to(device),\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        q_reps = qa_embedder.embed_questions(q_ids, q_mask).cpu().type(torch.float)\n",
        "    return q_reps.numpy()\n",
        "def make_qa_dense_index(\n",
        "    qa_embedder,\n",
        "    tokenizer,\n",
        "    passages_dset,\n",
        "    batch_size=512,\n",
        "    max_length=128,\n",
        "    index_name=\"kilt_passages_reps.dat\",\n",
        "    dtype=\"float32\",\n",
        "    device=\"cuda\",\n",
        "):\n",
        "    st_time = time()\n",
        "    fp = np.memmap(index_name, dtype=dtype, mode=\"w+\", shape=(len(passages_dset),128))\n",
        "    n_batches = math.ceil(len(passages_dset) / batch_size)\n",
        "    for i in range(n_batches):\n",
        "        passages = [p[\"z\"] for p in passages_dset[i * batch_size : (i + 1) * batch_size]]\n",
        "        reps = embed_passages_for_retrieval(passages, tokenizer, qa_embedder, max_length, device)\n",
        "        fp[i * batch_size : (i + 1) * batch_size] = reps\n",
        "        if i % 50 == 0:\n",
        "            print(i, time() - st_time)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGkQc1L0Kop9"
      },
      "source": [
        "os.chdir(r'/content/drive/MyDrive/TSAI/Capstone_1')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fB4Dp5hukVm"
      },
      "source": [
        "if not os.path.isfile('wiki40b_passages_reps_32_l-8_h-768_b-512-512.dat'):\n",
        "  print(\"hi\")\n",
        "\n",
        "  make_qa_dense_index(\n",
        "          qar_model, qar_tokenizer, passage_snippets, device='cuda',\n",
        "          index_name='wiki40b_passages_reps_32_l-8_h-768_b-512-512.dat' )"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01GnGvUo1YPC"
      },
      "source": [
        "### 4.b - Using the Trained Dense Retriever and Wikipedia Index\n",
        "Now that we have trained our model to compute query and answer embeddings and used it to compute passage embeddings for all our Wikipedia snippets, let's see whether it can actually find supporting evidence for a new question. Recall the the two steps to using the dense retriever: we first compute an embedding for a new question, then do Max Inner Product Search with the pre-computed passage representations.\n",
        "\n",
        "The MIPS part can be executed efficiently with the faiss library. Additionally, since we computed 128-dimensional passage embeddings, the whole of the representations fits on a GPU, making retrieval even faster. We can create the faiss_gpu index with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdiIwQw4Qboj"
      },
      "source": [
        "n_ret = 5"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzWm_WCC1g--"
      },
      "source": [
        "faiss_res = faiss.StandardGpuResources()\n",
        "wiki40b_passage_reps = np.memmap(\n",
        "            'wiki40b_passages_reps_32_l-8_h-768_b-512-512.dat',\n",
        "            dtype='float32', mode='r',\n",
        "            # shape=(wiki40b_snippets.num_rows, 128)\n",
        "            # wiki40b_snippets.num_rows = 11378343,english sections from wiki40B dataset\n",
        "            shape=(len(passage_snippets), 128)\n",
        ")\n",
        "\n",
        "wiki40b_index_flat = faiss.IndexFlatIP(128)\n",
        "wiki40b_gpu_index = faiss.index_cpu_to_gpu(faiss_res, 0, wiki40b_index_flat)\n",
        "wiki40b_gpu_index.add(wiki40b_passage_reps)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HFtgUv-30K4"
      },
      "source": [
        "\n",
        "# build a support document for the question out of Wikipedia snippets\n",
        "# def query_qa_dense_index(\n",
        "#     question, qa_embedder, tokenizer, wiki_passages, wiki_index, n_results=10, min_length=2, device=\"cuda\"\n",
        "# ):\n",
        "#     q_rep = embed_questions_for_retrieval([question], tokenizer, qa_embedder, device=device)\n",
        "#     D, I = wiki_index.search(q_rep, 2 * n_results)\n",
        "#     res_passages = [wiki_passages[int(i)] for i in I[0]]\n",
        "#     support_doc = \"<P> \" + \" <P> \".join([p[\"z\"] for p in res_passages])\n",
        "#     res_list = [p['z'] for p in res_passages]\n",
        "\n",
        "#     for r, sc in zip(res_list, D[0]):\n",
        "#         r[\"score\"] = float(sc)\n",
        "#     return support_doc, res_list\n",
        "# find nearest neighbors of an answer or declarative text in Wikipedia snippets\n",
        "\n",
        "# build a support document for the question out of Wikipedia snippets\n",
        "def query_qa_dense_index(\n",
        "    question, qa_embedder, tokenizer, wiki_passages, wiki_index, n_results=n_ret, min_length=1, device=\"cuda\"\n",
        "):\n",
        "    q_rep = embed_questions_for_retrieval([question], tokenizer, qa_embedder, device=device)\n",
        "    D, I = wiki_index.search(q_rep, 2 * n_results)\n",
        "    res_passages = [wiki_passages[int(i)] for i in I[0]]\n",
        "    support_doc = \"<P> \" + \" <P> \".join([p[\"z\"] for p in res_passages])\n",
        "    res_list = [dict([(k, p[k]) for k in [\"z\"]]) for p in res_passages]\n",
        "    res_list = [res for res in res_list if len(res[\"z\"].split()) > min_length][:n_results]\n",
        "    for r, sc in zip(res_list, D[0]):\n",
        "        r[\"score\"] = float(sc)\n",
        "    return support_doc, res_list"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1hJ2_U12lYQ"
      },
      "source": [
        "Now we can use the query_qa_dense_index function to query the dense index for our running example question :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhJqmCP52wnA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e7393aa7-7107-44b1-9bac-bd352a317431"
      },
      "source": [
        "question = test[12]['x']\n",
        "question"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'In what platform do the modules Conv2d() and Linear() run?'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYoEC2yU2jUA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "outputId": "bd05d3a7-d8b9-4308-dd9e-e0dd5b90243b"
      },
      "source": [
        "doc, res_list = query_qa_dense_index(question, qar_model, qar_tokenizer, passage_snippets, wiki40b_gpu_index, device='cuda')\n",
        "print(res_list)\n",
        "df = pd.DataFrame({\n",
        "    \n",
        "    'Text': ['--- ' + question] + [res['z'] for res in res_list],\n",
        "})\n",
        "df.style.set_properties(**{'text-align': 'left'})"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'z': \"I've put all your functions followed by the corresponding pytorch function. Most are the same name and put in the pytorch docs (https://pytorch.org/docs/stable/index.html)\\ntf.cumsum(alpha, axis = 1)  \\ntorch.cumsum(alpha, dim=1)\\n\\ntf.shape(alpha_cumsum)[0]\\nalpha_cumsum.shape[0]\\n\\ntf.random_uniform(shape = [len_batch, 1], minval = 0., maxval = 1.)\\ntorch.rand([len_batch,1])\\n\\ntf.nn.relu(rand_prob - alpha_cumsum)\\ntorch.nn.functional.relu(rand_prob - alpha_cumsum)\\n\\ntf.count_nonzero(alpha_relu, 1)\\ntorch.count_nonzero(alpha_relu, dim=1)\\n\\ntf.one_hot(alpha_index, len(a))\\ntorch.nn.functional.one_hot(alpha_index, len(a)) # assuming len(a) is number of classes\\n\\n\", 'score': 4.655016899108887}, {'z': \"I'm working on the same thing.\\nHere is what I got.\\ndef compute_angle(p1, p2):\\n    # inner_product = torch.dot(p1, p2)\\n    inner_product = (p1*p2).sum(-1)\\n    p1_norm = torch.linalg.norm(p1, axis=-1)\\n    p2_norm = torch.linalg.norm(p2, axis=-1)\\n    cos = inner_product / (p1_norm * p2_norm)\\n    cos = torch.clamp(cos, -0.99999, 0.99999)\\n    angle = torch.acos(cos)\\n    return angle\\ndef compute_dihedral(v1,v2,v3,v4):\\n    ab = v1 - v2\\n    cb = v3 - v2\\n    db = v4 - v3\\n    u = torch.cross(ab, cb)\\n    v = torch.cross(db, cb)\\n    w = torch.cross(u, v)\\n    angle = compute_angle(u, v)\\n    # angle = torch.where(compute_angle(cb, w)  0.001, -angle, angle)\\n    angle = torch.where(compute_angle(cb, w)  1, -angle, angle)\\n#     try:\\n#         if compute_angle(cb, w)  0.001:\\n#             angle = -angle\\n#     except ZeroDivisionError:\\n#         # dihedral=pi\\n#         pass\\n    return angle\\n\\nv1 = torch.tensor([-17.0490,   5.9270,  21.5340], requires_grad=True)\\nv2 = torch.tensor([-0.1608,  0.0600, -0.0371], requires_grad=True)\\nv3 = torch.tensor([-0.2000,  0.0007, -0.0927], requires_grad=True)\\nv4 = torch.tensor([-0.1423,  0.0197, -0.0727], requires_grad=True)\\n\\ndihedral = compute_dihedral(v1,v2,v3,v4)\\ntarget_dihedral = -2\\n\\nprint(dihedral)   # should print -2.6387\\n\\n\\nfor i in range(100):\\n    dihedral = compute_dihedral(v1,v2,v3,v4)\\n    loss = (dihedral - target_dihedral)**2\\n    loss.backward()\\n    learning_rate = 0.001\\n    with torch.no_grad():\\n        v1 -= learning_rate * v1.grad\\n        v2 -= learning_rate * v2.grad\\n        v3 -= learning_rate * v3.grad\\n        v4 -= learning_rate * v4.grad\\n\\n        # Manually zero the gradients after updating weights\\n        v1.grad = None\\n        v2.grad = None\\n        v3.grad = None\\n        v4.grad = None\\nprint(compute_dihedral(v1,v2,v3,v4))   # should print -2\\n\\n\", 'score': 4.624341011047363}, {'z': 'Cool!\\n\\nTake a look at how similar functions, like sin, are implemented. See: https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/UnaryOps.cpp for the device-independent part of the code. Then you have the CPU and CUDA-specific parts in ATen/native/cpu and ATen/native/cuda, respectively. \\n\\n', 'score': 4.598659515380859}, {'z': 'torch.baddbmm performs a batch matrix-matrix product of matrices in batch1 and batch2.   Performs a batch matrix-matrix product of matrices stored in input and mat2.   Returns the matrix product of the NNN 2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrix AAA or for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrix AAA using its Cholesky factor uuu: returns matrix inv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrix uuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK’s geqrf directly.   Alias of torch.outer().   Computes the dot product for 1D tensors.   Alias for torch.linalg.inv()   Alias for torch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias for torch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrix AAA of size (m × n)(m \\\\times n)(m × n) and a matrix BBB of size (m × k)(m \\\\times k)(m × k).   Computes the LU factorization of a matrix or batches of matrices A.   Returns the LU solve of the linear system Ax=bAx = bAx=b using the partially pivoted LU factorization of A from torch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensors L and U and a permutation tensor P such that LU_data, LU_pivots = (P @ L @ U).lu().   Matrix product of two tensors.   Alias for torch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matrices input and mat2.   Performs a matrix-vector product of the matrix input and the vector vec.   Alias for torch.linalg.householder_product().', 'score': 4.428356170654297}, {'z': 'Performs a matrix-vector product of the matrix mat and the vector vec.   Performs the outer-product of vectors vec1 and vec2 and adds it to the matrix input.   torch.baddbmm performs a batch matrix-matrix product of matrices in batch1 and batch2.   Performs a batch matrix-matrix product of matrices stored in input and mat2.   Returns the matrix product of the NNN 2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrix AAA or for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrix AAA using its Cholesky factor uuu: returns matrix inv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrix uuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK’s geqrf directly.   Alias of torch.outer().   Computes the dot product for 1D tensors.   Alias for torch.linalg.inv()   Alias for torch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias for torch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrix AAA of size (m × n)(m \\\\times n)(m × n) and a matrix BBB of size (m × k)(m \\\\times k)(m × k).   Computes the LU factorization of a matrix or batches of matrices A.   Returns the LU solve of the linear system Ax=bAx = bAx=b using the partially pivoted LU factorization of A from torch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensors L and U and a permutation tensor P such that LU_data, LU_pivots = (P @ L @ U).lu().   Matrix product of two tensors.   Alias for torch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matrices input and mat2.', 'score': 4.4006500244140625}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_594ec624_1399_11ec_a061_0242ac1c0002row0_col0,#T_594ec624_1399_11ec_a061_0242ac1c0002row1_col0,#T_594ec624_1399_11ec_a061_0242ac1c0002row2_col0,#T_594ec624_1399_11ec_a061_0242ac1c0002row3_col0,#T_594ec624_1399_11ec_a061_0242ac1c0002row4_col0,#T_594ec624_1399_11ec_a061_0242ac1c0002row5_col0{\n",
              "            text-align:  left;\n",
              "        }</style><table id=\"T_594ec624_1399_11ec_a061_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Text</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_594ec624_1399_11ec_a061_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_594ec624_1399_11ec_a061_0242ac1c0002row0_col0\" class=\"data row0 col0\" >--- In what platform do the modules Conv2d() and Linear() run?</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_594ec624_1399_11ec_a061_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_594ec624_1399_11ec_a061_0242ac1c0002row1_col0\" class=\"data row1 col0\" >I've put all your functions followed by the corresponding pytorch function. Most are the same name and put in the pytorch docs (https://pytorch.org/docs/stable/index.html)\n",
              "tf.cumsum(alpha, axis = 1)  \n",
              "torch.cumsum(alpha, dim=1)\n",
              "\n",
              "tf.shape(alpha_cumsum)[0]\n",
              "alpha_cumsum.shape[0]\n",
              "\n",
              "tf.random_uniform(shape = [len_batch, 1], minval = 0., maxval = 1.)\n",
              "torch.rand([len_batch,1])\n",
              "\n",
              "tf.nn.relu(rand_prob - alpha_cumsum)\n",
              "torch.nn.functional.relu(rand_prob - alpha_cumsum)\n",
              "\n",
              "tf.count_nonzero(alpha_relu, 1)\n",
              "torch.count_nonzero(alpha_relu, dim=1)\n",
              "\n",
              "tf.one_hot(alpha_index, len(a))\n",
              "torch.nn.functional.one_hot(alpha_index, len(a)) # assuming len(a) is number of classes\n",
              "\n",
              "</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_594ec624_1399_11ec_a061_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_594ec624_1399_11ec_a061_0242ac1c0002row2_col0\" class=\"data row2 col0\" >I'm working on the same thing.\n",
              "Here is what I got.\n",
              "def compute_angle(p1, p2):\n",
              "    # inner_product = torch.dot(p1, p2)\n",
              "    inner_product = (p1*p2).sum(-1)\n",
              "    p1_norm = torch.linalg.norm(p1, axis=-1)\n",
              "    p2_norm = torch.linalg.norm(p2, axis=-1)\n",
              "    cos = inner_product / (p1_norm * p2_norm)\n",
              "    cos = torch.clamp(cos, -0.99999, 0.99999)\n",
              "    angle = torch.acos(cos)\n",
              "    return angle\n",
              "def compute_dihedral(v1,v2,v3,v4):\n",
              "    ab = v1 - v2\n",
              "    cb = v3 - v2\n",
              "    db = v4 - v3\n",
              "    u = torch.cross(ab, cb)\n",
              "    v = torch.cross(db, cb)\n",
              "    w = torch.cross(u, v)\n",
              "    angle = compute_angle(u, v)\n",
              "    # angle = torch.where(compute_angle(cb, w)  0.001, -angle, angle)\n",
              "    angle = torch.where(compute_angle(cb, w)  1, -angle, angle)\n",
              "#     try:\n",
              "#         if compute_angle(cb, w)  0.001:\n",
              "#             angle = -angle\n",
              "#     except ZeroDivisionError:\n",
              "#         # dihedral=pi\n",
              "#         pass\n",
              "    return angle\n",
              "\n",
              "v1 = torch.tensor([-17.0490,   5.9270,  21.5340], requires_grad=True)\n",
              "v2 = torch.tensor([-0.1608,  0.0600, -0.0371], requires_grad=True)\n",
              "v3 = torch.tensor([-0.2000,  0.0007, -0.0927], requires_grad=True)\n",
              "v4 = torch.tensor([-0.1423,  0.0197, -0.0727], requires_grad=True)\n",
              "\n",
              "dihedral = compute_dihedral(v1,v2,v3,v4)\n",
              "target_dihedral = -2\n",
              "\n",
              "print(dihedral)   # should print -2.6387\n",
              "\n",
              "\n",
              "for i in range(100):\n",
              "    dihedral = compute_dihedral(v1,v2,v3,v4)\n",
              "    loss = (dihedral - target_dihedral)**2\n",
              "    loss.backward()\n",
              "    learning_rate = 0.001\n",
              "    with torch.no_grad():\n",
              "        v1 -= learning_rate * v1.grad\n",
              "        v2 -= learning_rate * v2.grad\n",
              "        v3 -= learning_rate * v3.grad\n",
              "        v4 -= learning_rate * v4.grad\n",
              "\n",
              "        # Manually zero the gradients after updating weights\n",
              "        v1.grad = None\n",
              "        v2.grad = None\n",
              "        v3.grad = None\n",
              "        v4.grad = None\n",
              "print(compute_dihedral(v1,v2,v3,v4))   # should print -2\n",
              "\n",
              "</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_594ec624_1399_11ec_a061_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_594ec624_1399_11ec_a061_0242ac1c0002row3_col0\" class=\"data row3 col0\" >Cool!\n",
              "\n",
              "Take a look at how similar functions, like sin, are implemented. See: https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/UnaryOps.cpp for the device-independent part of the code. Then you have the CPU and CUDA-specific parts in ATen/native/cpu and ATen/native/cuda, respectively. \n",
              "\n",
              "</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_594ec624_1399_11ec_a061_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_594ec624_1399_11ec_a061_0242ac1c0002row4_col0\" class=\"data row4 col0\" >torch.baddbmm performs a batch matrix-matrix product of matrices in batch1 and batch2.   Performs a batch matrix-matrix product of matrices stored in input and mat2.   Returns the matrix product of the NNN 2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrix AAA or for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrix AAA using its Cholesky factor uuu: returns matrix inv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrix uuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK’s geqrf directly.   Alias of torch.outer().   Computes the dot product for 1D tensors.   Alias for torch.linalg.inv()   Alias for torch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias for torch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrix AAA of size (m × n)(m \\times n)(m × n) and a matrix BBB of size (m × k)(m \\times k)(m × k).   Computes the LU factorization of a matrix or batches of matrices A.   Returns the LU solve of the linear system Ax=bAx = bAx=b using the partially pivoted LU factorization of A from torch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensors L and U and a permutation tensor P such that LU_data, LU_pivots = (P @ L @ U).lu().   Matrix product of two tensors.   Alias for torch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matrices input and mat2.   Performs a matrix-vector product of the matrix input and the vector vec.   Alias for torch.linalg.householder_product().</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_594ec624_1399_11ec_a061_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_594ec624_1399_11ec_a061_0242ac1c0002row5_col0\" class=\"data row5 col0\" >Performs a matrix-vector product of the matrix mat and the vector vec.   Performs the outer-product of vectors vec1 and vec2 and adds it to the matrix input.   torch.baddbmm performs a batch matrix-matrix product of matrices in batch1 and batch2.   Performs a batch matrix-matrix product of matrices stored in input and mat2.   Returns the matrix product of the NNN 2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrix AAA or for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrix AAA using its Cholesky factor uuu: returns matrix inv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrix uuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK’s geqrf directly.   Alias of torch.outer().   Computes the dot product for 1D tensors.   Alias for torch.linalg.inv()   Alias for torch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias for torch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrix AAA of size (m × n)(m \\times n)(m × n) and a matrix BBB of size (m × k)(m \\times k)(m × k).   Computes the LU factorization of a matrix or batches of matrices A.   Returns the LU solve of the linear system Ax=bAx = bAx=b using the partially pivoted LU factorization of A from torch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensors L and U and a permutation tensor P such that LU_data, LU_pivots = (P @ L @ U).lu().   Matrix product of two tensors.   Alias for torch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matrices input and mat2.</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fe24ed68850>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGGKrGgr6u6a"
      },
      "source": [
        "### 4.c - Retriever Model Evaluation\n",
        "We have trained a retrieval model that seems to be working a little better than the traditional word-matching based approach, at least on our running example. Before we use it to actually answer questions, however, we would like to be able to get some quantitative evaluation of the performances of both approaches.\n",
        "\n",
        "For the retriever, we want to favor recall over precision: our first priority is to make sure that all of the information needed to write the answers is present in the support document. If there is unrelated information, the generation model can learn to sort it out. We measure this by computing the proportion of words in the high-scoring answers which are present in the retrieved support document. To focus on important words, we also weigh answer words by their Inverse Document Frequency. This gives us the following IDF-recall scoring function:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suCtm8mSCI7H"
      },
      "source": [
        "## 5. Generating Answers with a Sequence-to-Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8rHQ10Zg33h"
      },
      "source": [
        "# ELI5 seq2seq model training\n",
        "###############\n",
        "class ELI5DatasetS2S(Dataset):\n",
        "    def __init__(\n",
        "        self, examples_array,num_rows, make_doc_fun=None, document_cache=None, training=True\n",
        "    ):\n",
        "        self.training = training\n",
        "        self.data = examples_array\n",
        "        self.make_doc_function = make_doc_fun\n",
        "        self.document_cache = {} if document_cache is None else document_cache\n",
        "        self.num_rows = num_rows\n",
        "        assert not (make_doc_fun is None and document_cache is None)\n",
        "        # make index of specific question-answer pairs from multi-answers\n",
        "        if self.training:\n",
        "            self.qa_id_list = [(i, 0) for i in range(self.num_rows)]\n",
        "\n",
        "        else:\n",
        "            self.qa_id_list = [(i, 0) for i in range(self.num_rows)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.qa_id_list)\n",
        "\n",
        "    def make_example(self, idx):\n",
        "        i, j = self.qa_id_list[idx]\n",
        "        example = self.data[i]\n",
        "        question = example[\"x\"] \n",
        "        answer = example[\"y\"]\n",
        "        q_id = example[\"id\"]\n",
        "        if self.make_doc_function is not None:\n",
        "            self.document_cache[q_id] = self.document_cache.get(q_id, self.make_doc_function(example[\"x\"]))\n",
        "        document = self.document_cache[q_id]\n",
        "        in_st = \"question: {} context: {}\".format(\n",
        "            question.lower().strip(), document.lower().strip(),\n",
        "        )\n",
        "        out_st = answer\n",
        "        return (in_st, out_st)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.make_example(idx)\n",
        "\n",
        "\n",
        "def make_qa_s2s_model(model_name=\"facebook/bart-large\", from_file=None, device=\"cuda\"):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
        "    if from_file is not None:\n",
        "        param_dict = torch.load(from_file)  # has model weights, optimizer, and scheduler states\n",
        "        model.load_state_dict(param_dict[\"model\"])\n",
        "    return tokenizer, model\n",
        "\n",
        "\n",
        "def make_qa_s2s_batch(qa_list, tokenizer, max_len=64, max_a_len=128, device=\"cuda\"):\n",
        "    q_ls = [q for q, a in qa_list]\n",
        "    a_ls = [a for q, a in qa_list]\n",
        "    q_toks = tokenizer.batch_encode_plus(q_ls, max_length=max_len, pad_to_max_length=True)\n",
        "    q_ids, q_mask = (\n",
        "        torch.LongTensor(q_toks[\"input_ids\"]).to(device),\n",
        "        torch.LongTensor(q_toks[\"attention_mask\"]).to(device),\n",
        "    )\n",
        "    a_toks = tokenizer.batch_encode_plus(a_ls, max_length=min(max_len, max_a_len), pad_to_max_length=True)\n",
        "    a_ids, a_mask = (\n",
        "        torch.LongTensor(a_toks[\"input_ids\"]).to(device),\n",
        "        torch.LongTensor(a_toks[\"attention_mask\"]).to(device),\n",
        "    )\n",
        "    labels = a_ids[:, 1:].contiguous().clone()\n",
        "    labels[a_mask[:, 1:].contiguous() == 0] = -100\n",
        "    # print(labels)\n",
        "    model_inputs = {\n",
        "        \"input_ids\": q_ids,\n",
        "        \"attention_mask\": q_mask,\n",
        "        \"decoder_input_ids\": a_ids[:, :-1].contiguous(),\n",
        "        \"labels\": labels,\n",
        "    }\n",
        "    # print(\"it'sme\",model_inputs)\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "def train_qa_s2s_epoch(model, dataset, tokenizer, optimizer, scheduler, args, e=0, curriculum=True):\n",
        "    model.train()\n",
        "    # make iterator\n",
        "    if curriculum:\n",
        "        train_sampler = SequentialSampler(dataset)\n",
        "    else:\n",
        "        train_sampler = RandomSampler(dataset)\n",
        "    model_collate_fn = functools.partial(\n",
        "        make_qa_s2s_batch, tokenizer=tokenizer, max_len=args.max_length, device=\"cuda\"\n",
        "    )\n",
        "    data_loader = DataLoader(dataset, batch_size=args.batch_size, sampler=train_sampler, collate_fn=model_collate_fn)\n",
        "    epoch_iterator = tqdm(data_loader, desc=\"Iteration\", disable=True)\n",
        "\n",
        "  \n",
        "    # accumulate loss since last print\n",
        "    loc_steps = 0\n",
        "    loc_loss = 0.0\n",
        "    st_time = time()\n",
        "    for step, batch_inputs in enumerate(epoch_iterator):\n",
        "        # print(type(step))\n",
        "        \n",
        "        pre_loss = model(**batch_inputs)[0]\n",
        "        # print(pre_loss.s(),\"pre sum\")\n",
        "        # print(pre_loss,\"pre loss\")\n",
        "        # print(pre_loss.item(),\"pre shape 0\")\n",
        "        loss = pre_loss.sum() / pre_loss.item()\n",
        "        loss.backward()\n",
        "        # optimizer\n",
        "        if step % args.backward_freq == 0:\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            model.zero_grad()\n",
        "        # some printing within the epoch\n",
        "        loc_loss += loss.item()\n",
        "        loc_steps += 1\n",
        "        if step % args.print_freq == 0 or step == 1:\n",
        "            print(\n",
        "                \"{:2d} {:5d} of {:5d} \\t L: {:.3f} \\t -- {:.3f}\".format(\n",
        "                    e, step, len(dataset) // args.batch_size, loc_loss / loc_steps, time() - st_time,\n",
        "                )\n",
        "            )\n",
        "            loc_loss = 0\n",
        "            loc_steps = 0\n",
        "\n",
        "\n",
        "def eval_qa_s2s_epoch(model, dataset, tokenizer, args):\n",
        "    model.eval()\n",
        "    # make iterator\n",
        "    train_sampler = SequentialSampler(dataset)\n",
        "    model_collate_fn = functools.partial(\n",
        "        make_qa_s2s_batch, tokenizer=tokenizer, max_len=args.max_length, device=\"cuda\"\n",
        "    )\n",
        "    data_loader = DataLoader(dataset, batch_size=args.batch_size, sampler=train_sampler, collate_fn=model_collate_fn)\n",
        "    epoch_iterator = tqdm(data_loader, desc=\"Iteration\", disable=True)\n",
        "    # accumulate loss since last print\n",
        "    loc_steps = 0\n",
        "    loc_loss = 0.0\n",
        "    st_time = time()\n",
        "    with torch.no_grad():\n",
        "        for step, batch_inputs in enumerate(epoch_iterator):\n",
        "            pre_loss = model(**batch_inputs)[0]\n",
        "            print(pre_loss,'pre_loss')\n",
        "            print(pre_loss.shape)\n",
        "            print(pre_loss.sum(),'sum')\n",
        "            loss = pre_loss.sum() / pre_loss.item()\n",
        "            loc_loss += loss.item()\n",
        "            print(\"loc loss here\",loc_loss)\n",
        "            loc_steps += 1\n",
        "            if step % args.print_freq == 0:\n",
        "                print(\n",
        "                    \"{:5d} of {:5d} \\t L: {:.3f} \\t -- {:.3f}\".format(\n",
        "                        step, len(dataset) // args.batch_size, loc_loss / loc_steps, time() - st_time,\n",
        "                    )\n",
        "                )\n",
        "    print(\"Total \\t L: {:.3f} \\t -- {:.3f}\".format(loc_loss / loc_steps, time() - st_time,))\n",
        "\n",
        "\n",
        "def train_qa_s2s(qa_s2s_model, qa_s2s_tokenizer, s2s_train_dset, s2s_valid_dset, s2s_args):\n",
        "    s2s_optimizer = AdamW(qa_s2s_model.parameters(), lr=s2s_args.learning_rate, eps=1e-8)\n",
        "    s2s_scheduler = get_linear_schedule_with_warmup(\n",
        "        s2s_optimizer,\n",
        "        num_warmup_steps=400,\n",
        "        num_training_steps=(s2s_args.num_epochs + 1) * math.ceil(len(s2s_train_dset) / s2s_args.batch_size),\n",
        "    )\n",
        "    for e in range(s2s_args.num_epochs):\n",
        "        # print((e == 0))\n",
        "\n",
        "        train_qa_s2s_epoch(\n",
        "            qa_s2s_model,\n",
        "            s2s_train_dset,\n",
        "            qa_s2s_tokenizer,\n",
        "            s2s_optimizer,\n",
        "            s2s_scheduler,\n",
        "            s2s_args,\n",
        "            e,\n",
        "            curriculum=True,\n",
        "        )\n",
        "        m_save_dict = {\n",
        "            \"model\": qa_s2s_model.state_dict(),\n",
        "            \"optimizer\": s2s_optimizer.state_dict(),\n",
        "            \"scheduler\": s2s_scheduler.state_dict(),\n",
        "        }\n",
        "        print(\"Saving model {}\".format(s2s_args.model_save_name))\n",
        "        eval_qa_s2s_epoch(qa_s2s_model, s2s_valid_dset, qa_s2s_tokenizer, s2s_args)\n",
        "        # torch.save(m_save_dict, \"\\{}_{}.pth\".format(s2s_args.model_save_name, e))\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfcUuZx_AMaQ"
      },
      "source": [
        "# qa_s2s_tokenizer.save_pretrained(path+\"qa_s2s_tokenizer\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d66TaMZE_641"
      },
      "source": [
        "# qar_tokenizer"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0JOPJ1S995Q"
      },
      "source": [
        "n_ret = 2"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e3acd4131f7b4eeba32f498dc4ac27f2",
            "170b9b8c0b2c4fd2b2ac932647b0d2a3",
            "9fa2138bfec94ddca88e3d2ee0dba4d9",
            "3781a7b71d0b4bc189f96ce92c160a2d",
            "359833458b554301b18213493e1223e6",
            "89895f0849e24fc98beabc5bf9128074",
            "b6c2eb46d9524e128b6bd452a7884ce0",
            "60208aa245a14626b6f5a220e3daba6b",
            "af69b0575ff14e9ca96e7d08ddd6a64a",
            "30bc808ec34f402b8b1db54ff7ac7f43",
            "13b3ee84a2bd46bba6a912492a62542d",
            "0497a2a67e394c30b5a47d941d515153",
            "3e6e4280eedf4077a90de2fbed18cba9",
            "454d4cbcc0c14379a25580aada52945b",
            "3ef0aa991b724add8a4db6bb0fde5532",
            "453c8152631d4e0db2d332404f7b2f38",
            "56d55c6f0a984b1cb8dedac4a993051a",
            "b82145de5372494f9ab63725d4025193",
            "376f8afc141347b1843fd58fa6f9e26d",
            "991c1acb21b241aca16fc1744b002e64",
            "3064160a45064fc9a7660140def19fdf",
            "5f1b1dbf825a464ca8c44ca514bd17f9",
            "a7eba9b43a2649cbaeab6574794f744e",
            "3a3c698b9fea41a7849a2d9fabff5041",
            "98abc9d6866747c5b0382e8175d694e9",
            "15d45d8f399443d59fdd82cd203eb1d5",
            "61a9f2d0c5fd4a00a084217c313d239a",
            "603b3c2d91b34d0b8be86fc7e432cd8a",
            "f526c5a5e80d4e7d96cf6de3990f3de9",
            "7f15dd7804764802b7503846d5e6602f",
            "b4d96a2cb6c04504947b6cf4c3df8952",
            "206de7c5805744a99a8147af59059f3d",
            "352b24a34a3c42bcb271e91ca6b76a62",
            "a91029969afe47bc88055da77464fede",
            "8e78e509d6b64e579544bb5c1ec50532",
            "90af0857e2f041638896687689a5f6d2",
            "254853d2fba441baba60661ce3b82a91",
            "b5d64a4355b940dcbb9e0fa653425947",
            "d488baee32944bd7af2621c0ada6ec75",
            "7687b88b8f854968949ece6fce039f10",
            "0706e77f6fb94dc891588ddf783e5011",
            "b9418ac043e54c8aad7ae21b94a91ad1",
            "6dba31d2149243f0b60727a75be5baa6",
            "172fa4da648b47219cc54a45ff29b7d5",
            "7b3646b526814cc3824360dfe340de66",
            "933ab246230e40c2a5621c4991c5e6b2",
            "ff051c719214490487c81b17716cc4e8",
            "2d0557a4bf0540d08e4bf143cb409e13",
            "f2e017b7f35b4fb6aae6dd93133e1635",
            "28b661505d624f73aa76122e3a1d5d01",
            "b6b527ca34b04cb58f24970023ded77e",
            "d4f6ba53a27d4ce4875ae2cf866571bf",
            "fc41dfa478f14490ae9b2bf10c6f77b3",
            "d6815d57a2c141479af40e9b7fd4c362",
            "ee58453af0424d1a8ec8d2b29d71e819",
            "c2c7ff66f8a44b5faeff6b82133d0705",
            "a71da9027dd64ce2a6ceeb1a6dc5cc42",
            "75268db943184524b620291aedd7d6aa",
            "aaaca7fba9e449f9b79dca36407a1664",
            "d9303146f6d34d04b183e88b33169e34",
            "1f22dabbc6004990967da7448777296b",
            "3278877db6f6428bab9809e269404d0b",
            "fe92083b89374349b888013ada18d88e",
            "ef2fcb6f8ab040568cb5933aee37cca3",
            "ca43ed81e60047c4a08173567d9463a6",
            "ad37d635e7d94ae2966ab2eeb86a9f55"
          ]
        },
        "id": "5Fhed0htCIL5",
        "outputId": "d5cc123b-2044-4e0a-940b-a3686fa5b284"
      },
      "source": [
        "# pre-computing support documents\n",
        "eli5_train_docs = []\n",
        "for example in train:\n",
        "    support_doc, dense_res_list = query_qa_dense_index(\n",
        "        example['x'], qar_model, qar_tokenizer,passage_snippets, wiki40b_gpu_index, n_results=n_ret\n",
        "    )\n",
        "    eli5_train_docs += [(example['id'], support_doc, dense_res_list)]\n",
        "\n",
        "eli5_valid_docs = []\n",
        "for example in test:\n",
        "    support_doc, dense_res_list = query_qa_dense_index(\n",
        "        example['x'], qar_model, qar_tokenizer, passage_snippets, wiki40b_gpu_index, n_results=n_ret\n",
        "    )\n",
        "    eli5_valid_docs += [(example['id'], support_doc, dense_res_list)]\n",
        "\n",
        "# training loop proper\n",
        "class ArgumentsS2S():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 2\n",
        "        self.backward_freq = 16\n",
        "        self.max_length = 512\n",
        "        self.print_freq = 100\n",
        "        self.model_save_name = \"eli5_bart_model\"\n",
        "        self.learning_rate = 2e-4\n",
        "        self.num_epochs =1\n",
        "\n",
        "s2s_args = ArgumentsS2S()\n",
        "\n",
        "# eli5_train_docs = json.load(open('precomputed/eli5_train_precomputed_dense_docs.json'))\n",
        "# eli5_valid_docs = json.load(open('precomputed/eli5_valid_precomputed_dense_docs.json'))\n",
        "s2s_train_dset = ELI5DatasetS2S(train,num_rows =len(train), document_cache=dict([(k, d) for k, d, src_ls in eli5_train_docs]))\n",
        "s2s_valid_dset = ELI5DatasetS2S(test,num_rows =len(test), document_cache=dict([(k, d) for k, d, src_ls in eli5_valid_docs]), training=False)\n",
        "\n",
        "qa_s2s_tokenizer, pre_model = make_qa_s2s_model(\n",
        "    model_name=\"facebook/bart-large\",\n",
        "    from_file=None,\n",
        "    device=\"cuda\"\n",
        ")\n",
        "# qa_s2s_model = torch.nn.DataParallel(pre_model)\n",
        "qa_s2s_model =pre_model\n",
        "train_qa_s2s(qa_s2s_model, qa_s2s_tokenizer, s2s_train_dset, s2s_valid_dset, s2s_args)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3acd4131f7b4eeba32f498dc4ac27f2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0497a2a67e394c30b5a47d941d515153",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7eba9b43a2649cbaeab6574794f744e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a91029969afe47bc88055da77464fede",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b3646b526814cc3824360dfe340de66",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2c7ff66f8a44b5faeff6b82133d0705",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0     0 of  4570 \t L: 1.000 \t -- 0.708\n",
            " 0     1 of  4570 \t L: 1.000 \t -- 1.228\n",
            " 0   100 of  4570 \t L: 1.000 \t -- 55.804\n",
            " 0   200 of  4570 \t L: 1.000 \t -- 112.262\n",
            " 0   300 of  4570 \t L: 1.000 \t -- 168.675\n",
            " 0   400 of  4570 \t L: 1.000 \t -- 226.245\n",
            " 0   500 of  4570 \t L: 1.000 \t -- 283.617\n",
            " 0   600 of  4570 \t L: 1.000 \t -- 341.312\n",
            " 0   700 of  4570 \t L: 1.000 \t -- 397.916\n",
            " 0   800 of  4570 \t L: 1.000 \t -- 454.350\n",
            " 0   900 of  4570 \t L: 1.000 \t -- 511.381\n",
            " 0  1000 of  4570 \t L: 1.000 \t -- 568.925\n",
            " 0  1100 of  4570 \t L: 1.000 \t -- 625.586\n",
            " 0  1200 of  4570 \t L: 1.000 \t -- 682.082\n",
            " 0  1300 of  4570 \t L: 1.000 \t -- 738.325\n",
            " 0  1400 of  4570 \t L: 1.000 \t -- 795.237\n",
            " 0  1500 of  4570 \t L: 1.000 \t -- 852.131\n",
            " 0  1600 of  4570 \t L: 1.000 \t -- 910.072\n",
            " 0  1700 of  4570 \t L: 1.000 \t -- 967.810\n",
            " 0  1800 of  4570 \t L: 1.000 \t -- 1024.755\n",
            " 0  1900 of  4570 \t L: 1.000 \t -- 1081.397\n",
            " 0  2000 of  4570 \t L: 1.000 \t -- 1139.332\n",
            " 0  2100 of  4570 \t L: 1.000 \t -- 1196.711\n",
            " 0  2200 of  4570 \t L: 1.000 \t -- 1253.074\n",
            " 0  2300 of  4570 \t L: 1.000 \t -- 1310.575\n",
            " 0  2400 of  4570 \t L: 1.000 \t -- 1367.119\n",
            " 0  2500 of  4570 \t L: 1.000 \t -- 1424.587\n",
            " 0  2600 of  4570 \t L: 1.000 \t -- 1482.042\n",
            " 0  2700 of  4570 \t L: 1.000 \t -- 1538.215\n",
            " 0  2800 of  4570 \t L: 1.000 \t -- 1595.013\n",
            " 0  2900 of  4570 \t L: 1.000 \t -- 1652.871\n",
            " 0  3000 of  4570 \t L: 1.000 \t -- 1710.774\n",
            " 0  3100 of  4570 \t L: 1.000 \t -- 1768.805\n",
            " 0  3200 of  4570 \t L: 1.000 \t -- 1826.758\n",
            " 0  3300 of  4570 \t L: 1.000 \t -- 1884.218\n",
            " 0  3400 of  4570 \t L: 1.000 \t -- 1941.722\n",
            " 0  3500 of  4570 \t L: 1.000 \t -- 1999.713\n",
            " 0  3600 of  4570 \t L: 1.000 \t -- 2057.720\n",
            " 0  3700 of  4570 \t L: 1.000 \t -- 2115.460\n",
            " 0  3800 of  4570 \t L: 1.000 \t -- 2173.378\n",
            " 0  3900 of  4570 \t L: 1.000 \t -- 2230.607\n",
            " 0  4000 of  4570 \t L: 1.000 \t -- 2287.723\n",
            " 0  4100 of  4570 \t L: 1.000 \t -- 2344.978\n",
            " 0  4200 of  4570 \t L: 1.000 \t -- 2402.461\n",
            " 0  4300 of  4570 \t L: 1.000 \t -- 2459.563\n",
            " 0  4400 of  4570 \t L: 1.000 \t -- 2517.357\n",
            " 0  4500 of  4570 \t L: 1.000 \t -- 2574.605\n",
            "Saving model eli5_bart_model\n",
            "tensor(3.1535, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1535, device='cuda:0') sum\n",
            "loc loss here 0.9999999403953552\n",
            "    0 of  1143 \t L: 1.000 \t -- 0.227\n",
            "tensor(3.2013, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2013, device='cuda:0') sum\n",
            "loc loss here 1.9999999403953552\n",
            "tensor(3.5476, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5476, device='cuda:0') sum\n",
            "loc loss here 2.9999999403953552\n",
            "tensor(3.6166, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6166, device='cuda:0') sum\n",
            "loc loss here 3.9999998807907104\n",
            "tensor(3.7034, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7034, device='cuda:0') sum\n",
            "loc loss here 4.999999821186066\n",
            "tensor(2.7285, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7285, device='cuda:0') sum\n",
            "loc loss here 5.999999821186066\n",
            "tensor(3.3907, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3907, device='cuda:0') sum\n",
            "loc loss here 6.999999821186066\n",
            "tensor(2.1344, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.1344, device='cuda:0') sum\n",
            "loc loss here 7.999999821186066\n",
            "tensor(2.2792, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2792, device='cuda:0') sum\n",
            "loc loss here 8.999999821186066\n",
            "tensor(3.4688, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4688, device='cuda:0') sum\n",
            "loc loss here 9.999999821186066\n",
            "tensor(3.4658, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4658, device='cuda:0') sum\n",
            "loc loss here 10.999999821186066\n",
            "tensor(3.8151, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8151, device='cuda:0') sum\n",
            "loc loss here 11.999999821186066\n",
            "tensor(2.0733, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.0733, device='cuda:0') sum\n",
            "loc loss here 12.999999821186066\n",
            "tensor(1.9373, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.9373, device='cuda:0') sum\n",
            "loc loss here 13.999999821186066\n",
            "tensor(4.0021, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0021, device='cuda:0') sum\n",
            "loc loss here 14.999999821186066\n",
            "tensor(3.5407, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5407, device='cuda:0') sum\n",
            "loc loss here 15.999999761581421\n",
            "tensor(3.6291, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6291, device='cuda:0') sum\n",
            "loc loss here 16.99999976158142\n",
            "tensor(3.9334, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9334, device='cuda:0') sum\n",
            "loc loss here 17.999999701976776\n",
            "tensor(2.4804, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4804, device='cuda:0') sum\n",
            "loc loss here 18.999999701976776\n",
            "tensor(4.5709, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5709, device='cuda:0') sum\n",
            "loc loss here 19.999999701976776\n",
            "tensor(3.3811, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3811, device='cuda:0') sum\n",
            "loc loss here 20.999999701976776\n",
            "tensor(2.5950, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5950, device='cuda:0') sum\n",
            "loc loss here 21.999999701976776\n",
            "tensor(3.5970, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5970, device='cuda:0') sum\n",
            "loc loss here 22.999999701976776\n",
            "tensor(3.6717, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6717, device='cuda:0') sum\n",
            "loc loss here 23.99999964237213\n",
            "tensor(3.7857, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7857, device='cuda:0') sum\n",
            "loc loss here 24.99999964237213\n",
            "tensor(2.0706, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.0706, device='cuda:0') sum\n",
            "loc loss here 25.99999964237213\n",
            "tensor(4.0520, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0520, device='cuda:0') sum\n",
            "loc loss here 26.99999964237213\n",
            "tensor(3.6636, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6636, device='cuda:0') sum\n",
            "loc loss here 27.99999964237213\n",
            "tensor(2.6958, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6958, device='cuda:0') sum\n",
            "loc loss here 28.99999964237213\n",
            "tensor(2.6792, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6792, device='cuda:0') sum\n",
            "loc loss here 29.99999964237213\n",
            "tensor(4.2116, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2116, device='cuda:0') sum\n",
            "loc loss here 30.99999964237213\n",
            "tensor(4.1839, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1839, device='cuda:0') sum\n",
            "loc loss here 31.99999964237213\n",
            "tensor(5.3624, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.3624, device='cuda:0') sum\n",
            "loc loss here 32.99999964237213\n",
            "tensor(2.7765, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7765, device='cuda:0') sum\n",
            "loc loss here 33.99999964237213\n",
            "tensor(3.1740, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1740, device='cuda:0') sum\n",
            "loc loss here 34.99999964237213\n",
            "tensor(2.7871, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7871, device='cuda:0') sum\n",
            "loc loss here 35.99999964237213\n",
            "tensor(3.9127, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9127, device='cuda:0') sum\n",
            "loc loss here 36.99999964237213\n",
            "tensor(3.3415, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3415, device='cuda:0') sum\n",
            "loc loss here 37.99999964237213\n",
            "tensor(3.4133, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4133, device='cuda:0') sum\n",
            "loc loss here 38.99999964237213\n",
            "tensor(3.5605, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5605, device='cuda:0') sum\n",
            "loc loss here 39.99999964237213\n",
            "tensor(3.4948, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4948, device='cuda:0') sum\n",
            "loc loss here 40.99999964237213\n",
            "tensor(3.5388, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5388, device='cuda:0') sum\n",
            "loc loss here 41.99999964237213\n",
            "tensor(4.0244, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0244, device='cuda:0') sum\n",
            "loc loss here 42.99999964237213\n",
            "tensor(4.2173, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2173, device='cuda:0') sum\n",
            "loc loss here 43.99999964237213\n",
            "tensor(2.6097, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6097, device='cuda:0') sum\n",
            "loc loss here 44.99999964237213\n",
            "tensor(2.1312, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.1312, device='cuda:0') sum\n",
            "loc loss here 45.99999964237213\n",
            "tensor(3.3444, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3444, device='cuda:0') sum\n",
            "loc loss here 46.99999964237213\n",
            "tensor(2.2482, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2482, device='cuda:0') sum\n",
            "loc loss here 47.99999964237213\n",
            "tensor(3.8223, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8223, device='cuda:0') sum\n",
            "loc loss here 48.99999964237213\n",
            "tensor(3.6758, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6758, device='cuda:0') sum\n",
            "loc loss here 49.99999964237213\n",
            "tensor(3.6559, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6559, device='cuda:0') sum\n",
            "loc loss here 50.99999964237213\n",
            "tensor(3.6652, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6652, device='cuda:0') sum\n",
            "loc loss here 51.99999964237213\n",
            "tensor(3.0829, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0829, device='cuda:0') sum\n",
            "loc loss here 52.99999958276749\n",
            "tensor(3.9586, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9586, device='cuda:0') sum\n",
            "loc loss here 53.99999958276749\n",
            "tensor(2.3635, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3635, device='cuda:0') sum\n",
            "loc loss here 54.99999958276749\n",
            "tensor(2.7076, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7076, device='cuda:0') sum\n",
            "loc loss here 55.99999958276749\n",
            "tensor(2.4558, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4558, device='cuda:0') sum\n",
            "loc loss here 56.99999958276749\n",
            "tensor(3.6898, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6898, device='cuda:0') sum\n",
            "loc loss here 57.99999958276749\n",
            "tensor(3.8092, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8092, device='cuda:0') sum\n",
            "loc loss here 58.99999958276749\n",
            "tensor(3.9913, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9913, device='cuda:0') sum\n",
            "loc loss here 59.99999958276749\n",
            "tensor(4.3359, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3359, device='cuda:0') sum\n",
            "loc loss here 60.99999958276749\n",
            "tensor(1.7283, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.7283, device='cuda:0') sum\n",
            "loc loss here 61.99999958276749\n",
            "tensor(2.6400, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6400, device='cuda:0') sum\n",
            "loc loss here 62.99999958276749\n",
            "tensor(2.7420, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7420, device='cuda:0') sum\n",
            "loc loss here 63.99999958276749\n",
            "tensor(3.3855, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3855, device='cuda:0') sum\n",
            "loc loss here 64.99999952316284\n",
            "tensor(4.1066, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1066, device='cuda:0') sum\n",
            "loc loss here 65.99999952316284\n",
            "tensor(2.4890, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4890, device='cuda:0') sum\n",
            "loc loss here 66.99999952316284\n",
            "tensor(3.7651, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7651, device='cuda:0') sum\n",
            "loc loss here 67.99999952316284\n",
            "tensor(2.8535, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8535, device='cuda:0') sum\n",
            "loc loss here 68.99999952316284\n",
            "tensor(3.5858, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5858, device='cuda:0') sum\n",
            "loc loss here 69.99999952316284\n",
            "tensor(3.0699, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0699, device='cuda:0') sum\n",
            "loc loss here 70.99999952316284\n",
            "tensor(3.6366, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6366, device='cuda:0') sum\n",
            "loc loss here 71.99999952316284\n",
            "tensor(4.0128, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0128, device='cuda:0') sum\n",
            "loc loss here 72.99999952316284\n",
            "tensor(2.6779, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6779, device='cuda:0') sum\n",
            "loc loss here 73.99999952316284\n",
            "tensor(3.0647, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0647, device='cuda:0') sum\n",
            "loc loss here 74.99999952316284\n",
            "tensor(1.5103, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.5103, device='cuda:0') sum\n",
            "loc loss here 75.99999952316284\n",
            "tensor(3.4755, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4755, device='cuda:0') sum\n",
            "loc loss here 76.99999952316284\n",
            "tensor(3.3832, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3832, device='cuda:0') sum\n",
            "loc loss here 77.9999994635582\n",
            "tensor(2.4585, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4585, device='cuda:0') sum\n",
            "loc loss here 78.9999994635582\n",
            "tensor(3.5555, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5555, device='cuda:0') sum\n",
            "loc loss here 79.9999994635582\n",
            "tensor(2.7532, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7532, device='cuda:0') sum\n",
            "loc loss here 80.99999940395355\n",
            "tensor(3.2158, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2158, device='cuda:0') sum\n",
            "loc loss here 81.99999940395355\n",
            "tensor(2.8338, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8338, device='cuda:0') sum\n",
            "loc loss here 82.99999940395355\n",
            "tensor(2.5396, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5396, device='cuda:0') sum\n",
            "loc loss here 83.99999940395355\n",
            "tensor(2.8702, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8702, device='cuda:0') sum\n",
            "loc loss here 84.99999940395355\n",
            "tensor(1.6806, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.6806, device='cuda:0') sum\n",
            "loc loss here 85.99999940395355\n",
            "tensor(3.1553, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1553, device='cuda:0') sum\n",
            "loc loss here 86.99999940395355\n",
            "tensor(3.2689, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2689, device='cuda:0') sum\n",
            "loc loss here 87.99999940395355\n",
            "tensor(3.8625, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8625, device='cuda:0') sum\n",
            "loc loss here 88.99999940395355\n",
            "tensor(3.1001, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1001, device='cuda:0') sum\n",
            "loc loss here 89.99999940395355\n",
            "tensor(2.3049, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3049, device='cuda:0') sum\n",
            "loc loss here 90.99999940395355\n",
            "tensor(3.7645, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7645, device='cuda:0') sum\n",
            "loc loss here 91.99999940395355\n",
            "tensor(3.0889, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0889, device='cuda:0') sum\n",
            "loc loss here 92.99999940395355\n",
            "tensor(2.0459, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.0459, device='cuda:0') sum\n",
            "loc loss here 93.99999940395355\n",
            "tensor(3.1885, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1885, device='cuda:0') sum\n",
            "loc loss here 94.99999940395355\n",
            "tensor(3.4482, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4482, device='cuda:0') sum\n",
            "loc loss here 95.99999940395355\n",
            "tensor(3.3283, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3283, device='cuda:0') sum\n",
            "loc loss here 96.99999940395355\n",
            "tensor(4.2418, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2418, device='cuda:0') sum\n",
            "loc loss here 97.99999940395355\n",
            "tensor(4.6144, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.6144, device='cuda:0') sum\n",
            "loc loss here 98.99999940395355\n",
            "tensor(2.3158, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3158, device='cuda:0') sum\n",
            "loc loss here 99.99999940395355\n",
            "tensor(3.1798, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1798, device='cuda:0') sum\n",
            "loc loss here 100.99999940395355\n",
            "  100 of  1143 \t L: 1.000 \t -- 21.174\n",
            "tensor(2.3440, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3440, device='cuda:0') sum\n",
            "loc loss here 101.99999940395355\n",
            "tensor(4.4463, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.4463, device='cuda:0') sum\n",
            "loc loss here 102.99999940395355\n",
            "tensor(3.1116, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1116, device='cuda:0') sum\n",
            "loc loss here 103.99999934434891\n",
            "tensor(3.1263, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1263, device='cuda:0') sum\n",
            "loc loss here 104.99999934434891\n",
            "tensor(3.3884, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3884, device='cuda:0') sum\n",
            "loc loss here 105.99999934434891\n",
            "tensor(3.6383, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6383, device='cuda:0') sum\n",
            "loc loss here 106.99999934434891\n",
            "tensor(2.6852, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6852, device='cuda:0') sum\n",
            "loc loss here 107.99999934434891\n",
            "tensor(3.4261, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4261, device='cuda:0') sum\n",
            "loc loss here 108.99999934434891\n",
            "tensor(3.8903, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8903, device='cuda:0') sum\n",
            "loc loss here 109.99999928474426\n",
            "tensor(1.5903, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.5903, device='cuda:0') sum\n",
            "loc loss here 110.99999928474426\n",
            "tensor(3.6069, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6069, device='cuda:0') sum\n",
            "loc loss here 111.99999922513962\n",
            "tensor(3.8774, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8774, device='cuda:0') sum\n",
            "loc loss here 112.99999922513962\n",
            "tensor(2.0054, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.0054, device='cuda:0') sum\n",
            "loc loss here 113.99999922513962\n",
            "tensor(3.6556, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6556, device='cuda:0') sum\n",
            "loc loss here 114.99999922513962\n",
            "tensor(3.4481, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4481, device='cuda:0') sum\n",
            "loc loss here 115.99999922513962\n",
            "tensor(3.2743, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2743, device='cuda:0') sum\n",
            "loc loss here 116.99999916553497\n",
            "tensor(3.1324, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1324, device='cuda:0') sum\n",
            "loc loss here 117.99999910593033\n",
            "tensor(3.1099, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1099, device='cuda:0') sum\n",
            "loc loss here 118.99999910593033\n",
            "tensor(3.4197, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4197, device='cuda:0') sum\n",
            "loc loss here 119.99999904632568\n",
            "tensor(4.3122, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3122, device='cuda:0') sum\n",
            "loc loss here 120.99999904632568\n",
            "tensor(3.3891, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3891, device='cuda:0') sum\n",
            "loc loss here 121.99999904632568\n",
            "tensor(4.0781, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0781, device='cuda:0') sum\n",
            "loc loss here 122.99999904632568\n",
            "tensor(3.0303, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0303, device='cuda:0') sum\n",
            "loc loss here 123.99999904632568\n",
            "tensor(3.7636, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7636, device='cuda:0') sum\n",
            "loc loss here 124.99999904632568\n",
            "tensor(1.4182, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.4182, device='cuda:0') sum\n",
            "loc loss here 125.99999904632568\n",
            "tensor(3.9868, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9868, device='cuda:0') sum\n",
            "loc loss here 126.99999904632568\n",
            "tensor(2.8492, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8492, device='cuda:0') sum\n",
            "loc loss here 127.99999904632568\n",
            "tensor(2.6549, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6549, device='cuda:0') sum\n",
            "loc loss here 128.99999904632568\n",
            "tensor(5.6875, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.6875, device='cuda:0') sum\n",
            "loc loss here 129.99999904632568\n",
            "tensor(2.8336, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8336, device='cuda:0') sum\n",
            "loc loss here 130.99999904632568\n",
            "tensor(3.2159, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2159, device='cuda:0') sum\n",
            "loc loss here 131.99999904632568\n",
            "tensor(4.0307, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0307, device='cuda:0') sum\n",
            "loc loss here 132.99999904632568\n",
            "tensor(3.5176, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5176, device='cuda:0') sum\n",
            "loc loss here 133.99999898672104\n",
            "tensor(3.1575, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1575, device='cuda:0') sum\n",
            "loc loss here 134.99999898672104\n",
            "tensor(3.9306, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9306, device='cuda:0') sum\n",
            "loc loss here 135.99999898672104\n",
            "tensor(2.9699, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9699, device='cuda:0') sum\n",
            "loc loss here 136.99999898672104\n",
            "tensor(2.7470, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7470, device='cuda:0') sum\n",
            "loc loss here 137.9999989271164\n",
            "tensor(2.8293, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8293, device='cuda:0') sum\n",
            "loc loss here 138.9999989271164\n",
            "tensor(3.4872, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4872, device='cuda:0') sum\n",
            "loc loss here 139.99999886751175\n",
            "tensor(3.2437, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2437, device='cuda:0') sum\n",
            "loc loss here 140.9999988079071\n",
            "tensor(2.9509, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9509, device='cuda:0') sum\n",
            "loc loss here 141.9999988079071\n",
            "tensor(3.7309, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7309, device='cuda:0') sum\n",
            "loc loss here 142.9999988079071\n",
            "tensor(3.5884, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5884, device='cuda:0') sum\n",
            "loc loss here 143.9999988079071\n",
            "tensor(3.4314, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4314, device='cuda:0') sum\n",
            "loc loss here 144.9999988079071\n",
            "tensor(3.5036, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5036, device='cuda:0') sum\n",
            "loc loss here 145.9999988079071\n",
            "tensor(2.5933, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5933, device='cuda:0') sum\n",
            "loc loss here 146.9999988079071\n",
            "tensor(2.4599, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4599, device='cuda:0') sum\n",
            "loc loss here 147.9999988079071\n",
            "tensor(3.6214, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6214, device='cuda:0') sum\n",
            "loc loss here 148.9999988079071\n",
            "tensor(2.7555, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7555, device='cuda:0') sum\n",
            "loc loss here 149.9999988079071\n",
            "tensor(3.6530, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6530, device='cuda:0') sum\n",
            "loc loss here 150.9999988079071\n",
            "tensor(3.6654, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6654, device='cuda:0') sum\n",
            "loc loss here 151.9999988079071\n",
            "tensor(3.3599, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3599, device='cuda:0') sum\n",
            "loc loss here 152.99999874830246\n",
            "tensor(4.5069, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5069, device='cuda:0') sum\n",
            "loc loss here 153.99999874830246\n",
            "tensor(3.4113, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4113, device='cuda:0') sum\n",
            "loc loss here 154.99999874830246\n",
            "tensor(3.5594, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5594, device='cuda:0') sum\n",
            "loc loss here 155.99999874830246\n",
            "tensor(2.5739, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5739, device='cuda:0') sum\n",
            "loc loss here 156.99999874830246\n",
            "tensor(4.1564, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1564, device='cuda:0') sum\n",
            "loc loss here 157.99999874830246\n",
            "tensor(3.6459, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6459, device='cuda:0') sum\n",
            "loc loss here 158.99999874830246\n",
            "tensor(3.4746, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4746, device='cuda:0') sum\n",
            "loc loss here 159.99999874830246\n",
            "tensor(3.1177, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1177, device='cuda:0') sum\n",
            "loc loss here 160.99999874830246\n",
            "tensor(3.1808, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1808, device='cuda:0') sum\n",
            "loc loss here 161.99999874830246\n",
            "tensor(4.0546, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0546, device='cuda:0') sum\n",
            "loc loss here 162.99999874830246\n",
            "tensor(3.4386, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4386, device='cuda:0') sum\n",
            "loc loss here 163.99999874830246\n",
            "tensor(3.1688, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1688, device='cuda:0') sum\n",
            "loc loss here 164.99999874830246\n",
            "tensor(3.1883, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1883, device='cuda:0') sum\n",
            "loc loss here 165.99999874830246\n",
            "tensor(3.0941, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0941, device='cuda:0') sum\n",
            "loc loss here 166.99999868869781\n",
            "tensor(3.5515, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5515, device='cuda:0') sum\n",
            "loc loss here 167.99999862909317\n",
            "tensor(3.9284, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9284, device='cuda:0') sum\n",
            "loc loss here 168.99999862909317\n",
            "tensor(2.7062, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7062, device='cuda:0') sum\n",
            "loc loss here 169.99999862909317\n",
            "tensor(3.9731, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9731, device='cuda:0') sum\n",
            "loc loss here 170.99999862909317\n",
            "tensor(3.9246, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9246, device='cuda:0') sum\n",
            "loc loss here 171.99999862909317\n",
            "tensor(5.1634, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.1634, device='cuda:0') sum\n",
            "loc loss here 172.99999862909317\n",
            "tensor(5.3169, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.3169, device='cuda:0') sum\n",
            "loc loss here 173.99999862909317\n",
            "tensor(4.1606, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1606, device='cuda:0') sum\n",
            "loc loss here 174.99999862909317\n",
            "tensor(3.8050, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8050, device='cuda:0') sum\n",
            "loc loss here 175.99999862909317\n",
            "tensor(1.5052, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.5052, device='cuda:0') sum\n",
            "loc loss here 176.99999862909317\n",
            "tensor(3.2023, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2023, device='cuda:0') sum\n",
            "loc loss here 177.99999862909317\n",
            "tensor(3.0311, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0311, device='cuda:0') sum\n",
            "loc loss here 178.99999862909317\n",
            "tensor(4.2950, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2950, device='cuda:0') sum\n",
            "loc loss here 179.99999862909317\n",
            "tensor(2.6689, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6689, device='cuda:0') sum\n",
            "loc loss here 180.99999856948853\n",
            "tensor(3.8184, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8184, device='cuda:0') sum\n",
            "loc loss here 181.99999856948853\n",
            "tensor(2.5487, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5487, device='cuda:0') sum\n",
            "loc loss here 182.99999856948853\n",
            "tensor(3.5125, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5125, device='cuda:0') sum\n",
            "loc loss here 183.99999856948853\n",
            "tensor(2.1717, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.1717, device='cuda:0') sum\n",
            "loc loss here 184.99999856948853\n",
            "tensor(4.3382, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3382, device='cuda:0') sum\n",
            "loc loss here 185.99999856948853\n",
            "tensor(3.1320, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1320, device='cuda:0') sum\n",
            "loc loss here 186.99999850988388\n",
            "tensor(1.8168, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.8168, device='cuda:0') sum\n",
            "loc loss here 187.99999850988388\n",
            "tensor(3.3861, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3861, device='cuda:0') sum\n",
            "loc loss here 188.99999850988388\n",
            "tensor(3.5229, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5229, device='cuda:0') sum\n",
            "loc loss here 189.99999845027924\n",
            "tensor(2.8998, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8998, device='cuda:0') sum\n",
            "loc loss here 190.9999983906746\n",
            "tensor(4.6532, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.6532, device='cuda:0') sum\n",
            "loc loss here 191.99999833106995\n",
            "tensor(3.2736, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2736, device='cuda:0') sum\n",
            "loc loss here 192.99999833106995\n",
            "tensor(3.8979, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8979, device='cuda:0') sum\n",
            "loc loss here 193.99999833106995\n",
            "tensor(3.8625, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8625, device='cuda:0') sum\n",
            "loc loss here 194.99999833106995\n",
            "tensor(3.6201, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6201, device='cuda:0') sum\n",
            "loc loss here 195.99999833106995\n",
            "tensor(2.4704, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4704, device='cuda:0') sum\n",
            "loc loss here 196.99999833106995\n",
            "tensor(3.1595, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1595, device='cuda:0') sum\n",
            "loc loss here 197.9999982714653\n",
            "tensor(4.2026, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2026, device='cuda:0') sum\n",
            "loc loss here 198.9999982714653\n",
            "tensor(5.2262, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.2262, device='cuda:0') sum\n",
            "loc loss here 199.9999982714653\n",
            "tensor(3.0195, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0195, device='cuda:0') sum\n",
            "loc loss here 200.9999982714653\n",
            "  200 of  1143 \t L: 1.000 \t -- 42.506\n",
            "tensor(4.1148, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1148, device='cuda:0') sum\n",
            "loc loss here 201.9999982714653\n",
            "tensor(3.9164, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9164, device='cuda:0') sum\n",
            "loc loss here 202.9999982714653\n",
            "tensor(3.3864, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3864, device='cuda:0') sum\n",
            "loc loss here 203.9999982714653\n",
            "tensor(3.0888, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0888, device='cuda:0') sum\n",
            "loc loss here 204.9999982714653\n",
            "tensor(5.3395, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.3395, device='cuda:0') sum\n",
            "loc loss here 205.9999982714653\n",
            "tensor(4.1407, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1407, device='cuda:0') sum\n",
            "loc loss here 206.9999982714653\n",
            "tensor(3.7931, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7931, device='cuda:0') sum\n",
            "loc loss here 207.9999982714653\n",
            "tensor(4.3025, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3025, device='cuda:0') sum\n",
            "loc loss here 208.9999982714653\n",
            "tensor(3.4647, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4647, device='cuda:0') sum\n",
            "loc loss here 209.9999982714653\n",
            "tensor(2.6291, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6291, device='cuda:0') sum\n",
            "loc loss here 210.9999982714653\n",
            "tensor(3.5895, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5895, device='cuda:0') sum\n",
            "loc loss here 211.9999982714653\n",
            "tensor(3.6328, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6328, device='cuda:0') sum\n",
            "loc loss here 212.9999982714653\n",
            "tensor(1.5326, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.5326, device='cuda:0') sum\n",
            "loc loss here 213.9999982714653\n",
            "tensor(2.7908, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7908, device='cuda:0') sum\n",
            "loc loss here 214.9999982714653\n",
            "tensor(3.6835, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6835, device='cuda:0') sum\n",
            "loc loss here 215.99999821186066\n",
            "tensor(4.9119, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.9119, device='cuda:0') sum\n",
            "loc loss here 216.99999821186066\n",
            "tensor(3.2516, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2516, device='cuda:0') sum\n",
            "loc loss here 217.99999821186066\n",
            "tensor(4.5644, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5644, device='cuda:0') sum\n",
            "loc loss here 218.99999821186066\n",
            "tensor(3.2277, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2277, device='cuda:0') sum\n",
            "loc loss here 219.99999821186066\n",
            "tensor(2.9545, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9545, device='cuda:0') sum\n",
            "loc loss here 220.99999821186066\n",
            "tensor(4.0748, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0748, device='cuda:0') sum\n",
            "loc loss here 221.99999821186066\n",
            "tensor(2.2553, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2553, device='cuda:0') sum\n",
            "loc loss here 222.99999821186066\n",
            "tensor(1.8619, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.8619, device='cuda:0') sum\n",
            "loc loss here 223.99999821186066\n",
            "tensor(4.2360, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2360, device='cuda:0') sum\n",
            "loc loss here 224.99999821186066\n",
            "tensor(2.4806, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4806, device='cuda:0') sum\n",
            "loc loss here 225.99999821186066\n",
            "tensor(2.7946, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7946, device='cuda:0') sum\n",
            "loc loss here 226.999998152256\n",
            "tensor(4.2612, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2612, device='cuda:0') sum\n",
            "loc loss here 227.999998152256\n",
            "tensor(3.7174, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7174, device='cuda:0') sum\n",
            "loc loss here 228.999998152256\n",
            "tensor(3.2333, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2333, device='cuda:0') sum\n",
            "loc loss here 229.999998152256\n",
            "tensor(5.0108, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.0108, device='cuda:0') sum\n",
            "loc loss here 230.999998152256\n",
            "tensor(3.7633, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7633, device='cuda:0') sum\n",
            "loc loss here 231.999998152256\n",
            "tensor(2.7853, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7853, device='cuda:0') sum\n",
            "loc loss here 232.999998152256\n",
            "tensor(3.9284, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9284, device='cuda:0') sum\n",
            "loc loss here 233.999998152256\n",
            "tensor(3.1282, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1282, device='cuda:0') sum\n",
            "loc loss here 234.999998152256\n",
            "tensor(3.3930, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3930, device='cuda:0') sum\n",
            "loc loss here 235.999998152256\n",
            "tensor(3.9241, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9241, device='cuda:0') sum\n",
            "loc loss here 236.999998152256\n",
            "tensor(3.3424, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3424, device='cuda:0') sum\n",
            "loc loss here 237.999998152256\n",
            "tensor(2.1859, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.1859, device='cuda:0') sum\n",
            "loc loss here 238.999998152256\n",
            "tensor(2.2925, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2925, device='cuda:0') sum\n",
            "loc loss here 239.999998152256\n",
            "tensor(3.6899, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6899, device='cuda:0') sum\n",
            "loc loss here 240.999998152256\n",
            "tensor(4.5598, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5598, device='cuda:0') sum\n",
            "loc loss here 241.999998152256\n",
            "tensor(3.3820, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3820, device='cuda:0') sum\n",
            "loc loss here 242.99999809265137\n",
            "tensor(3.2401, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2401, device='cuda:0') sum\n",
            "loc loss here 243.99999809265137\n",
            "tensor(3.9193, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9193, device='cuda:0') sum\n",
            "loc loss here 244.99999803304672\n",
            "tensor(3.0692, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0692, device='cuda:0') sum\n",
            "loc loss here 245.99999803304672\n",
            "tensor(2.6419, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6419, device='cuda:0') sum\n",
            "loc loss here 246.99999803304672\n",
            "tensor(3.3568, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3568, device='cuda:0') sum\n",
            "loc loss here 247.99999803304672\n",
            "tensor(4.1920, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1920, device='cuda:0') sum\n",
            "loc loss here 248.99999803304672\n",
            "tensor(3.2059, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2059, device='cuda:0') sum\n",
            "loc loss here 249.99999803304672\n",
            "tensor(3.1662, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1662, device='cuda:0') sum\n",
            "loc loss here 250.99999803304672\n",
            "tensor(4.0879, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0879, device='cuda:0') sum\n",
            "loc loss here 251.99999803304672\n",
            "tensor(2.5535, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5535, device='cuda:0') sum\n",
            "loc loss here 252.99999803304672\n",
            "tensor(3.6212, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6212, device='cuda:0') sum\n",
            "loc loss here 253.99999803304672\n",
            "tensor(3.9077, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9077, device='cuda:0') sum\n",
            "loc loss here 254.99999797344208\n",
            "tensor(3.7107, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7107, device='cuda:0') sum\n",
            "loc loss here 255.99999797344208\n",
            "tensor(2.8854, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8854, device='cuda:0') sum\n",
            "loc loss here 256.9999979734421\n",
            "tensor(4.3752, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3752, device='cuda:0') sum\n",
            "loc loss here 257.99999791383743\n",
            "tensor(4.1082, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1082, device='cuda:0') sum\n",
            "loc loss here 258.99999791383743\n",
            "tensor(2.3880, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3880, device='cuda:0') sum\n",
            "loc loss here 259.99999791383743\n",
            "tensor(3.1376, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1376, device='cuda:0') sum\n",
            "loc loss here 260.99999791383743\n",
            "tensor(1.4683, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.4683, device='cuda:0') sum\n",
            "loc loss here 261.99999791383743\n",
            "tensor(3.4126, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4126, device='cuda:0') sum\n",
            "loc loss here 262.99999791383743\n",
            "tensor(3.8120, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8120, device='cuda:0') sum\n",
            "loc loss here 263.99999791383743\n",
            "tensor(2.0787, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.0787, device='cuda:0') sum\n",
            "loc loss here 264.99999791383743\n",
            "tensor(3.8529, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8529, device='cuda:0') sum\n",
            "loc loss here 265.99999791383743\n",
            "tensor(3.1009, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1009, device='cuda:0') sum\n",
            "loc loss here 266.99999791383743\n",
            "tensor(3.1269, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1269, device='cuda:0') sum\n",
            "loc loss here 267.99999791383743\n",
            "tensor(1.3737, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.3737, device='cuda:0') sum\n",
            "loc loss here 268.99999791383743\n",
            "tensor(2.9928, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9928, device='cuda:0') sum\n",
            "loc loss here 269.9999978542328\n",
            "tensor(3.9256, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9256, device='cuda:0') sum\n",
            "loc loss here 270.9999978542328\n",
            "tensor(3.1697, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1697, device='cuda:0') sum\n",
            "loc loss here 271.99999779462814\n",
            "tensor(3.7085, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7085, device='cuda:0') sum\n",
            "loc loss here 272.99999779462814\n",
            "tensor(2.8581, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8581, device='cuda:0') sum\n",
            "loc loss here 273.99999779462814\n",
            "tensor(2.8290, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8290, device='cuda:0') sum\n",
            "loc loss here 274.99999779462814\n",
            "tensor(2.9230, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9230, device='cuda:0') sum\n",
            "loc loss here 275.99999779462814\n",
            "tensor(3.4247, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4247, device='cuda:0') sum\n",
            "loc loss here 276.9999977350235\n",
            "tensor(4.0482, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0482, device='cuda:0') sum\n",
            "loc loss here 277.9999977350235\n",
            "tensor(3.4432, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4432, device='cuda:0') sum\n",
            "loc loss here 278.99999767541885\n",
            "tensor(4.7102, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.7102, device='cuda:0') sum\n",
            "loc loss here 279.99999767541885\n",
            "tensor(3.4799, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4799, device='cuda:0') sum\n",
            "loc loss here 280.9999976158142\n",
            "tensor(4.2700, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2700, device='cuda:0') sum\n",
            "loc loss here 281.9999976158142\n",
            "tensor(4.0851, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0851, device='cuda:0') sum\n",
            "loc loss here 282.9999976158142\n",
            "tensor(3.9701, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9701, device='cuda:0') sum\n",
            "loc loss here 283.9999976158142\n",
            "tensor(3.2403, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2403, device='cuda:0') sum\n",
            "loc loss here 284.9999976158142\n",
            "tensor(3.3575, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3575, device='cuda:0') sum\n",
            "loc loss here 285.99999755620956\n",
            "tensor(3.2787, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2787, device='cuda:0') sum\n",
            "loc loss here 286.99999755620956\n",
            "tensor(4.4771, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.4771, device='cuda:0') sum\n",
            "loc loss here 287.99999755620956\n",
            "tensor(4.6363, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.6363, device='cuda:0') sum\n",
            "loc loss here 288.99999755620956\n",
            "tensor(2.1453, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.1453, device='cuda:0') sum\n",
            "loc loss here 289.99999755620956\n",
            "tensor(4.6498, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.6498, device='cuda:0') sum\n",
            "loc loss here 290.99999755620956\n",
            "tensor(3.2688, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2688, device='cuda:0') sum\n",
            "loc loss here 291.99999755620956\n",
            "tensor(3.8174, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8174, device='cuda:0') sum\n",
            "loc loss here 292.9999974966049\n",
            "tensor(4.0522, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0522, device='cuda:0') sum\n",
            "loc loss here 293.9999974966049\n",
            "tensor(2.0449, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.0449, device='cuda:0') sum\n",
            "loc loss here 294.9999974966049\n",
            "tensor(2.4304, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4304, device='cuda:0') sum\n",
            "loc loss here 295.9999974370003\n",
            "tensor(4.0078, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0078, device='cuda:0') sum\n",
            "loc loss here 296.9999974370003\n",
            "tensor(4.1409, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1409, device='cuda:0') sum\n",
            "loc loss here 297.9999974370003\n",
            "tensor(2.5435, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5435, device='cuda:0') sum\n",
            "loc loss here 298.9999974370003\n",
            "tensor(3.7997, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7997, device='cuda:0') sum\n",
            "loc loss here 299.9999974370003\n",
            "tensor(1.6450, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.6450, device='cuda:0') sum\n",
            "loc loss here 300.9999974370003\n",
            "  300 of  1143 \t L: 1.000 \t -- 63.049\n",
            "tensor(4.2253, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2253, device='cuda:0') sum\n",
            "loc loss here 301.9999974370003\n",
            "tensor(2.7569, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7569, device='cuda:0') sum\n",
            "loc loss here 302.9999974370003\n",
            "tensor(3.1793, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1793, device='cuda:0') sum\n",
            "loc loss here 303.9999974370003\n",
            "tensor(2.7050, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7050, device='cuda:0') sum\n",
            "loc loss here 304.9999974370003\n",
            "tensor(3.2298, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2298, device='cuda:0') sum\n",
            "loc loss here 305.9999974370003\n",
            "tensor(4.3861, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3861, device='cuda:0') sum\n",
            "loc loss here 306.9999974370003\n",
            "tensor(2.8753, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8753, device='cuda:0') sum\n",
            "loc loss here 307.9999974370003\n",
            "tensor(3.0066, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0066, device='cuda:0') sum\n",
            "loc loss here 308.9999974370003\n",
            "tensor(3.0112, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0112, device='cuda:0') sum\n",
            "loc loss here 309.9999974370003\n",
            "tensor(2.1876, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.1876, device='cuda:0') sum\n",
            "loc loss here 310.9999974370003\n",
            "tensor(3.7031, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7031, device='cuda:0') sum\n",
            "loc loss here 311.9999974370003\n",
            "tensor(1.8946, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.8946, device='cuda:0') sum\n",
            "loc loss here 312.9999974370003\n",
            "tensor(2.4385, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4385, device='cuda:0') sum\n",
            "loc loss here 313.9999974370003\n",
            "tensor(3.6808, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6808, device='cuda:0') sum\n",
            "loc loss here 314.99999737739563\n",
            "tensor(3.3021, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3021, device='cuda:0') sum\n",
            "loc loss here 315.999997317791\n",
            "tensor(3.4771, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4771, device='cuda:0') sum\n",
            "loc loss here 316.999997317791\n",
            "tensor(3.7621, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7621, device='cuda:0') sum\n",
            "loc loss here 317.999997317791\n",
            "tensor(3.4968, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4968, device='cuda:0') sum\n",
            "loc loss here 318.99999725818634\n",
            "tensor(4.4650, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.4650, device='cuda:0') sum\n",
            "loc loss here 319.99999725818634\n",
            "tensor(4.5945, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5945, device='cuda:0') sum\n",
            "loc loss here 320.99999725818634\n",
            "tensor(3.3922, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3922, device='cuda:0') sum\n",
            "loc loss here 321.99999725818634\n",
            "tensor(5.2693, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.2693, device='cuda:0') sum\n",
            "loc loss here 322.99999725818634\n",
            "tensor(3.1668, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1668, device='cuda:0') sum\n",
            "loc loss here 323.9999971985817\n",
            "tensor(2.7935, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7935, device='cuda:0') sum\n",
            "loc loss here 324.9999971985817\n",
            "tensor(3.1744, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1744, device='cuda:0') sum\n",
            "loc loss here 325.9999971985817\n",
            "tensor(2.5498, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5498, device='cuda:0') sum\n",
            "loc loss here 326.99999713897705\n",
            "tensor(3.2642, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2642, device='cuda:0') sum\n",
            "loc loss here 327.99999713897705\n",
            "tensor(3.5925, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5925, device='cuda:0') sum\n",
            "loc loss here 328.99999713897705\n",
            "tensor(3.1645, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1645, device='cuda:0') sum\n",
            "loc loss here 329.99999713897705\n",
            "tensor(2.6116, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6116, device='cuda:0') sum\n",
            "loc loss here 330.99999713897705\n",
            "tensor(3.8224, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8224, device='cuda:0') sum\n",
            "loc loss here 331.99999713897705\n",
            "tensor(3.2759, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2759, device='cuda:0') sum\n",
            "loc loss here 332.99999713897705\n",
            "tensor(3.2651, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2651, device='cuda:0') sum\n",
            "loc loss here 333.99999713897705\n",
            "tensor(4.1375, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1375, device='cuda:0') sum\n",
            "loc loss here 334.99999713897705\n",
            "tensor(2.5752, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5752, device='cuda:0') sum\n",
            "loc loss here 335.99999713897705\n",
            "tensor(3.5032, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5032, device='cuda:0') sum\n",
            "loc loss here 336.9999970793724\n",
            "tensor(4.1001, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1001, device='cuda:0') sum\n",
            "loc loss here 337.9999970793724\n",
            "tensor(4.8999, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.8999, device='cuda:0') sum\n",
            "loc loss here 338.9999970793724\n",
            "tensor(2.4554, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4554, device='cuda:0') sum\n",
            "loc loss here 339.9999970793724\n",
            "tensor(2.2819, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2819, device='cuda:0') sum\n",
            "loc loss here 340.99999701976776\n",
            "tensor(3.6489, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6489, device='cuda:0') sum\n",
            "loc loss here 341.99999701976776\n",
            "tensor(3.6610, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6610, device='cuda:0') sum\n",
            "loc loss here 342.99999701976776\n",
            "tensor(3.4406, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4406, device='cuda:0') sum\n",
            "loc loss here 343.99999701976776\n",
            "tensor(1.4266, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.4266, device='cuda:0') sum\n",
            "loc loss here 344.99999701976776\n",
            "tensor(3.3330, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3330, device='cuda:0') sum\n",
            "loc loss here 345.99999701976776\n",
            "tensor(2.8673, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8673, device='cuda:0') sum\n",
            "loc loss here 346.99999701976776\n",
            "tensor(2.6125, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6125, device='cuda:0') sum\n",
            "loc loss here 347.99999701976776\n",
            "tensor(3.9656, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9656, device='cuda:0') sum\n",
            "loc loss here 348.99999701976776\n",
            "tensor(2.6594, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6594, device='cuda:0') sum\n",
            "loc loss here 349.99999701976776\n",
            "tensor(3.2930, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2930, device='cuda:0') sum\n",
            "loc loss here 350.99999701976776\n",
            "tensor(1.5286, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.5286, device='cuda:0') sum\n",
            "loc loss here 351.99999701976776\n",
            "tensor(3.8576, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8576, device='cuda:0') sum\n",
            "loc loss here 352.9999969601631\n",
            "tensor(3.1599, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1599, device='cuda:0') sum\n",
            "loc loss here 353.9999969601631\n",
            "tensor(5.1853, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.1853, device='cuda:0') sum\n",
            "loc loss here 354.9999969005585\n",
            "tensor(2.9168, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9168, device='cuda:0') sum\n",
            "loc loss here 355.9999969005585\n",
            "tensor(3.2256, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2256, device='cuda:0') sum\n",
            "loc loss here 356.9999969005585\n",
            "tensor(2.3603, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3603, device='cuda:0') sum\n",
            "loc loss here 357.9999969005585\n",
            "tensor(2.9665, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9665, device='cuda:0') sum\n",
            "loc loss here 358.9999969005585\n",
            "tensor(5.0905, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.0905, device='cuda:0') sum\n",
            "loc loss here 359.9999969005585\n",
            "tensor(3.4144, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4144, device='cuda:0') sum\n",
            "loc loss here 360.9999969005585\n",
            "tensor(2.7358, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7358, device='cuda:0') sum\n",
            "loc loss here 361.9999969005585\n",
            "tensor(3.0778, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0778, device='cuda:0') sum\n",
            "loc loss here 362.9999969005585\n",
            "tensor(3.8205, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8205, device='cuda:0') sum\n",
            "loc loss here 363.9999969005585\n",
            "tensor(3.4350, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4350, device='cuda:0') sum\n",
            "loc loss here 364.9999969005585\n",
            "tensor(3.4503, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4503, device='cuda:0') sum\n",
            "loc loss here 365.9999969005585\n",
            "tensor(2.9756, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9756, device='cuda:0') sum\n",
            "loc loss here 366.9999969005585\n",
            "tensor(2.2424, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2424, device='cuda:0') sum\n",
            "loc loss here 367.9999969005585\n",
            "tensor(3.5940, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5940, device='cuda:0') sum\n",
            "loc loss here 368.9999969005585\n",
            "tensor(3.2394, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2394, device='cuda:0') sum\n",
            "loc loss here 369.9999969005585\n",
            "tensor(1.7170, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.7170, device='cuda:0') sum\n",
            "loc loss here 370.9999969005585\n",
            "tensor(2.6512, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6512, device='cuda:0') sum\n",
            "loc loss here 371.9999969005585\n",
            "tensor(2.9800, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9800, device='cuda:0') sum\n",
            "loc loss here 372.9999969005585\n",
            "tensor(3.8456, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8456, device='cuda:0') sum\n",
            "loc loss here 373.9999969005585\n",
            "tensor(3.0475, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0475, device='cuda:0') sum\n",
            "loc loss here 374.9999968409538\n",
            "tensor(3.9100, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9100, device='cuda:0') sum\n",
            "loc loss here 375.9999968409538\n",
            "tensor(3.7719, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7719, device='cuda:0') sum\n",
            "loc loss here 376.9999968409538\n",
            "tensor(2.8493, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8493, device='cuda:0') sum\n",
            "loc loss here 377.9999968409538\n",
            "tensor(3.3902, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3902, device='cuda:0') sum\n",
            "loc loss here 378.9999968409538\n",
            "tensor(4.7905, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.7905, device='cuda:0') sum\n",
            "loc loss here 379.9999968409538\n",
            "tensor(3.2433, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2433, device='cuda:0') sum\n",
            "loc loss here 380.9999967813492\n",
            "tensor(3.4093, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4093, device='cuda:0') sum\n",
            "loc loss here 381.9999967813492\n",
            "tensor(3.1593, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1593, device='cuda:0') sum\n",
            "loc loss here 382.9999967813492\n",
            "tensor(3.5497, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5497, device='cuda:0') sum\n",
            "loc loss here 383.99999672174454\n",
            "tensor(2.3438, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3438, device='cuda:0') sum\n",
            "loc loss here 384.99999672174454\n",
            "tensor(3.0653, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0653, device='cuda:0') sum\n",
            "loc loss here 385.9999966621399\n",
            "tensor(5.3561, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.3561, device='cuda:0') sum\n",
            "loc loss here 386.9999966621399\n",
            "tensor(3.7433, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7433, device='cuda:0') sum\n",
            "loc loss here 387.9999966621399\n",
            "tensor(3.0498, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0498, device='cuda:0') sum\n",
            "loc loss here 388.99999660253525\n",
            "tensor(3.1219, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1219, device='cuda:0') sum\n",
            "loc loss here 389.99999660253525\n",
            "tensor(4.0561, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0561, device='cuda:0') sum\n",
            "loc loss here 390.99999660253525\n",
            "tensor(4.0489, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0489, device='cuda:0') sum\n",
            "loc loss here 391.99999660253525\n",
            "tensor(3.1401, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1401, device='cuda:0') sum\n",
            "loc loss here 392.99999660253525\n",
            "tensor(3.8087, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8087, device='cuda:0') sum\n",
            "loc loss here 393.9999965429306\n",
            "tensor(4.2550, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2550, device='cuda:0') sum\n",
            "loc loss here 394.9999965429306\n",
            "tensor(2.7170, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7170, device='cuda:0') sum\n",
            "loc loss here 395.9999965429306\n",
            "tensor(2.7076, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7076, device='cuda:0') sum\n",
            "loc loss here 396.9999965429306\n",
            "tensor(3.7892, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7892, device='cuda:0') sum\n",
            "loc loss here 397.99999648332596\n",
            "tensor(2.4037, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4037, device='cuda:0') sum\n",
            "loc loss here 398.99999648332596\n",
            "tensor(3.2058, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2058, device='cuda:0') sum\n",
            "loc loss here 399.99999648332596\n",
            "tensor(4.0240, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0240, device='cuda:0') sum\n",
            "loc loss here 400.99999648332596\n",
            "  400 of  1143 \t L: 1.000 \t -- 82.659\n",
            "tensor(3.8187, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8187, device='cuda:0') sum\n",
            "loc loss here 401.99999648332596\n",
            "tensor(3.1596, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1596, device='cuda:0') sum\n",
            "loc loss here 402.99999648332596\n",
            "tensor(2.6823, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6823, device='cuda:0') sum\n",
            "loc loss here 403.99999648332596\n",
            "tensor(3.5086, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5086, device='cuda:0') sum\n",
            "loc loss here 404.99999648332596\n",
            "tensor(2.9895, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9895, device='cuda:0') sum\n",
            "loc loss here 405.99999648332596\n",
            "tensor(3.1147, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1147, device='cuda:0') sum\n",
            "loc loss here 406.99999648332596\n",
            "tensor(3.1368, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1368, device='cuda:0') sum\n",
            "loc loss here 407.99999648332596\n",
            "tensor(4.4385, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.4385, device='cuda:0') sum\n",
            "loc loss here 408.99999648332596\n",
            "tensor(2.5072, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5072, device='cuda:0') sum\n",
            "loc loss here 409.99999648332596\n",
            "tensor(2.6568, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6568, device='cuda:0') sum\n",
            "loc loss here 410.99999648332596\n",
            "tensor(4.1857, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1857, device='cuda:0') sum\n",
            "loc loss here 411.99999648332596\n",
            "tensor(4.0799, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0799, device='cuda:0') sum\n",
            "loc loss here 412.99999648332596\n",
            "tensor(3.0190, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0190, device='cuda:0') sum\n",
            "loc loss here 413.99999648332596\n",
            "tensor(3.9792, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9792, device='cuda:0') sum\n",
            "loc loss here 414.99999648332596\n",
            "tensor(3.1751, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1751, device='cuda:0') sum\n",
            "loc loss here 415.99999648332596\n",
            "tensor(3.1641, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1641, device='cuda:0') sum\n",
            "loc loss here 416.99999648332596\n",
            "tensor(2.3849, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3849, device='cuda:0') sum\n",
            "loc loss here 417.99999648332596\n",
            "tensor(3.7367, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7367, device='cuda:0') sum\n",
            "loc loss here 418.99999648332596\n",
            "tensor(3.4830, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4830, device='cuda:0') sum\n",
            "loc loss here 419.9999964237213\n",
            "tensor(3.9580, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9580, device='cuda:0') sum\n",
            "loc loss here 420.9999964237213\n",
            "tensor(3.2357, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2357, device='cuda:0') sum\n",
            "loc loss here 421.9999964237213\n",
            "tensor(3.5209, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5209, device='cuda:0') sum\n",
            "loc loss here 422.9999964237213\n",
            "tensor(3.0883, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0883, device='cuda:0') sum\n",
            "loc loss here 423.9999964237213\n",
            "tensor(3.6588, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6588, device='cuda:0') sum\n",
            "loc loss here 424.99999636411667\n",
            "tensor(3.2696, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2696, device='cuda:0') sum\n",
            "loc loss here 425.99999636411667\n",
            "tensor(3.3153, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3153, device='cuda:0') sum\n",
            "loc loss here 426.99999636411667\n",
            "tensor(3.2147, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2147, device='cuda:0') sum\n",
            "loc loss here 427.99999636411667\n",
            "tensor(2.7659, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7659, device='cuda:0') sum\n",
            "loc loss here 428.99999636411667\n",
            "tensor(3.4891, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4891, device='cuda:0') sum\n",
            "loc loss here 429.99999636411667\n",
            "tensor(3.1620, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1620, device='cuda:0') sum\n",
            "loc loss here 430.99999636411667\n",
            "tensor(3.0195, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0195, device='cuda:0') sum\n",
            "loc loss here 431.99999636411667\n",
            "tensor(3.9275, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9275, device='cuda:0') sum\n",
            "loc loss here 432.99999636411667\n",
            "tensor(3.4703, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4703, device='cuda:0') sum\n",
            "loc loss here 433.999996304512\n",
            "tensor(4.3837, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3837, device='cuda:0') sum\n",
            "loc loss here 434.999996304512\n",
            "tensor(2.4903, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4903, device='cuda:0') sum\n",
            "loc loss here 435.999996304512\n",
            "tensor(2.2288, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2288, device='cuda:0') sum\n",
            "loc loss here 436.999996304512\n",
            "tensor(1.7905, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.7905, device='cuda:0') sum\n",
            "loc loss here 437.999996304512\n",
            "tensor(2.9502, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9502, device='cuda:0') sum\n",
            "loc loss here 438.999996304512\n",
            "tensor(3.4074, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4074, device='cuda:0') sum\n",
            "loc loss here 439.999996304512\n",
            "tensor(3.5056, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5056, device='cuda:0') sum\n",
            "loc loss here 440.999996304512\n",
            "tensor(4.3654, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3654, device='cuda:0') sum\n",
            "loc loss here 441.999996304512\n",
            "tensor(2.3195, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3195, device='cuda:0') sum\n",
            "loc loss here 442.999996304512\n",
            "tensor(3.7314, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7314, device='cuda:0') sum\n",
            "loc loss here 443.999996304512\n",
            "tensor(4.4778, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.4778, device='cuda:0') sum\n",
            "loc loss here 444.999996304512\n",
            "tensor(5.2902, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.2902, device='cuda:0') sum\n",
            "loc loss here 445.999996304512\n",
            "tensor(4.1241, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1241, device='cuda:0') sum\n",
            "loc loss here 446.999996304512\n",
            "tensor(1.7261, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.7261, device='cuda:0') sum\n",
            "loc loss here 447.9999962449074\n",
            "tensor(4.2574, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2574, device='cuda:0') sum\n",
            "loc loss here 448.9999962449074\n",
            "tensor(3.6257, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6257, device='cuda:0') sum\n",
            "loc loss here 449.99999618530273\n",
            "tensor(3.2876, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2876, device='cuda:0') sum\n",
            "loc loss here 450.99999618530273\n",
            "tensor(3.7582, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7582, device='cuda:0') sum\n",
            "loc loss here 451.9999961256981\n",
            "tensor(4.1883, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1883, device='cuda:0') sum\n",
            "loc loss here 452.9999961256981\n",
            "tensor(3.3318, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3318, device='cuda:0') sum\n",
            "loc loss here 453.9999961256981\n",
            "tensor(1.9489, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.9489, device='cuda:0') sum\n",
            "loc loss here 454.9999961256981\n",
            "tensor(1.6412, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.6412, device='cuda:0') sum\n",
            "loc loss here 455.9999961256981\n",
            "tensor(3.0231, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0231, device='cuda:0') sum\n",
            "loc loss here 456.9999961256981\n",
            "tensor(4.5205, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5205, device='cuda:0') sum\n",
            "loc loss here 457.9999961256981\n",
            "tensor(3.7077, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7077, device='cuda:0') sum\n",
            "loc loss here 458.9999961256981\n",
            "tensor(4.0668, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0668, device='cuda:0') sum\n",
            "loc loss here 459.9999961256981\n",
            "tensor(2.4262, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4262, device='cuda:0') sum\n",
            "loc loss here 460.9999961256981\n",
            "tensor(2.7408, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7408, device='cuda:0') sum\n",
            "loc loss here 461.9999961256981\n",
            "tensor(4.1430, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1430, device='cuda:0') sum\n",
            "loc loss here 462.9999961256981\n",
            "tensor(2.6372, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6372, device='cuda:0') sum\n",
            "loc loss here 463.9999961256981\n",
            "tensor(2.2109, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2109, device='cuda:0') sum\n",
            "loc loss here 464.9999961256981\n",
            "tensor(2.9171, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9171, device='cuda:0') sum\n",
            "loc loss here 465.9999961256981\n",
            "tensor(2.8981, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8981, device='cuda:0') sum\n",
            "loc loss here 466.99999606609344\n",
            "tensor(2.6616, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6616, device='cuda:0') sum\n",
            "loc loss here 467.99999606609344\n",
            "tensor(3.3186, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3186, device='cuda:0') sum\n",
            "loc loss here 468.99999606609344\n",
            "tensor(3.8325, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8325, device='cuda:0') sum\n",
            "loc loss here 469.99999606609344\n",
            "tensor(2.2671, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2671, device='cuda:0') sum\n",
            "loc loss here 470.99999606609344\n",
            "tensor(3.1812, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1812, device='cuda:0') sum\n",
            "loc loss here 471.99999606609344\n",
            "tensor(4.1909, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1909, device='cuda:0') sum\n",
            "loc loss here 472.99999606609344\n",
            "tensor(2.2393, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2393, device='cuda:0') sum\n",
            "loc loss here 473.99999606609344\n",
            "tensor(3.1062, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1062, device='cuda:0') sum\n",
            "loc loss here 474.99999606609344\n",
            "tensor(3.0719, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0719, device='cuda:0') sum\n",
            "loc loss here 475.99999606609344\n",
            "tensor(2.1772, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.1772, device='cuda:0') sum\n",
            "loc loss here 476.99999606609344\n",
            "tensor(3.9472, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9472, device='cuda:0') sum\n",
            "loc loss here 477.9999960064888\n",
            "tensor(3.5836, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5836, device='cuda:0') sum\n",
            "loc loss here 478.9999960064888\n",
            "tensor(3.3376, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3376, device='cuda:0') sum\n",
            "loc loss here 479.9999960064888\n",
            "tensor(2.7078, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7078, device='cuda:0') sum\n",
            "loc loss here 480.9999960064888\n",
            "tensor(2.8379, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8379, device='cuda:0') sum\n",
            "loc loss here 481.9999960064888\n",
            "tensor(2.9346, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9346, device='cuda:0') sum\n",
            "loc loss here 482.9999960064888\n",
            "tensor(2.3787, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3787, device='cuda:0') sum\n",
            "loc loss here 483.9999960064888\n",
            "tensor(2.7106, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7106, device='cuda:0') sum\n",
            "loc loss here 484.9999960064888\n",
            "tensor(2.0984, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.0984, device='cuda:0') sum\n",
            "loc loss here 485.9999960064888\n",
            "tensor(2.4239, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4239, device='cuda:0') sum\n",
            "loc loss here 486.9999960064888\n",
            "tensor(2.9662, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9662, device='cuda:0') sum\n",
            "loc loss here 487.9999960064888\n",
            "tensor(3.2768, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2768, device='cuda:0') sum\n",
            "loc loss here 488.9999960064888\n",
            "tensor(3.2538, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2538, device='cuda:0') sum\n",
            "loc loss here 489.9999960064888\n",
            "tensor(3.9702, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9702, device='cuda:0') sum\n",
            "loc loss here 490.9999960064888\n",
            "tensor(2.2795, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2795, device='cuda:0') sum\n",
            "loc loss here 491.9999960064888\n",
            "tensor(4.2787, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2787, device='cuda:0') sum\n",
            "loc loss here 492.9999960064888\n",
            "tensor(3.8770, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8770, device='cuda:0') sum\n",
            "loc loss here 493.9999960064888\n",
            "tensor(3.5896, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5896, device='cuda:0') sum\n",
            "loc loss here 494.9999960064888\n",
            "tensor(3.3865, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3865, device='cuda:0') sum\n",
            "loc loss here 495.9999960064888\n",
            "tensor(3.8453, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8453, device='cuda:0') sum\n",
            "loc loss here 496.9999960064888\n",
            "tensor(3.3510, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3510, device='cuda:0') sum\n",
            "loc loss here 497.99999594688416\n",
            "tensor(2.9680, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9680, device='cuda:0') sum\n",
            "loc loss here 498.9999958872795\n",
            "tensor(3.3605, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3605, device='cuda:0') sum\n",
            "loc loss here 499.9999958872795\n",
            "tensor(2.6900, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6900, device='cuda:0') sum\n",
            "loc loss here 500.99999582767487\n",
            "  500 of  1143 \t L: 1.000 \t -- 103.542\n",
            "tensor(3.8444, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8444, device='cuda:0') sum\n",
            "loc loss here 501.99999582767487\n",
            "tensor(2.7599, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7599, device='cuda:0') sum\n",
            "loc loss here 502.99999582767487\n",
            "tensor(3.0529, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0529, device='cuda:0') sum\n",
            "loc loss here 503.99999582767487\n",
            "tensor(3.8588, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8588, device='cuda:0') sum\n",
            "loc loss here 504.99999582767487\n",
            "tensor(4.1799, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1799, device='cuda:0') sum\n",
            "loc loss here 505.99999582767487\n",
            "tensor(3.3830, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3830, device='cuda:0') sum\n",
            "loc loss here 506.99999582767487\n",
            "tensor(2.3442, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3442, device='cuda:0') sum\n",
            "loc loss here 507.99999582767487\n",
            "tensor(3.8960, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8960, device='cuda:0') sum\n",
            "loc loss here 508.9999957680702\n",
            "tensor(2.8366, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8366, device='cuda:0') sum\n",
            "loc loss here 509.9999957680702\n",
            "tensor(2.8563, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8563, device='cuda:0') sum\n",
            "loc loss here 510.9999957680702\n",
            "tensor(2.7806, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7806, device='cuda:0') sum\n",
            "loc loss here 511.9999957680702\n",
            "tensor(3.4344, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4344, device='cuda:0') sum\n",
            "loc loss here 512.9999957680702\n",
            "tensor(2.5051, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5051, device='cuda:0') sum\n",
            "loc loss here 513.9999957680702\n",
            "tensor(3.0767, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0767, device='cuda:0') sum\n",
            "loc loss here 514.9999957084656\n",
            "tensor(5.5011, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.5011, device='cuda:0') sum\n",
            "loc loss here 515.9999957084656\n",
            "tensor(3.2412, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2412, device='cuda:0') sum\n",
            "loc loss here 516.9999957084656\n",
            "tensor(4.5323, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5323, device='cuda:0') sum\n",
            "loc loss here 517.9999957084656\n",
            "tensor(3.4016, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4016, device='cuda:0') sum\n",
            "loc loss here 518.9999957084656\n",
            "tensor(2.4700, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4700, device='cuda:0') sum\n",
            "loc loss here 519.9999957084656\n",
            "tensor(3.4088, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4088, device='cuda:0') sum\n",
            "loc loss here 520.9999957084656\n",
            "tensor(2.4041, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4041, device='cuda:0') sum\n",
            "loc loss here 521.9999957084656\n",
            "tensor(1.9089, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.9089, device='cuda:0') sum\n",
            "loc loss here 522.9999957084656\n",
            "tensor(3.5459, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5459, device='cuda:0') sum\n",
            "loc loss here 523.9999957084656\n",
            "tensor(3.6938, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6938, device='cuda:0') sum\n",
            "loc loss here 524.9999957084656\n",
            "tensor(3.5930, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5930, device='cuda:0') sum\n",
            "loc loss here 525.9999957084656\n",
            "tensor(3.1854, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1854, device='cuda:0') sum\n",
            "loc loss here 526.9999957084656\n",
            "tensor(2.9802, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9802, device='cuda:0') sum\n",
            "loc loss here 527.9999957084656\n",
            "tensor(4.1720, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1720, device='cuda:0') sum\n",
            "loc loss here 528.9999957084656\n",
            "tensor(2.5933, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5933, device='cuda:0') sum\n",
            "loc loss here 529.9999956488609\n",
            "tensor(2.2455, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2455, device='cuda:0') sum\n",
            "loc loss here 530.9999956488609\n",
            "tensor(3.3673, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3673, device='cuda:0') sum\n",
            "loc loss here 531.9999956488609\n",
            "tensor(2.2330, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2330, device='cuda:0') sum\n",
            "loc loss here 532.9999956488609\n",
            "tensor(3.1393, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1393, device='cuda:0') sum\n",
            "loc loss here 533.9999956488609\n",
            "tensor(4.5380, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5380, device='cuda:0') sum\n",
            "loc loss here 534.9999956488609\n",
            "tensor(3.1588, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1588, device='cuda:0') sum\n",
            "loc loss here 535.9999956488609\n",
            "tensor(4.5243, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5243, device='cuda:0') sum\n",
            "loc loss here 536.9999956488609\n",
            "tensor(3.3177, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3177, device='cuda:0') sum\n",
            "loc loss here 537.9999956488609\n",
            "tensor(3.5578, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5578, device='cuda:0') sum\n",
            "loc loss here 538.9999955892563\n",
            "tensor(3.9765, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9765, device='cuda:0') sum\n",
            "loc loss here 539.9999955892563\n",
            "tensor(3.6903, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6903, device='cuda:0') sum\n",
            "loc loss here 540.9999955892563\n",
            "tensor(3.2894, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2894, device='cuda:0') sum\n",
            "loc loss here 541.9999955892563\n",
            "tensor(2.5057, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5057, device='cuda:0') sum\n",
            "loc loss here 542.9999955892563\n",
            "tensor(3.0740, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0740, device='cuda:0') sum\n",
            "loc loss here 543.9999955892563\n",
            "tensor(3.1637, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1637, device='cuda:0') sum\n",
            "loc loss here 544.9999955892563\n",
            "tensor(3.0594, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0594, device='cuda:0') sum\n",
            "loc loss here 545.9999955892563\n",
            "tensor(3.8294, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8294, device='cuda:0') sum\n",
            "loc loss here 546.9999955892563\n",
            "tensor(4.0207, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0207, device='cuda:0') sum\n",
            "loc loss here 547.9999955892563\n",
            "tensor(3.3109, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3109, device='cuda:0') sum\n",
            "loc loss here 548.9999955892563\n",
            "tensor(3.1182, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1182, device='cuda:0') sum\n",
            "loc loss here 549.9999955892563\n",
            "tensor(4.1730, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1730, device='cuda:0') sum\n",
            "loc loss here 550.9999955892563\n",
            "tensor(3.9984, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9984, device='cuda:0') sum\n",
            "loc loss here 551.9999955892563\n",
            "tensor(3.5770, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5770, device='cuda:0') sum\n",
            "loc loss here 552.9999955296516\n",
            "tensor(3.6351, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6351, device='cuda:0') sum\n",
            "loc loss here 553.9999955296516\n",
            "tensor(3.0602, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0602, device='cuda:0') sum\n",
            "loc loss here 554.9999955296516\n",
            "tensor(4.3343, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3343, device='cuda:0') sum\n",
            "loc loss here 555.9999955296516\n",
            "tensor(3.3447, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3447, device='cuda:0') sum\n",
            "loc loss here 556.9999955296516\n",
            "tensor(3.4386, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4386, device='cuda:0') sum\n",
            "loc loss here 557.9999955296516\n",
            "tensor(3.2114, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2114, device='cuda:0') sum\n",
            "loc loss here 558.9999955296516\n",
            "tensor(2.9943, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9943, device='cuda:0') sum\n",
            "loc loss here 559.9999955296516\n",
            "tensor(4.1355, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1355, device='cuda:0') sum\n",
            "loc loss here 560.9999955296516\n",
            "tensor(4.8317, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.8317, device='cuda:0') sum\n",
            "loc loss here 561.9999955296516\n",
            "tensor(3.1343, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1343, device='cuda:0') sum\n",
            "loc loss here 562.9999955296516\n",
            "tensor(3.0767, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0767, device='cuda:0') sum\n",
            "loc loss here 563.9999955296516\n",
            "tensor(3.8406, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8406, device='cuda:0') sum\n",
            "loc loss here 564.9999955296516\n",
            "tensor(2.2300, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2300, device='cuda:0') sum\n",
            "loc loss here 565.9999955296516\n",
            "tensor(3.2006, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2006, device='cuda:0') sum\n",
            "loc loss here 566.9999955296516\n",
            "tensor(3.3472, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3472, device='cuda:0') sum\n",
            "loc loss here 567.9999955296516\n",
            "tensor(3.8904, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8904, device='cuda:0') sum\n",
            "loc loss here 568.9999955296516\n",
            "tensor(3.7220, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7220, device='cuda:0') sum\n",
            "loc loss here 569.9999955296516\n",
            "tensor(3.7451, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7451, device='cuda:0') sum\n",
            "loc loss here 570.9999955296516\n",
            "tensor(3.3154, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3154, device='cuda:0') sum\n",
            "loc loss here 571.9999955296516\n",
            "tensor(4.4759, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.4759, device='cuda:0') sum\n",
            "loc loss here 572.9999955296516\n",
            "tensor(2.8301, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8301, device='cuda:0') sum\n",
            "loc loss here 573.999995470047\n",
            "tensor(4.6278, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.6278, device='cuda:0') sum\n",
            "loc loss here 574.999995470047\n",
            "tensor(4.0643, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0643, device='cuda:0') sum\n",
            "loc loss here 575.999995470047\n",
            "tensor(3.9877, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9877, device='cuda:0') sum\n",
            "loc loss here 576.999995470047\n",
            "tensor(3.8155, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8155, device='cuda:0') sum\n",
            "loc loss here 577.999995470047\n",
            "tensor(3.2451, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2451, device='cuda:0') sum\n",
            "loc loss here 578.9999954104424\n",
            "tensor(4.3349, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3349, device='cuda:0') sum\n",
            "loc loss here 579.9999954104424\n",
            "tensor(2.0302, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.0302, device='cuda:0') sum\n",
            "loc loss here 580.9999954104424\n",
            "tensor(4.5385, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5385, device='cuda:0') sum\n",
            "loc loss here 581.9999954104424\n",
            "tensor(3.6386, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6386, device='cuda:0') sum\n",
            "loc loss here 582.9999954104424\n",
            "tensor(3.4131, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4131, device='cuda:0') sum\n",
            "loc loss here 583.9999954104424\n",
            "tensor(4.0633, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0633, device='cuda:0') sum\n",
            "loc loss here 584.9999954104424\n",
            "tensor(2.7110, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7110, device='cuda:0') sum\n",
            "loc loss here 585.9999954104424\n",
            "tensor(2.9803, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9803, device='cuda:0') sum\n",
            "loc loss here 586.9999954104424\n",
            "tensor(3.9219, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9219, device='cuda:0') sum\n",
            "loc loss here 587.9999954104424\n",
            "tensor(3.4403, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4403, device='cuda:0') sum\n",
            "loc loss here 588.9999953508377\n",
            "tensor(3.6944, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6944, device='cuda:0') sum\n",
            "loc loss here 589.9999953508377\n",
            "tensor(2.8929, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8929, device='cuda:0') sum\n",
            "loc loss here 590.9999953508377\n",
            "tensor(5.3405, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.3405, device='cuda:0') sum\n",
            "loc loss here 591.9999953508377\n",
            "tensor(3.3465, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3465, device='cuda:0') sum\n",
            "loc loss here 592.9999953508377\n",
            "tensor(3.6149, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6149, device='cuda:0') sum\n",
            "loc loss here 593.9999953508377\n",
            "tensor(3.3068, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3068, device='cuda:0') sum\n",
            "loc loss here 594.9999953508377\n",
            "tensor(1.7167, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.7167, device='cuda:0') sum\n",
            "loc loss here 595.9999953508377\n",
            "tensor(3.3933, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3933, device='cuda:0') sum\n",
            "loc loss here 596.9999953508377\n",
            "tensor(4.0707, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0707, device='cuda:0') sum\n",
            "loc loss here 597.9999953508377\n",
            "tensor(3.4984, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4984, device='cuda:0') sum\n",
            "loc loss here 598.9999953508377\n",
            "tensor(3.2568, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2568, device='cuda:0') sum\n",
            "loc loss here 599.9999953508377\n",
            "tensor(3.7900, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7900, device='cuda:0') sum\n",
            "loc loss here 600.9999952912331\n",
            "  600 of  1143 \t L: 1.000 \t -- 123.508\n",
            "tensor(2.1588, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.1588, device='cuda:0') sum\n",
            "loc loss here 601.9999952912331\n",
            "tensor(2.3371, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3371, device='cuda:0') sum\n",
            "loc loss here 602.9999952912331\n",
            "tensor(3.1236, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1236, device='cuda:0') sum\n",
            "loc loss here 603.9999952912331\n",
            "tensor(3.4992, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4992, device='cuda:0') sum\n",
            "loc loss here 604.9999952912331\n",
            "tensor(2.2612, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2612, device='cuda:0') sum\n",
            "loc loss here 605.9999952912331\n",
            "tensor(3.5214, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5214, device='cuda:0') sum\n",
            "loc loss here 606.9999952316284\n",
            "tensor(1.9420, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.9420, device='cuda:0') sum\n",
            "loc loss here 607.9999952316284\n",
            "tensor(3.2532, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2532, device='cuda:0') sum\n",
            "loc loss here 608.9999952316284\n",
            "tensor(2.8666, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8666, device='cuda:0') sum\n",
            "loc loss here 609.9999952316284\n",
            "tensor(3.0412, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0412, device='cuda:0') sum\n",
            "loc loss here 610.9999952316284\n",
            "tensor(3.5767, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5767, device='cuda:0') sum\n",
            "loc loss here 611.9999951720238\n",
            "tensor(3.7512, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7512, device='cuda:0') sum\n",
            "loc loss here 612.9999951720238\n",
            "tensor(2.7797, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7797, device='cuda:0') sum\n",
            "loc loss here 613.9999951720238\n",
            "tensor(3.2021, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2021, device='cuda:0') sum\n",
            "loc loss here 614.9999951720238\n",
            "tensor(3.4898, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4898, device='cuda:0') sum\n",
            "loc loss here 615.9999951720238\n",
            "tensor(3.7295, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7295, device='cuda:0') sum\n",
            "loc loss here 616.9999951124191\n",
            "tensor(2.2608, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2608, device='cuda:0') sum\n",
            "loc loss here 617.9999951124191\n",
            "tensor(3.9533, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9533, device='cuda:0') sum\n",
            "loc loss here 618.9999951124191\n",
            "tensor(3.4446, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4446, device='cuda:0') sum\n",
            "loc loss here 619.9999951124191\n",
            "tensor(3.4936, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4936, device='cuda:0') sum\n",
            "loc loss here 620.9999951124191\n",
            "tensor(3.9037, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9037, device='cuda:0') sum\n",
            "loc loss here 621.9999951124191\n",
            "tensor(3.7535, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7535, device='cuda:0') sum\n",
            "loc loss here 622.9999951124191\n",
            "tensor(3.4997, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4997, device='cuda:0') sum\n",
            "loc loss here 623.9999951124191\n",
            "tensor(3.5583, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5583, device='cuda:0') sum\n",
            "loc loss here 624.9999951124191\n",
            "tensor(2.6839, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6839, device='cuda:0') sum\n",
            "loc loss here 625.9999951124191\n",
            "tensor(3.6178, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6178, device='cuda:0') sum\n",
            "loc loss here 626.9999950528145\n",
            "tensor(4.0550, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0550, device='cuda:0') sum\n",
            "loc loss here 627.9999950528145\n",
            "tensor(3.3232, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3232, device='cuda:0') sum\n",
            "loc loss here 628.9999949932098\n",
            "tensor(3.9828, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9828, device='cuda:0') sum\n",
            "loc loss here 629.9999949932098\n",
            "tensor(4.0043, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0043, device='cuda:0') sum\n",
            "loc loss here 630.9999949932098\n",
            "tensor(3.5145, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5145, device='cuda:0') sum\n",
            "loc loss here 631.9999949932098\n",
            "tensor(2.2542, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2542, device='cuda:0') sum\n",
            "loc loss here 632.9999949932098\n",
            "tensor(2.4547, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4547, device='cuda:0') sum\n",
            "loc loss here 633.9999949932098\n",
            "tensor(3.0262, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0262, device='cuda:0') sum\n",
            "loc loss here 634.9999949932098\n",
            "tensor(2.5989, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5989, device='cuda:0') sum\n",
            "loc loss here 635.9999949932098\n",
            "tensor(3.6778, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6778, device='cuda:0') sum\n",
            "loc loss here 636.9999949336052\n",
            "tensor(3.1355, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1355, device='cuda:0') sum\n",
            "loc loss here 637.9999949336052\n",
            "tensor(4.2682, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2682, device='cuda:0') sum\n",
            "loc loss here 638.9999949336052\n",
            "tensor(3.7235, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7235, device='cuda:0') sum\n",
            "loc loss here 639.9999949336052\n",
            "tensor(3.2172, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2172, device='cuda:0') sum\n",
            "loc loss here 640.9999948740005\n",
            "tensor(3.4853, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4853, device='cuda:0') sum\n",
            "loc loss here 641.9999948740005\n",
            "tensor(3.2326, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2326, device='cuda:0') sum\n",
            "loc loss here 642.9999948740005\n",
            "tensor(3.6001, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6001, device='cuda:0') sum\n",
            "loc loss here 643.9999948740005\n",
            "tensor(4.1011, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1011, device='cuda:0') sum\n",
            "loc loss here 644.9999948740005\n",
            "tensor(2.8892, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8892, device='cuda:0') sum\n",
            "loc loss here 645.9999948740005\n",
            "tensor(3.5361, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5361, device='cuda:0') sum\n",
            "loc loss here 646.9999948143959\n",
            "tensor(3.2433, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2433, device='cuda:0') sum\n",
            "loc loss here 647.9999947547913\n",
            "tensor(2.4375, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4375, device='cuda:0') sum\n",
            "loc loss here 648.9999947547913\n",
            "tensor(3.3084, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3084, device='cuda:0') sum\n",
            "loc loss here 649.9999947547913\n",
            "tensor(2.6795, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6795, device='cuda:0') sum\n",
            "loc loss here 650.9999947547913\n",
            "tensor(2.5581, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5581, device='cuda:0') sum\n",
            "loc loss here 651.9999947547913\n",
            "tensor(3.2653, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2653, device='cuda:0') sum\n",
            "loc loss here 652.9999947547913\n",
            "tensor(2.9328, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9328, device='cuda:0') sum\n",
            "loc loss here 653.9999947547913\n",
            "tensor(3.8526, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8526, device='cuda:0') sum\n",
            "loc loss here 654.9999947547913\n",
            "tensor(3.5761, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5761, device='cuda:0') sum\n",
            "loc loss here 655.9999947547913\n",
            "tensor(3.9060, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9060, device='cuda:0') sum\n",
            "loc loss here 656.9999947547913\n",
            "tensor(2.8744, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8744, device='cuda:0') sum\n",
            "loc loss here 657.9999947547913\n",
            "tensor(3.7282, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7282, device='cuda:0') sum\n",
            "loc loss here 658.9999946951866\n",
            "tensor(3.7076, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7076, device='cuda:0') sum\n",
            "loc loss here 659.9999946951866\n",
            "tensor(2.9142, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9142, device='cuda:0') sum\n",
            "loc loss here 660.999994635582\n",
            "tensor(3.1267, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1267, device='cuda:0') sum\n",
            "loc loss here 661.999994635582\n",
            "tensor(4.1327, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1327, device='cuda:0') sum\n",
            "loc loss here 662.999994635582\n",
            "tensor(3.1024, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1024, device='cuda:0') sum\n",
            "loc loss here 663.999994635582\n",
            "tensor(5.0165, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.0165, device='cuda:0') sum\n",
            "loc loss here 664.999994635582\n",
            "tensor(3.2767, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2767, device='cuda:0') sum\n",
            "loc loss here 665.999994635582\n",
            "tensor(4.7074, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.7074, device='cuda:0') sum\n",
            "loc loss here 666.999994635582\n",
            "tensor(4.1858, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1858, device='cuda:0') sum\n",
            "loc loss here 667.999994635582\n",
            "tensor(3.6375, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6375, device='cuda:0') sum\n",
            "loc loss here 668.999994635582\n",
            "tensor(2.7438, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7438, device='cuda:0') sum\n",
            "loc loss here 669.999994635582\n",
            "tensor(2.3643, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3643, device='cuda:0') sum\n",
            "loc loss here 670.999994635582\n",
            "tensor(3.8850, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8850, device='cuda:0') sum\n",
            "loc loss here 671.999994635582\n",
            "tensor(3.2150, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2150, device='cuda:0') sum\n",
            "loc loss here 672.999994635582\n",
            "tensor(3.9278, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9278, device='cuda:0') sum\n",
            "loc loss here 673.999994635582\n",
            "tensor(3.3753, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3753, device='cuda:0') sum\n",
            "loc loss here 674.999994635582\n",
            "tensor(3.3359, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3359, device='cuda:0') sum\n",
            "loc loss here 675.999994635582\n",
            "tensor(2.4795, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4795, device='cuda:0') sum\n",
            "loc loss here 676.9999945759773\n",
            "tensor(3.1087, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1087, device='cuda:0') sum\n",
            "loc loss here 677.9999945759773\n",
            "tensor(3.2508, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2508, device='cuda:0') sum\n",
            "loc loss here 678.9999945759773\n",
            "tensor(3.0554, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0554, device='cuda:0') sum\n",
            "loc loss here 679.9999945759773\n",
            "tensor(3.7144, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7144, device='cuda:0') sum\n",
            "loc loss here 680.9999945759773\n",
            "tensor(4.3914, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3914, device='cuda:0') sum\n",
            "loc loss here 681.9999945163727\n",
            "tensor(4.6460, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.6460, device='cuda:0') sum\n",
            "loc loss here 682.9999945163727\n",
            "tensor(3.3347, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3347, device='cuda:0') sum\n",
            "loc loss here 683.9999945163727\n",
            "tensor(3.6054, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6054, device='cuda:0') sum\n",
            "loc loss here 684.9999945163727\n",
            "tensor(3.3426, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3426, device='cuda:0') sum\n",
            "loc loss here 685.9999945163727\n",
            "tensor(2.7296, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7296, device='cuda:0') sum\n",
            "loc loss here 686.9999945163727\n",
            "tensor(2.3089, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3089, device='cuda:0') sum\n",
            "loc loss here 687.9999945163727\n",
            "tensor(3.3895, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3895, device='cuda:0') sum\n",
            "loc loss here 688.9999945163727\n",
            "tensor(3.2558, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2558, device='cuda:0') sum\n",
            "loc loss here 689.9999945163727\n",
            "tensor(3.7966, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7966, device='cuda:0') sum\n",
            "loc loss here 690.9999945163727\n",
            "tensor(4.0786, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0786, device='cuda:0') sum\n",
            "loc loss here 691.9999945163727\n",
            "tensor(3.4897, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4897, device='cuda:0') sum\n",
            "loc loss here 692.9999945163727\n",
            "tensor(3.5679, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5679, device='cuda:0') sum\n",
            "loc loss here 693.9999945163727\n",
            "tensor(3.2240, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2240, device='cuda:0') sum\n",
            "loc loss here 694.9999945163727\n",
            "tensor(3.6129, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6129, device='cuda:0') sum\n",
            "loc loss here 695.9999945163727\n",
            "tensor(2.5268, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5268, device='cuda:0') sum\n",
            "loc loss here 696.9999945163727\n",
            "tensor(2.9923, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9923, device='cuda:0') sum\n",
            "loc loss here 697.9999945163727\n",
            "tensor(2.5604, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5604, device='cuda:0') sum\n",
            "loc loss here 698.9999945163727\n",
            "tensor(2.8685, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8685, device='cuda:0') sum\n",
            "loc loss here 699.999994456768\n",
            "tensor(2.4471, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4471, device='cuda:0') sum\n",
            "loc loss here 700.999994456768\n",
            "  700 of  1143 \t L: 1.000 \t -- 143.416\n",
            "tensor(3.9355, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9355, device='cuda:0') sum\n",
            "loc loss here 701.999994456768\n",
            "tensor(2.9892, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9892, device='cuda:0') sum\n",
            "loc loss here 702.999994456768\n",
            "tensor(2.5751, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5751, device='cuda:0') sum\n",
            "loc loss here 703.999994456768\n",
            "tensor(3.6670, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6670, device='cuda:0') sum\n",
            "loc loss here 704.999994456768\n",
            "tensor(3.6472, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6472, device='cuda:0') sum\n",
            "loc loss here 705.999994456768\n",
            "tensor(3.5607, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5607, device='cuda:0') sum\n",
            "loc loss here 706.999994456768\n",
            "tensor(3.6463, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6463, device='cuda:0') sum\n",
            "loc loss here 707.999994456768\n",
            "tensor(3.7564, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7564, device='cuda:0') sum\n",
            "loc loss here 708.9999943971634\n",
            "tensor(2.8163, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8163, device='cuda:0') sum\n",
            "loc loss here 709.9999943971634\n",
            "tensor(2.9521, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9521, device='cuda:0') sum\n",
            "loc loss here 710.9999943375587\n",
            "tensor(2.2695, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2695, device='cuda:0') sum\n",
            "loc loss here 711.9999943375587\n",
            "tensor(3.4577, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4577, device='cuda:0') sum\n",
            "loc loss here 712.9999943375587\n",
            "tensor(1.9143, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.9143, device='cuda:0') sum\n",
            "loc loss here 713.9999943375587\n",
            "tensor(3.3933, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3933, device='cuda:0') sum\n",
            "loc loss here 714.9999943375587\n",
            "tensor(3.4834, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4834, device='cuda:0') sum\n",
            "loc loss here 715.9999943375587\n",
            "tensor(3.2318, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2318, device='cuda:0') sum\n",
            "loc loss here 716.9999943375587\n",
            "tensor(3.7336, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7336, device='cuda:0') sum\n",
            "loc loss here 717.9999942779541\n",
            "tensor(2.7425, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7425, device='cuda:0') sum\n",
            "loc loss here 718.9999942779541\n",
            "tensor(5.2626, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.2626, device='cuda:0') sum\n",
            "loc loss here 719.9999942779541\n",
            "tensor(3.8232, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8232, device='cuda:0') sum\n",
            "loc loss here 720.9999942779541\n",
            "tensor(2.9306, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9306, device='cuda:0') sum\n",
            "loc loss here 721.9999942183495\n",
            "tensor(3.9263, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9263, device='cuda:0') sum\n",
            "loc loss here 722.9999942183495\n",
            "tensor(2.0970, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.0970, device='cuda:0') sum\n",
            "loc loss here 723.9999942183495\n",
            "tensor(3.8515, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8515, device='cuda:0') sum\n",
            "loc loss here 724.9999941587448\n",
            "tensor(3.2330, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2330, device='cuda:0') sum\n",
            "loc loss here 725.9999941587448\n",
            "tensor(3.4594, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4594, device='cuda:0') sum\n",
            "loc loss here 726.9999941587448\n",
            "tensor(4.6955, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.6955, device='cuda:0') sum\n",
            "loc loss here 727.9999941587448\n",
            "tensor(3.6318, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6318, device='cuda:0') sum\n",
            "loc loss here 728.9999940991402\n",
            "tensor(3.9025, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9025, device='cuda:0') sum\n",
            "loc loss here 729.9999940991402\n",
            "tensor(2.8799, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8799, device='cuda:0') sum\n",
            "loc loss here 730.9999940991402\n",
            "tensor(1.5886, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.5886, device='cuda:0') sum\n",
            "loc loss here 731.9999940991402\n",
            "tensor(2.4353, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4353, device='cuda:0') sum\n",
            "loc loss here 732.9999940991402\n",
            "tensor(3.0581, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0581, device='cuda:0') sum\n",
            "loc loss here 733.9999940991402\n",
            "tensor(4.1597, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1597, device='cuda:0') sum\n",
            "loc loss here 734.9999940991402\n",
            "tensor(3.7031, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7031, device='cuda:0') sum\n",
            "loc loss here 735.9999940991402\n",
            "tensor(4.3372, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3372, device='cuda:0') sum\n",
            "loc loss here 736.9999940991402\n",
            "tensor(2.2798, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2798, device='cuda:0') sum\n",
            "loc loss here 737.9999940991402\n",
            "tensor(2.9224, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9224, device='cuda:0') sum\n",
            "loc loss here 738.9999940991402\n",
            "tensor(2.8104, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8104, device='cuda:0') sum\n",
            "loc loss here 739.9999940395355\n",
            "tensor(3.1206, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1206, device='cuda:0') sum\n",
            "loc loss here 740.9999940395355\n",
            "tensor(3.7282, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7282, device='cuda:0') sum\n",
            "loc loss here 741.9999940395355\n",
            "tensor(3.4347, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4347, device='cuda:0') sum\n",
            "loc loss here 742.9999940395355\n",
            "tensor(3.4314, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4314, device='cuda:0') sum\n",
            "loc loss here 743.9999940395355\n",
            "tensor(3.1737, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1737, device='cuda:0') sum\n",
            "loc loss here 744.9999939799309\n",
            "tensor(4.1488, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1488, device='cuda:0') sum\n",
            "loc loss here 745.9999939799309\n",
            "tensor(3.7680, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7680, device='cuda:0') sum\n",
            "loc loss here 746.9999939799309\n",
            "tensor(3.5410, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5410, device='cuda:0') sum\n",
            "loc loss here 747.9999939799309\n",
            "tensor(2.1793, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.1793, device='cuda:0') sum\n",
            "loc loss here 748.9999939799309\n",
            "tensor(3.6316, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6316, device='cuda:0') sum\n",
            "loc loss here 749.9999939799309\n",
            "tensor(2.6417, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6417, device='cuda:0') sum\n",
            "loc loss here 750.9999939799309\n",
            "tensor(3.4297, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4297, device='cuda:0') sum\n",
            "loc loss here 751.9999939799309\n",
            "tensor(2.6257, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6257, device='cuda:0') sum\n",
            "loc loss here 752.9999939799309\n",
            "tensor(3.6964, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6964, device='cuda:0') sum\n",
            "loc loss here 753.9999939203262\n",
            "tensor(3.6198, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6198, device='cuda:0') sum\n",
            "loc loss here 754.9999939203262\n",
            "tensor(3.7689, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7689, device='cuda:0') sum\n",
            "loc loss here 755.9999938607216\n",
            "tensor(3.1318, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1318, device='cuda:0') sum\n",
            "loc loss here 756.9999938607216\n",
            "tensor(2.4879, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4879, device='cuda:0') sum\n",
            "loc loss here 757.9999938607216\n",
            "tensor(2.9587, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9587, device='cuda:0') sum\n",
            "loc loss here 758.9999938607216\n",
            "tensor(3.4153, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4153, device='cuda:0') sum\n",
            "loc loss here 759.9999938607216\n",
            "tensor(3.1910, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1910, device='cuda:0') sum\n",
            "loc loss here 760.9999938607216\n",
            "tensor(1.8011, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.8011, device='cuda:0') sum\n",
            "loc loss here 761.9999938607216\n",
            "tensor(4.3864, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3864, device='cuda:0') sum\n",
            "loc loss here 762.9999938607216\n",
            "tensor(1.9899, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.9899, device='cuda:0') sum\n",
            "loc loss here 763.999993801117\n",
            "tensor(3.7311, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7311, device='cuda:0') sum\n",
            "loc loss here 764.999993801117\n",
            "tensor(3.3209, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3209, device='cuda:0') sum\n",
            "loc loss here 765.999993801117\n",
            "tensor(3.6806, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6806, device='cuda:0') sum\n",
            "loc loss here 766.999993801117\n",
            "tensor(1.9437, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.9437, device='cuda:0') sum\n",
            "loc loss here 767.9999937415123\n",
            "tensor(3.3933, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3933, device='cuda:0') sum\n",
            "loc loss here 768.9999937415123\n",
            "tensor(3.2246, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2246, device='cuda:0') sum\n",
            "loc loss here 769.9999937415123\n",
            "tensor(3.2799, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2799, device='cuda:0') sum\n",
            "loc loss here 770.9999937415123\n",
            "tensor(3.7455, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7455, device='cuda:0') sum\n",
            "loc loss here 771.9999937415123\n",
            "tensor(2.6935, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6935, device='cuda:0') sum\n",
            "loc loss here 772.9999937415123\n",
            "tensor(3.4644, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4644, device='cuda:0') sum\n",
            "loc loss here 773.9999936819077\n",
            "tensor(4.2161, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2161, device='cuda:0') sum\n",
            "loc loss here 774.9999936819077\n",
            "tensor(3.6199, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6199, device='cuda:0') sum\n",
            "loc loss here 775.999993622303\n",
            "tensor(4.0854, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0854, device='cuda:0') sum\n",
            "loc loss here 776.999993622303\n",
            "tensor(3.1317, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1317, device='cuda:0') sum\n",
            "loc loss here 777.999993622303\n",
            "tensor(6.1870, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(6.1870, device='cuda:0') sum\n",
            "loc loss here 778.999993622303\n",
            "tensor(2.4516, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4516, device='cuda:0') sum\n",
            "loc loss here 779.999993622303\n",
            "tensor(2.5993, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5993, device='cuda:0') sum\n",
            "loc loss here 780.999993622303\n",
            "tensor(3.2269, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2269, device='cuda:0') sum\n",
            "loc loss here 781.9999935626984\n",
            "tensor(2.9518, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9518, device='cuda:0') sum\n",
            "loc loss here 782.9999935626984\n",
            "tensor(4.2298, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2298, device='cuda:0') sum\n",
            "loc loss here 783.9999935626984\n",
            "tensor(3.6604, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6604, device='cuda:0') sum\n",
            "loc loss here 784.9999935030937\n",
            "tensor(2.9617, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9617, device='cuda:0') sum\n",
            "loc loss here 785.9999934434891\n",
            "tensor(3.1333, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1333, device='cuda:0') sum\n",
            "loc loss here 786.9999934434891\n",
            "tensor(3.4419, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4419, device='cuda:0') sum\n",
            "loc loss here 787.9999934434891\n",
            "tensor(3.2891, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2891, device='cuda:0') sum\n",
            "loc loss here 788.9999934434891\n",
            "tensor(3.7217, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7217, device='cuda:0') sum\n",
            "loc loss here 789.9999934434891\n",
            "tensor(3.1731, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1731, device='cuda:0') sum\n",
            "loc loss here 790.9999933838844\n",
            "tensor(3.3697, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3697, device='cuda:0') sum\n",
            "loc loss here 791.9999933838844\n",
            "tensor(3.6430, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6430, device='cuda:0') sum\n",
            "loc loss here 792.9999933838844\n",
            "tensor(1.7836, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.7836, device='cuda:0') sum\n",
            "loc loss here 793.9999933242798\n",
            "tensor(4.3389, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3389, device='cuda:0') sum\n",
            "loc loss here 794.9999933242798\n",
            "tensor(4.1766, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1766, device='cuda:0') sum\n",
            "loc loss here 795.9999933242798\n",
            "tensor(3.6190, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6190, device='cuda:0') sum\n",
            "loc loss here 796.9999933242798\n",
            "tensor(3.1722, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1722, device='cuda:0') sum\n",
            "loc loss here 797.9999933242798\n",
            "tensor(4.4757, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.4757, device='cuda:0') sum\n",
            "loc loss here 798.9999933242798\n",
            "tensor(2.7266, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7266, device='cuda:0') sum\n",
            "loc loss here 799.9999933242798\n",
            "tensor(1.9448, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.9448, device='cuda:0') sum\n",
            "loc loss here 800.9999933242798\n",
            "  800 of  1143 \t L: 1.000 \t -- 164.080\n",
            "tensor(3.9573, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9573, device='cuda:0') sum\n",
            "loc loss here 801.9999933242798\n",
            "tensor(3.4465, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4465, device='cuda:0') sum\n",
            "loc loss here 802.9999933242798\n",
            "tensor(1.6094, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.6094, device='cuda:0') sum\n",
            "loc loss here 803.9999933242798\n",
            "tensor(2.3607, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3607, device='cuda:0') sum\n",
            "loc loss here 804.9999933242798\n",
            "tensor(3.8399, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8399, device='cuda:0') sum\n",
            "loc loss here 805.9999933242798\n",
            "tensor(3.0831, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0831, device='cuda:0') sum\n",
            "loc loss here 806.9999933242798\n",
            "tensor(2.4311, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4311, device='cuda:0') sum\n",
            "loc loss here 807.9999933242798\n",
            "tensor(3.1851, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1851, device='cuda:0') sum\n",
            "loc loss here 808.9999933242798\n",
            "tensor(2.9134, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9134, device='cuda:0') sum\n",
            "loc loss here 809.9999933242798\n",
            "tensor(3.5289, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5289, device='cuda:0') sum\n",
            "loc loss here 810.9999932646751\n",
            "tensor(3.3333, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3333, device='cuda:0') sum\n",
            "loc loss here 811.9999932646751\n",
            "tensor(3.7691, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7691, device='cuda:0') sum\n",
            "loc loss here 812.9999932050705\n",
            "tensor(4.5030, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5030, device='cuda:0') sum\n",
            "loc loss here 813.9999932050705\n",
            "tensor(3.8138, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8138, device='cuda:0') sum\n",
            "loc loss here 814.9999932050705\n",
            "tensor(3.1403, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1403, device='cuda:0') sum\n",
            "loc loss here 815.9999931454659\n",
            "tensor(4.0883, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0883, device='cuda:0') sum\n",
            "loc loss here 816.9999931454659\n",
            "tensor(2.4544, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4544, device='cuda:0') sum\n",
            "loc loss here 817.9999931454659\n",
            "tensor(3.6702, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6702, device='cuda:0') sum\n",
            "loc loss here 818.9999931454659\n",
            "tensor(3.1030, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1030, device='cuda:0') sum\n",
            "loc loss here 819.9999930858612\n",
            "tensor(3.5429, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5429, device='cuda:0') sum\n",
            "loc loss here 820.9999930858612\n",
            "tensor(2.9548, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9548, device='cuda:0') sum\n",
            "loc loss here 821.9999930262566\n",
            "tensor(3.1412, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1412, device='cuda:0') sum\n",
            "loc loss here 822.9999930262566\n",
            "tensor(4.6658, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.6658, device='cuda:0') sum\n",
            "loc loss here 823.9999930262566\n",
            "tensor(3.5917, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5917, device='cuda:0') sum\n",
            "loc loss here 824.9999929666519\n",
            "tensor(3.5409, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5409, device='cuda:0') sum\n",
            "loc loss here 825.9999929070473\n",
            "tensor(3.4567, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4567, device='cuda:0') sum\n",
            "loc loss here 826.9999928474426\n",
            "tensor(3.2458, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2458, device='cuda:0') sum\n",
            "loc loss here 827.9999928474426\n",
            "tensor(3.5083, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5083, device='cuda:0') sum\n",
            "loc loss here 828.9999928474426\n",
            "tensor(2.9913, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9913, device='cuda:0') sum\n",
            "loc loss here 829.9999928474426\n",
            "tensor(3.5198, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5198, device='cuda:0') sum\n",
            "loc loss here 830.9999928474426\n",
            "tensor(3.3002, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3002, device='cuda:0') sum\n",
            "loc loss here 831.9999928474426\n",
            "tensor(4.3104, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3104, device='cuda:0') sum\n",
            "loc loss here 832.9999928474426\n",
            "tensor(4.3083, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3083, device='cuda:0') sum\n",
            "loc loss here 833.9999928474426\n",
            "tensor(3.9337, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9337, device='cuda:0') sum\n",
            "loc loss here 834.9999928474426\n",
            "tensor(3.3585, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3585, device='cuda:0') sum\n",
            "loc loss here 835.999992787838\n",
            "tensor(3.7658, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7658, device='cuda:0') sum\n",
            "loc loss here 836.999992787838\n",
            "tensor(4.8748, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.8748, device='cuda:0') sum\n",
            "loc loss here 837.999992787838\n",
            "tensor(2.1081, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.1081, device='cuda:0') sum\n",
            "loc loss here 838.999992787838\n",
            "tensor(2.6891, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6891, device='cuda:0') sum\n",
            "loc loss here 839.999992787838\n",
            "tensor(2.9604, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9604, device='cuda:0') sum\n",
            "loc loss here 840.9999927282333\n",
            "tensor(3.3528, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3528, device='cuda:0') sum\n",
            "loc loss here 841.9999927282333\n",
            "tensor(4.5153, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5153, device='cuda:0') sum\n",
            "loc loss here 842.9999927282333\n",
            "tensor(3.2299, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2299, device='cuda:0') sum\n",
            "loc loss here 843.9999926686287\n",
            "tensor(3.7411, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7411, device='cuda:0') sum\n",
            "loc loss here 844.9999926686287\n",
            "tensor(3.7082, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7082, device='cuda:0') sum\n",
            "loc loss here 845.9999926686287\n",
            "tensor(3.2338, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2338, device='cuda:0') sum\n",
            "loc loss here 846.9999926686287\n",
            "tensor(3.6720, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6720, device='cuda:0') sum\n",
            "loc loss here 847.9999926686287\n",
            "tensor(4.1228, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1228, device='cuda:0') sum\n",
            "loc loss here 848.9999926686287\n",
            "tensor(3.3319, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3319, device='cuda:0') sum\n",
            "loc loss here 849.9999926686287\n",
            "tensor(3.8890, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8890, device='cuda:0') sum\n",
            "loc loss here 850.9999926686287\n",
            "tensor(3.8163, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8163, device='cuda:0') sum\n",
            "loc loss here 851.9999926686287\n",
            "tensor(4.5686, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5686, device='cuda:0') sum\n",
            "loc loss here 852.9999926686287\n",
            "tensor(2.3191, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3191, device='cuda:0') sum\n",
            "loc loss here 853.9999926686287\n",
            "tensor(4.2751, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2751, device='cuda:0') sum\n",
            "loc loss here 854.9999926686287\n",
            "tensor(4.1113, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1113, device='cuda:0') sum\n",
            "loc loss here 855.9999926686287\n",
            "tensor(3.3175, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3175, device='cuda:0') sum\n",
            "loc loss here 856.9999926686287\n",
            "tensor(2.8933, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8933, device='cuda:0') sum\n",
            "loc loss here 857.9999926686287\n",
            "tensor(4.2730, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2730, device='cuda:0') sum\n",
            "loc loss here 858.9999926686287\n",
            "tensor(4.4618, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.4618, device='cuda:0') sum\n",
            "loc loss here 859.999992609024\n",
            "tensor(2.0327, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.0327, device='cuda:0') sum\n",
            "loc loss here 860.999992609024\n",
            "tensor(3.5156, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5156, device='cuda:0') sum\n",
            "loc loss here 861.999992609024\n",
            "tensor(4.0654, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0654, device='cuda:0') sum\n",
            "loc loss here 862.999992609024\n",
            "tensor(3.0588, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0588, device='cuda:0') sum\n",
            "loc loss here 863.999992609024\n",
            "tensor(4.5508, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5508, device='cuda:0') sum\n",
            "loc loss here 864.999992609024\n",
            "tensor(3.5105, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5105, device='cuda:0') sum\n",
            "loc loss here 865.999992609024\n",
            "tensor(3.2003, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2003, device='cuda:0') sum\n",
            "loc loss here 866.999992609024\n",
            "tensor(2.9825, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9825, device='cuda:0') sum\n",
            "loc loss here 867.999992609024\n",
            "tensor(2.5850, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5850, device='cuda:0') sum\n",
            "loc loss here 868.999992609024\n",
            "tensor(3.6594, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6594, device='cuda:0') sum\n",
            "loc loss here 869.9999925494194\n",
            "tensor(3.9303, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9303, device='cuda:0') sum\n",
            "loc loss here 870.9999925494194\n",
            "tensor(3.1315, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1315, device='cuda:0') sum\n",
            "loc loss here 871.9999924898148\n",
            "tensor(3.2034, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2034, device='cuda:0') sum\n",
            "loc loss here 872.9999924898148\n",
            "tensor(3.5657, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5657, device='cuda:0') sum\n",
            "loc loss here 873.9999924898148\n",
            "tensor(3.6095, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6095, device='cuda:0') sum\n",
            "loc loss here 874.9999924898148\n",
            "tensor(3.4186, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4186, device='cuda:0') sum\n",
            "loc loss here 875.9999924898148\n",
            "tensor(2.6320, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6320, device='cuda:0') sum\n",
            "loc loss here 876.9999924898148\n",
            "tensor(1.8720, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.8720, device='cuda:0') sum\n",
            "loc loss here 877.9999924898148\n",
            "tensor(3.7252, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7252, device='cuda:0') sum\n",
            "loc loss here 878.9999924302101\n",
            "tensor(4.1113, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1113, device='cuda:0') sum\n",
            "loc loss here 879.9999924302101\n",
            "tensor(3.4672, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4672, device='cuda:0') sum\n",
            "loc loss here 880.9999924302101\n",
            "tensor(1.7283, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.7283, device='cuda:0') sum\n",
            "loc loss here 881.9999924302101\n",
            "tensor(3.4635, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4635, device='cuda:0') sum\n",
            "loc loss here 882.9999923706055\n",
            "tensor(3.5924, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5924, device='cuda:0') sum\n",
            "loc loss here 883.9999923706055\n",
            "tensor(3.6949, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6949, device='cuda:0') sum\n",
            "loc loss here 884.9999923706055\n",
            "tensor(3.0216, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0216, device='cuda:0') sum\n",
            "loc loss here 885.9999923706055\n",
            "tensor(3.1776, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1776, device='cuda:0') sum\n",
            "loc loss here 886.9999923706055\n",
            "tensor(2.5901, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5901, device='cuda:0') sum\n",
            "loc loss here 887.9999923706055\n",
            "tensor(3.7869, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7869, device='cuda:0') sum\n",
            "loc loss here 888.9999923706055\n",
            "tensor(2.3276, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3276, device='cuda:0') sum\n",
            "loc loss here 889.9999923706055\n",
            "tensor(3.9298, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9298, device='cuda:0') sum\n",
            "loc loss here 890.9999923706055\n",
            "tensor(2.9956, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9956, device='cuda:0') sum\n",
            "loc loss here 891.9999923706055\n",
            "tensor(3.1714, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1714, device='cuda:0') sum\n",
            "loc loss here 892.9999923706055\n",
            "tensor(1.4558, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.4558, device='cuda:0') sum\n",
            "loc loss here 893.9999923706055\n",
            "tensor(4.3904, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3904, device='cuda:0') sum\n",
            "loc loss here 894.9999923706055\n",
            "tensor(4.0368, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0368, device='cuda:0') sum\n",
            "loc loss here 895.9999923706055\n",
            "tensor(3.7332, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7332, device='cuda:0') sum\n",
            "loc loss here 896.9999923706055\n",
            "tensor(5.0417, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.0417, device='cuda:0') sum\n",
            "loc loss here 897.9999923706055\n",
            "tensor(3.2009, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2009, device='cuda:0') sum\n",
            "loc loss here 898.9999923706055\n",
            "tensor(2.4094, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4094, device='cuda:0') sum\n",
            "loc loss here 899.9999923706055\n",
            "tensor(3.5586, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5586, device='cuda:0') sum\n",
            "loc loss here 900.9999923706055\n",
            "  900 of  1143 \t L: 1.000 \t -- 184.107\n",
            "tensor(3.5180, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5180, device='cuda:0') sum\n",
            "loc loss here 901.9999923110008\n",
            "tensor(3.3640, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3640, device='cuda:0') sum\n",
            "loc loss here 902.9999923110008\n",
            "tensor(3.1899, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1899, device='cuda:0') sum\n",
            "loc loss here 903.9999923110008\n",
            "tensor(5.4627, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.4627, device='cuda:0') sum\n",
            "loc loss here 904.9999923110008\n",
            "tensor(3.6353, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6353, device='cuda:0') sum\n",
            "loc loss here 905.9999922513962\n",
            "tensor(3.9614, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9614, device='cuda:0') sum\n",
            "loc loss here 906.9999922513962\n",
            "tensor(2.2815, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2815, device='cuda:0') sum\n",
            "loc loss here 907.9999922513962\n",
            "tensor(3.2130, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2130, device='cuda:0') sum\n",
            "loc loss here 908.9999921917915\n",
            "tensor(3.1053, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1053, device='cuda:0') sum\n",
            "loc loss here 909.9999921917915\n",
            "tensor(4.4971, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.4971, device='cuda:0') sum\n",
            "loc loss here 910.9999921917915\n",
            "tensor(2.6582, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6582, device='cuda:0') sum\n",
            "loc loss here 911.9999921917915\n",
            "tensor(3.8892, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8892, device='cuda:0') sum\n",
            "loc loss here 912.9999921917915\n",
            "tensor(3.2384, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2384, device='cuda:0') sum\n",
            "loc loss here 913.9999921917915\n",
            "tensor(3.2282, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2282, device='cuda:0') sum\n",
            "loc loss here 914.9999921917915\n",
            "tensor(2.3251, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3251, device='cuda:0') sum\n",
            "loc loss here 915.9999921917915\n",
            "tensor(2.0923, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.0923, device='cuda:0') sum\n",
            "loc loss here 916.9999921917915\n",
            "tensor(3.9932, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9932, device='cuda:0') sum\n",
            "loc loss here 917.9999921917915\n",
            "tensor(3.7039, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7039, device='cuda:0') sum\n",
            "loc loss here 918.9999921917915\n",
            "tensor(4.0215, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0215, device='cuda:0') sum\n",
            "loc loss here 919.9999921917915\n",
            "tensor(3.3611, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3611, device='cuda:0') sum\n",
            "loc loss here 920.9999921321869\n",
            "tensor(2.2480, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2480, device='cuda:0') sum\n",
            "loc loss here 921.9999921321869\n",
            "tensor(3.7232, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7232, device='cuda:0') sum\n",
            "loc loss here 922.9999921321869\n",
            "tensor(2.6986, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6986, device='cuda:0') sum\n",
            "loc loss here 923.9999921321869\n",
            "tensor(2.5681, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5681, device='cuda:0') sum\n",
            "loc loss here 924.9999921321869\n",
            "tensor(3.4339, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4339, device='cuda:0') sum\n",
            "loc loss here 925.9999921321869\n",
            "tensor(3.3335, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3335, device='cuda:0') sum\n",
            "loc loss here 926.9999920725822\n",
            "tensor(2.6826, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6826, device='cuda:0') sum\n",
            "loc loss here 927.9999920725822\n",
            "tensor(2.7297, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7297, device='cuda:0') sum\n",
            "loc loss here 928.9999920725822\n",
            "tensor(4.1201, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1201, device='cuda:0') sum\n",
            "loc loss here 929.9999920725822\n",
            "tensor(3.5474, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5474, device='cuda:0') sum\n",
            "loc loss here 930.9999920725822\n",
            "tensor(4.2955, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2955, device='cuda:0') sum\n",
            "loc loss here 931.9999920725822\n",
            "tensor(4.1875, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1875, device='cuda:0') sum\n",
            "loc loss here 932.9999920725822\n",
            "tensor(4.1844, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1844, device='cuda:0') sum\n",
            "loc loss here 933.9999920725822\n",
            "tensor(3.7810, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7810, device='cuda:0') sum\n",
            "loc loss here 934.9999920129776\n",
            "tensor(3.1984, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1984, device='cuda:0') sum\n",
            "loc loss here 935.9999920129776\n",
            "tensor(2.3932, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3932, device='cuda:0') sum\n",
            "loc loss here 936.9999920129776\n",
            "tensor(3.6649, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6649, device='cuda:0') sum\n",
            "loc loss here 937.9999920129776\n",
            "tensor(3.2385, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2385, device='cuda:0') sum\n",
            "loc loss here 938.9999920129776\n",
            "tensor(4.4858, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.4858, device='cuda:0') sum\n",
            "loc loss here 939.9999920129776\n",
            "tensor(3.5415, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5415, device='cuda:0') sum\n",
            "loc loss here 940.9999920129776\n",
            "tensor(4.0114, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0114, device='cuda:0') sum\n",
            "loc loss here 941.9999920129776\n",
            "tensor(3.1142, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1142, device='cuda:0') sum\n",
            "loc loss here 942.9999920129776\n",
            "tensor(2.4865, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4865, device='cuda:0') sum\n",
            "loc loss here 943.9999920129776\n",
            "tensor(3.7641, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7641, device='cuda:0') sum\n",
            "loc loss here 944.9999920129776\n",
            "tensor(4.1148, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1148, device='cuda:0') sum\n",
            "loc loss here 945.9999920129776\n",
            "tensor(3.4254, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4254, device='cuda:0') sum\n",
            "loc loss here 946.9999920129776\n",
            "tensor(4.4660, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.4660, device='cuda:0') sum\n",
            "loc loss here 947.9999920129776\n",
            "tensor(3.6394, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6394, device='cuda:0') sum\n",
            "loc loss here 948.9999920129776\n",
            "tensor(5.6576, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.6576, device='cuda:0') sum\n",
            "loc loss here 949.9999920129776\n",
            "tensor(3.4913, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4913, device='cuda:0') sum\n",
            "loc loss here 950.9999920129776\n",
            "tensor(2.5360, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5360, device='cuda:0') sum\n",
            "loc loss here 951.9999920129776\n",
            "tensor(4.6181, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.6181, device='cuda:0') sum\n",
            "loc loss here 952.9999920129776\n",
            "tensor(4.5335, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5335, device='cuda:0') sum\n",
            "loc loss here 953.9999920129776\n",
            "tensor(1.7110, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.7110, device='cuda:0') sum\n",
            "loc loss here 954.9999920129776\n",
            "tensor(3.5709, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5709, device='cuda:0') sum\n",
            "loc loss here 955.9999920129776\n",
            "tensor(3.2773, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2773, device='cuda:0') sum\n",
            "loc loss here 956.999991953373\n",
            "tensor(3.4459, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4459, device='cuda:0') sum\n",
            "loc loss here 957.999991953373\n",
            "tensor(4.0265, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0265, device='cuda:0') sum\n",
            "loc loss here 958.999991953373\n",
            "tensor(3.2148, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2148, device='cuda:0') sum\n",
            "loc loss here 959.999991953373\n",
            "tensor(3.0250, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0250, device='cuda:0') sum\n",
            "loc loss here 960.999991953373\n",
            "tensor(3.7291, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7291, device='cuda:0') sum\n",
            "loc loss here 961.999991953373\n",
            "tensor(3.4015, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4015, device='cuda:0') sum\n",
            "loc loss here 962.999991953373\n",
            "tensor(3.8168, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8168, device='cuda:0') sum\n",
            "loc loss here 963.999991953373\n",
            "tensor(3.5596, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5596, device='cuda:0') sum\n",
            "loc loss here 964.999991953373\n",
            "tensor(3.9927, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9927, device='cuda:0') sum\n",
            "loc loss here 965.999991953373\n",
            "tensor(3.3416, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3416, device='cuda:0') sum\n",
            "loc loss here 966.9999918937683\n",
            "tensor(3.5949, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5949, device='cuda:0') sum\n",
            "loc loss here 967.9999918937683\n",
            "tensor(2.6470, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6470, device='cuda:0') sum\n",
            "loc loss here 968.9999918937683\n",
            "tensor(3.6488, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6488, device='cuda:0') sum\n",
            "loc loss here 969.9999918937683\n",
            "tensor(3.4701, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4701, device='cuda:0') sum\n",
            "loc loss here 970.9999918937683\n",
            "tensor(3.0902, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0902, device='cuda:0') sum\n",
            "loc loss here 971.9999918937683\n",
            "tensor(3.7482, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7482, device='cuda:0') sum\n",
            "loc loss here 972.9999918937683\n",
            "tensor(3.5013, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5013, device='cuda:0') sum\n",
            "loc loss here 973.9999918341637\n",
            "tensor(3.0184, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0184, device='cuda:0') sum\n",
            "loc loss here 974.999991774559\n",
            "tensor(4.8712, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.8712, device='cuda:0') sum\n",
            "loc loss here 975.999991774559\n",
            "tensor(2.5855, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5855, device='cuda:0') sum\n",
            "loc loss here 976.999991774559\n",
            "tensor(3.4000, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4000, device='cuda:0') sum\n",
            "loc loss here 977.999991774559\n",
            "tensor(2.4940, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4940, device='cuda:0') sum\n",
            "loc loss here 978.999991774559\n",
            "tensor(3.1802, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1802, device='cuda:0') sum\n",
            "loc loss here 979.999991774559\n",
            "tensor(3.0335, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0335, device='cuda:0') sum\n",
            "loc loss here 980.999991774559\n",
            "tensor(4.8195, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.8195, device='cuda:0') sum\n",
            "loc loss here 981.999991774559\n",
            "tensor(3.0626, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0626, device='cuda:0') sum\n",
            "loc loss here 982.999991774559\n",
            "tensor(3.2747, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2747, device='cuda:0') sum\n",
            "loc loss here 983.999991774559\n",
            "tensor(3.9867, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9867, device='cuda:0') sum\n",
            "loc loss here 984.999991774559\n",
            "tensor(2.9311, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9311, device='cuda:0') sum\n",
            "loc loss here 985.9999917149544\n",
            "tensor(4.6519, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.6519, device='cuda:0') sum\n",
            "loc loss here 986.9999916553497\n",
            "tensor(2.9202, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9202, device='cuda:0') sum\n",
            "loc loss here 987.9999916553497\n",
            "tensor(2.0109, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.0109, device='cuda:0') sum\n",
            "loc loss here 988.9999916553497\n",
            "tensor(3.9666, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9666, device='cuda:0') sum\n",
            "loc loss here 989.9999916553497\n",
            "tensor(2.7254, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7254, device='cuda:0') sum\n",
            "loc loss here 990.9999916553497\n",
            "tensor(2.4359, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4359, device='cuda:0') sum\n",
            "loc loss here 991.9999916553497\n",
            "tensor(4.4745, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.4745, device='cuda:0') sum\n",
            "loc loss here 992.9999916553497\n",
            "tensor(4.1353, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1353, device='cuda:0') sum\n",
            "loc loss here 993.9999916553497\n",
            "tensor(3.2191, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2191, device='cuda:0') sum\n",
            "loc loss here 994.9999916553497\n",
            "tensor(3.7364, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7364, device='cuda:0') sum\n",
            "loc loss here 995.9999916553497\n",
            "tensor(3.8037, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8037, device='cuda:0') sum\n",
            "loc loss here 996.9999916553497\n",
            "tensor(3.0036, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0036, device='cuda:0') sum\n",
            "loc loss here 997.9999916553497\n",
            "tensor(3.1742, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1742, device='cuda:0') sum\n",
            "loc loss here 998.9999916553497\n",
            "tensor(3.5590, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5590, device='cuda:0') sum\n",
            "loc loss here 999.9999916553497\n",
            "tensor(2.2660, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2660, device='cuda:0') sum\n",
            "loc loss here 1000.9999916553497\n",
            " 1000 of  1143 \t L: 1.000 \t -- 204.336\n",
            "tensor(2.4508, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4508, device='cuda:0') sum\n",
            "loc loss here 1001.9999916553497\n",
            "tensor(3.7918, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7918, device='cuda:0') sum\n",
            "loc loss here 1002.9999916553497\n",
            "tensor(3.1459, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1459, device='cuda:0') sum\n",
            "loc loss here 1003.9999916553497\n",
            "tensor(3.2924, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2924, device='cuda:0') sum\n",
            "loc loss here 1004.9999915957451\n",
            "tensor(3.5534, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5534, device='cuda:0') sum\n",
            "loc loss here 1005.9999915957451\n",
            "tensor(3.5688, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5688, device='cuda:0') sum\n",
            "loc loss here 1006.9999915957451\n",
            "tensor(4.7120, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.7120, device='cuda:0') sum\n",
            "loc loss here 1007.9999915957451\n",
            "tensor(3.9891, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9891, device='cuda:0') sum\n",
            "loc loss here 1008.9999915957451\n",
            "tensor(3.6427, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6427, device='cuda:0') sum\n",
            "loc loss here 1009.9999915957451\n",
            "tensor(2.8289, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8289, device='cuda:0') sum\n",
            "loc loss here 1010.9999915957451\n",
            "tensor(3.7136, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7136, device='cuda:0') sum\n",
            "loc loss here 1011.9999915957451\n",
            "tensor(4.0275, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0275, device='cuda:0') sum\n",
            "loc loss here 1012.9999915957451\n",
            "tensor(2.9147, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9147, device='cuda:0') sum\n",
            "loc loss here 1013.9999915361404\n",
            "tensor(2.5162, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5162, device='cuda:0') sum\n",
            "loc loss here 1014.9999915361404\n",
            "tensor(2.8711, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8711, device='cuda:0') sum\n",
            "loc loss here 1015.9999915361404\n",
            "tensor(3.0990, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0990, device='cuda:0') sum\n",
            "loc loss here 1016.9999914765358\n",
            "tensor(3.2705, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2705, device='cuda:0') sum\n",
            "loc loss here 1017.9999914765358\n",
            "tensor(2.2220, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.2220, device='cuda:0') sum\n",
            "loc loss here 1018.9999914765358\n",
            "tensor(3.7375, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7375, device='cuda:0') sum\n",
            "loc loss here 1019.9999914765358\n",
            "tensor(2.7816, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7816, device='cuda:0') sum\n",
            "loc loss here 1020.9999914169312\n",
            "tensor(3.2972, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2972, device='cuda:0') sum\n",
            "loc loss here 1021.9999914169312\n",
            "tensor(2.9534, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9534, device='cuda:0') sum\n",
            "loc loss here 1022.9999914169312\n",
            "tensor(2.6356, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6356, device='cuda:0') sum\n",
            "loc loss here 1023.9999913573265\n",
            "tensor(2.9048, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9048, device='cuda:0') sum\n",
            "loc loss here 1024.9999913573265\n",
            "tensor(3.7820, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7820, device='cuda:0') sum\n",
            "loc loss here 1025.9999913573265\n",
            "tensor(4.0325, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0325, device='cuda:0') sum\n",
            "loc loss here 1026.9999913573265\n",
            "tensor(4.5093, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5093, device='cuda:0') sum\n",
            "loc loss here 1027.9999913573265\n",
            "tensor(3.6195, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6195, device='cuda:0') sum\n",
            "loc loss here 1028.9999912977219\n",
            "tensor(2.5897, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5897, device='cuda:0') sum\n",
            "loc loss here 1029.9999912977219\n",
            "tensor(4.0172, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0172, device='cuda:0') sum\n",
            "loc loss here 1030.9999912977219\n",
            "tensor(3.5122, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5122, device='cuda:0') sum\n",
            "loc loss here 1031.9999912381172\n",
            "tensor(3.7038, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7038, device='cuda:0') sum\n",
            "loc loss here 1032.9999912381172\n",
            "tensor(4.7326, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.7326, device='cuda:0') sum\n",
            "loc loss here 1033.9999912381172\n",
            "tensor(3.4694, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4694, device='cuda:0') sum\n",
            "loc loss here 1034.9999912381172\n",
            "tensor(3.2519, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2519, device='cuda:0') sum\n",
            "loc loss here 1035.9999912381172\n",
            "tensor(4.0725, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0725, device='cuda:0') sum\n",
            "loc loss here 1036.9999912381172\n",
            "tensor(2.7831, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7831, device='cuda:0') sum\n",
            "loc loss here 1037.9999912381172\n",
            "tensor(3.7065, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7065, device='cuda:0') sum\n",
            "loc loss here 1038.9999911785126\n",
            "tensor(3.4480, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4480, device='cuda:0') sum\n",
            "loc loss here 1039.9999911785126\n",
            "tensor(4.6553, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.6553, device='cuda:0') sum\n",
            "loc loss here 1040.9999911785126\n",
            "tensor(3.3050, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3050, device='cuda:0') sum\n",
            "loc loss here 1041.9999911785126\n",
            "tensor(3.2913, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2913, device='cuda:0') sum\n",
            "loc loss here 1042.999991118908\n",
            "tensor(2.4484, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4484, device='cuda:0') sum\n",
            "loc loss here 1043.999991118908\n",
            "tensor(2.8167, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8167, device='cuda:0') sum\n",
            "loc loss here 1044.9999910593033\n",
            "tensor(3.8988, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8988, device='cuda:0') sum\n",
            "loc loss here 1045.9999909996986\n",
            "tensor(4.0923, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0923, device='cuda:0') sum\n",
            "loc loss here 1046.9999909996986\n",
            "tensor(4.6804, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.6804, device='cuda:0') sum\n",
            "loc loss here 1047.9999909996986\n",
            "tensor(3.4353, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4353, device='cuda:0') sum\n",
            "loc loss here 1048.9999909996986\n",
            "tensor(2.5738, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5738, device='cuda:0') sum\n",
            "loc loss here 1049.9999909996986\n",
            "tensor(2.8046, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8046, device='cuda:0') sum\n",
            "loc loss here 1050.9999909996986\n",
            "tensor(4.5843, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5843, device='cuda:0') sum\n",
            "loc loss here 1051.9999909996986\n",
            "tensor(3.0563, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0563, device='cuda:0') sum\n",
            "loc loss here 1052.999990940094\n",
            "tensor(3.6407, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6407, device='cuda:0') sum\n",
            "loc loss here 1053.999990940094\n",
            "tensor(2.7719, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7719, device='cuda:0') sum\n",
            "loc loss here 1054.999990940094\n",
            "tensor(3.9420, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9420, device='cuda:0') sum\n",
            "loc loss here 1055.999990940094\n",
            "tensor(3.5752, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5752, device='cuda:0') sum\n",
            "loc loss here 1056.999990940094\n",
            "tensor(2.8328, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8328, device='cuda:0') sum\n",
            "loc loss here 1057.999990940094\n",
            "tensor(3.0484, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0484, device='cuda:0') sum\n",
            "loc loss here 1058.999990940094\n",
            "tensor(3.4895, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4895, device='cuda:0') sum\n",
            "loc loss here 1059.999990940094\n",
            "tensor(2.1203, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.1203, device='cuda:0') sum\n",
            "loc loss here 1060.999990940094\n",
            "tensor(3.3585, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3585, device='cuda:0') sum\n",
            "loc loss here 1061.999990940094\n",
            "tensor(3.1230, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1230, device='cuda:0') sum\n",
            "loc loss here 1062.999990940094\n",
            "tensor(2.9047, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9047, device='cuda:0') sum\n",
            "loc loss here 1063.999990940094\n",
            "tensor(4.0376, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0376, device='cuda:0') sum\n",
            "loc loss here 1064.999990940094\n",
            "tensor(3.6897, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6897, device='cuda:0') sum\n",
            "loc loss here 1065.999990940094\n",
            "tensor(3.8020, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.8020, device='cuda:0') sum\n",
            "loc loss here 1066.999990940094\n",
            "tensor(3.6234, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6234, device='cuda:0') sum\n",
            "loc loss here 1067.999990940094\n",
            "tensor(3.4064, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4064, device='cuda:0') sum\n",
            "loc loss here 1068.999990940094\n",
            "tensor(3.2464, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2464, device='cuda:0') sum\n",
            "loc loss here 1069.999990940094\n",
            "tensor(3.7174, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7174, device='cuda:0') sum\n",
            "loc loss here 1070.999990940094\n",
            "tensor(3.9717, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9717, device='cuda:0') sum\n",
            "loc loss here 1071.999990940094\n",
            "tensor(4.2588, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2588, device='cuda:0') sum\n",
            "loc loss here 1072.999990940094\n",
            "tensor(2.5396, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5396, device='cuda:0') sum\n",
            "loc loss here 1073.999990940094\n",
            "tensor(3.1193, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1193, device='cuda:0') sum\n",
            "loc loss here 1074.999990940094\n",
            "tensor(2.5321, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5321, device='cuda:0') sum\n",
            "loc loss here 1075.999990940094\n",
            "tensor(2.9588, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9588, device='cuda:0') sum\n",
            "loc loss here 1076.999990940094\n",
            "tensor(3.5946, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5946, device='cuda:0') sum\n",
            "loc loss here 1077.999990940094\n",
            "tensor(2.5257, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5257, device='cuda:0') sum\n",
            "loc loss here 1078.999990940094\n",
            "tensor(3.5811, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5811, device='cuda:0') sum\n",
            "loc loss here 1079.999990940094\n",
            "tensor(4.2107, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2107, device='cuda:0') sum\n",
            "loc loss here 1080.999990940094\n",
            "tensor(2.9105, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9105, device='cuda:0') sum\n",
            "loc loss here 1081.999990940094\n",
            "tensor(4.3085, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.3085, device='cuda:0') sum\n",
            "loc loss here 1082.999990940094\n",
            "tensor(3.4266, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4266, device='cuda:0') sum\n",
            "loc loss here 1083.999990940094\n",
            "tensor(2.7239, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7239, device='cuda:0') sum\n",
            "loc loss here 1084.9999908804893\n",
            "tensor(3.4171, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4171, device='cuda:0') sum\n",
            "loc loss here 1085.9999908208847\n",
            "tensor(3.3753, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3753, device='cuda:0') sum\n",
            "loc loss here 1086.99999076128\n",
            "tensor(2.6239, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6239, device='cuda:0') sum\n",
            "loc loss here 1087.9999907016754\n",
            "tensor(2.3678, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.3678, device='cuda:0') sum\n",
            "loc loss here 1088.9999907016754\n",
            "tensor(3.5929, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5929, device='cuda:0') sum\n",
            "loc loss here 1089.9999906420708\n",
            "tensor(3.1159, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1159, device='cuda:0') sum\n",
            "loc loss here 1090.9999906420708\n",
            "tensor(3.0280, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0280, device='cuda:0') sum\n",
            "loc loss here 1091.9999906420708\n",
            "tensor(3.2672, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2672, device='cuda:0') sum\n",
            "loc loss here 1092.9999906420708\n",
            "tensor(2.4937, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4937, device='cuda:0') sum\n",
            "loc loss here 1093.9999906420708\n",
            "tensor(5.5747, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(5.5747, device='cuda:0') sum\n",
            "loc loss here 1094.9999906420708\n",
            "tensor(3.0825, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0825, device='cuda:0') sum\n",
            "loc loss here 1095.9999906420708\n",
            "tensor(2.8708, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8708, device='cuda:0') sum\n",
            "loc loss here 1096.9999906420708\n",
            "tensor(2.9821, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9821, device='cuda:0') sum\n",
            "loc loss here 1097.9999905824661\n",
            "tensor(3.5559, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5559, device='cuda:0') sum\n",
            "loc loss here 1098.9999905824661\n",
            "tensor(4.2587, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2587, device='cuda:0') sum\n",
            "loc loss here 1099.9999905824661\n",
            "tensor(4.0583, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.0583, device='cuda:0') sum\n",
            "loc loss here 1100.9999905824661\n",
            " 1100 of  1143 \t L: 1.000 \t -- 224.133\n",
            "tensor(3.5710, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5710, device='cuda:0') sum\n",
            "loc loss here 1101.9999905824661\n",
            "tensor(2.5868, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5868, device='cuda:0') sum\n",
            "loc loss here 1102.9999905824661\n",
            "tensor(3.4234, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4234, device='cuda:0') sum\n",
            "loc loss here 1103.9999905228615\n",
            "tensor(3.3081, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3081, device='cuda:0') sum\n",
            "loc loss here 1104.9999904632568\n",
            "tensor(2.1414, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.1414, device='cuda:0') sum\n",
            "loc loss here 1105.9999904632568\n",
            "tensor(3.7652, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7652, device='cuda:0') sum\n",
            "loc loss here 1106.9999904632568\n",
            "tensor(4.5850, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.5850, device='cuda:0') sum\n",
            "loc loss here 1107.9999904632568\n",
            "tensor(2.8828, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8828, device='cuda:0') sum\n",
            "loc loss here 1108.9999904632568\n",
            "tensor(3.6520, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.6520, device='cuda:0') sum\n",
            "loc loss here 1109.9999904036522\n",
            "tensor(2.4394, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.4394, device='cuda:0') sum\n",
            "loc loss here 1110.9999903440475\n",
            "tensor(3.4580, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4580, device='cuda:0') sum\n",
            "loc loss here 1111.999990284443\n",
            "tensor(2.7432, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7432, device='cuda:0') sum\n",
            "loc loss here 1112.9999902248383\n",
            "tensor(3.0278, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0278, device='cuda:0') sum\n",
            "loc loss here 1113.9999902248383\n",
            "tensor(3.4328, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4328, device='cuda:0') sum\n",
            "loc loss here 1114.9999901652336\n",
            "tensor(3.7393, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7393, device='cuda:0') sum\n",
            "loc loss here 1115.999990105629\n",
            "tensor(4.1354, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.1354, device='cuda:0') sum\n",
            "loc loss here 1116.999990105629\n",
            "tensor(3.9614, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9614, device='cuda:0') sum\n",
            "loc loss here 1117.999990105629\n",
            "tensor(3.9033, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9033, device='cuda:0') sum\n",
            "loc loss here 1118.999990105629\n",
            "tensor(3.7843, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7843, device='cuda:0') sum\n",
            "loc loss here 1119.9999900460243\n",
            "tensor(3.0600, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.0600, device='cuda:0') sum\n",
            "loc loss here 1120.9999900460243\n",
            "tensor(3.9970, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9970, device='cuda:0') sum\n",
            "loc loss here 1121.9999899864197\n",
            "tensor(2.6282, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6282, device='cuda:0') sum\n",
            "loc loss here 1122.9999899864197\n",
            "tensor(3.9106, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.9106, device='cuda:0') sum\n",
            "loc loss here 1123.9999899864197\n",
            "tensor(2.6607, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6607, device='cuda:0') sum\n",
            "loc loss here 1124.9999899864197\n",
            "tensor(2.6200, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.6200, device='cuda:0') sum\n",
            "loc loss here 1125.9999899864197\n",
            "tensor(3.2539, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2539, device='cuda:0') sum\n",
            "loc loss here 1126.9999899864197\n",
            "tensor(2.7873, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.7873, device='cuda:0') sum\n",
            "loc loss here 1127.9999899864197\n",
            "tensor(3.2938, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.2938, device='cuda:0') sum\n",
            "loc loss here 1128.9999899864197\n",
            "tensor(3.3686, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3686, device='cuda:0') sum\n",
            "loc loss here 1129.999989926815\n",
            "tensor(1.8380, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.8380, device='cuda:0') sum\n",
            "loc loss here 1130.9999898672104\n",
            "tensor(2.8732, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.8732, device='cuda:0') sum\n",
            "loc loss here 1131.9999898672104\n",
            "tensor(3.7648, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7648, device='cuda:0') sum\n",
            "loc loss here 1132.9999898672104\n",
            "tensor(1.7746, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(1.7746, device='cuda:0') sum\n",
            "loc loss here 1133.9999898672104\n",
            "tensor(4.2861, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(4.2861, device='cuda:0') sum\n",
            "loc loss here 1134.9999898672104\n",
            "tensor(3.4510, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.4510, device='cuda:0') sum\n",
            "loc loss here 1135.9999898672104\n",
            "tensor(2.5717, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.5717, device='cuda:0') sum\n",
            "loc loss here 1136.9999898672104\n",
            "tensor(3.3167, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.3167, device='cuda:0') sum\n",
            "loc loss here 1137.9999898672104\n",
            "tensor(3.5710, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5710, device='cuda:0') sum\n",
            "loc loss here 1138.9999898672104\n",
            "tensor(3.1761, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.1761, device='cuda:0') sum\n",
            "loc loss here 1139.9999898076057\n",
            "tensor(3.5765, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.5765, device='cuda:0') sum\n",
            "loc loss here 1140.9999898076057\n",
            "tensor(2.9100, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(2.9100, device='cuda:0') sum\n",
            "loc loss here 1141.9999898076057\n",
            "tensor(3.7965, device='cuda:0') pre_loss\n",
            "torch.Size([])\n",
            "tensor(3.7965, device='cuda:0') sum\n",
            "loc loss here 1142.999989748001\n",
            "Total \t L: 1.000 \t -- 232.638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RXg9GMtSs2P"
      },
      "source": [
        "We now have everything we need to answer any question! Now let's try the full system on our running example along with the first four questions of the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8sdw-BbC_oV",
        "outputId": "86ede4e1-3fe0-42f9-8bf0-6e7256a6b3cd"
      },
      "source": [
        "import psutil\n",
        "def get_size(bytes, suffix=\"B\"):\n",
        "    factor = 1024\n",
        "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
        "        if bytes < factor:\n",
        "            return f\"{bytes:.2f}{unit}{suffix}\"\n",
        "        bytes /= factor\n",
        "print(\"=\"*40, \"Memory Information\", \"=\"*40)\n",
        "svmem = psutil.virtual_memory()\n",
        "print(f\"Total: {get_size(svmem.total)}\") ; print(f\"Available: {get_size(svmem.available)}\")\n",
        "print(f\"Used: {get_size(svmem.used)}\") ; print(f\"Percentage: {svmem.percent}%\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================== Memory Information ========================================\n",
            "Total: 25.46GB\n",
            "Available: 21.75GB\n",
            "Used: 6.33GB\n",
            "Percentage: 14.6%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inSpTFrw9H6s"
      },
      "source": [
        "    import torch\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1xobu8OStdQ"
      },
      "source": [
        "# generate answer from input \"question: ... context: <p> ...\"\n",
        "def qa_s2s_generate(\n",
        "    question_doc,\n",
        "    qa_s2s_model,\n",
        "    qa_s2s_tokenizer,\n",
        "    num_answers=1,\n",
        "    num_beams=None,\n",
        "    min_len=64,\n",
        "    max_len=512,\n",
        "    do_sample=False,\n",
        "    temp=1.0,\n",
        "    top_p=None,\n",
        "    top_k=None,\n",
        "    max_input_length=1024,\n",
        "    device=\"cuda:0\",\n",
        "):\n",
        "    model_inputs = make_qa_s2s_batch([(question_doc, \"A\")], qa_s2s_tokenizer, max_input_length, device=device,)\n",
        "    n_beams = num_answers if num_beams is None else max(num_beams, num_answers)\n",
        "    generated_ids = qa_s2s_model.generate(\n",
        "        input_ids=model_inputs[\"input_ids\"],\n",
        "        attention_mask=model_inputs[\"attention_mask\"],\n",
        "        min_length=min_len,\n",
        "        max_length=max_len,\n",
        "        do_sample=do_sample,\n",
        "        early_stopping=True,\n",
        "        num_beams=1 if do_sample else n_beams,\n",
        "        temperature=temp,\n",
        "        top_k=top_k,\n",
        "        top_p=top_p,\n",
        "        eos_token_id=qa_s2s_tokenizer.eos_token_id,\n",
        "        no_repeat_ngram_size=3,\n",
        "        num_return_sequences=num_answers,\n",
        "        decoder_start_token_id=qa_s2s_tokenizer.bos_token_id,\n",
        "    )\n",
        "    return [qa_s2s_tokenizer.decode(ans_ids, skip_special_tokens=True).strip() for ans_ids in generated_ids]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49FI64_uS6JZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "76662bb5-53fd-4a31-b46a-32eae2ae60f7"
      },
      "source": [
        "questions = []\n",
        "answers = []\n",
        "\n",
        "for i in [10] + [j for j in range(4)]:\n",
        "    # create support document with the dense index\n",
        "    question = test[i]['x']\n",
        "    doc, res_list = query_qa_dense_index(\n",
        "        question, qar_model, qar_tokenizer,\n",
        "        passage_snippets, wiki40b_gpu_index, device='cuda'\n",
        "    )\n",
        "    # concatenate question and support document into BART input\n",
        "    question_doc = \"question: {} context: {}\".format(question, doc)\n",
        "    # generate an answer with beam search\n",
        "    answer = qa_s2s_generate(\n",
        "            question_doc, qa_s2s_model, qa_s2s_tokenizer,\n",
        "            num_answers=1,\n",
        "            num_beams=8,\n",
        "            min_len=64,\n",
        "            max_len=256,\n",
        "            max_input_length=1024,\n",
        "            device=\"cuda:0\"\n",
        "    )[0]\n",
        "    questions += [question]\n",
        "    answers += [answer]\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Question': questions,\n",
        "    'Answer': answers,\n",
        "})\n",
        "df.style.set_properties(**{'text-align': 'left'})"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_49860368_13a0_11ec_a061_0242ac1c0002row0_col0,#T_49860368_13a0_11ec_a061_0242ac1c0002row0_col1,#T_49860368_13a0_11ec_a061_0242ac1c0002row1_col0,#T_49860368_13a0_11ec_a061_0242ac1c0002row1_col1,#T_49860368_13a0_11ec_a061_0242ac1c0002row2_col0,#T_49860368_13a0_11ec_a061_0242ac1c0002row2_col1,#T_49860368_13a0_11ec_a061_0242ac1c0002row3_col0,#T_49860368_13a0_11ec_a061_0242ac1c0002row3_col1,#T_49860368_13a0_11ec_a061_0242ac1c0002row4_col0,#T_49860368_13a0_11ec_a061_0242ac1c0002row4_col1{\n",
              "            text-align:  left;\n",
              "        }</style><table id=\"T_49860368_13a0_11ec_a061_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Question</th>        <th class=\"col_heading level0 col1\" >Answer</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_49860368_13a0_11ec_a061_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_49860368_13a0_11ec_a061_0242ac1c0002row0_col0\" class=\"data row0 col0\" >`with torch.enable_grad` also works outside a `no_grad` context</td>\n",
              "                        <td id=\"T_49860368_13a0_11ec_a061_0242ac1c0002row0_col1\" class=\"data row0 col1\" >enable_grad` also works outside a no_grad context context:\n",
              "\n",
              "def __init__(self):\n",
              "    super(self, self).__init__()\n",
              "\n",
              "   self.len(len)\n",
              "\n",
              "self.len = nn.Linear(2, 2, 2)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_49860368_13a0_11ec_a061_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_49860368_13a0_11ec_a061_0242ac1c0002row1_col0\" class=\"data row1 col0\" >\"exp_cuda\" not implemented for 'ComplexDouble'</td>\n",
              "                        <td id=\"T_49860368_13a0_11ec_a061_0242ac1c0002row1_col1\" class=\"data row1 col1\" >You can use the following code:\n",
              "import torch.utils as tf\n",
              "def __init__(self):\n",
              "    super(tf, self).__init__()\n",
              "print(self.getattr(self).getattr())\n",
              "\n",
              "def forward(self, x):\n",
              "\n",
              "   self.setattr(x)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_49860368_13a0_11ec_a061_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_49860368_13a0_11ec_a061_0242ac1c0002row2_col0\" class=\"data row2 col0\" >How to correctly use CTC Loss with GRU in pytorch?</td>\n",
              "                        <td id=\"T_49860368_13a0_11ec_a061_0242ac1c0002row2_col1\" class=\"data row2 col1\" >PyTorch is a deep learning deep learning extension library for PyTorch. It supports CTCLoss, which is an extension of the GRU library.\n",
              "\n",
              "You can do something like this:\n",
              "import torch.utils as tf\n",
              "def __init__(self):\n",
              "    super(tf, self).__init__()\n",
              "def forward(self, x):\n",
              " x = torch.randn(3, 3)\n",
              "x_predicted = x.sum(x)\n",
              "print(x.shape[0])\n",
              "\n",
              "If you want to do something more complicated, you can do the following:\n",
              "\n",
              "self.x = x[0] = x(x[0].shape[1]</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_49860368_13a0_11ec_a061_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_49860368_13a0_11ec_a061_0242ac1c0002row3_col0\" class=\"data row3 col0\" >glibc error while importing torch</td>\n",
              "                        <td id=\"T_49860368_13a0_11ec_a061_0242ac1c0002row3_col1\" class=\"data row3 col1\" >You can use the following code:\n",
              "\n",
              "def __init__(self):\n",
              "    super(self, self).__init__()\n",
              "\n",
              "class MyModel(torch.randn(10, 10, 10))\n",
              "  self.train_state = train_state[None, None, None]\n",
              "\n",
              "\n",
              "class TrainingMode(nn.Module):\n",
              "\n",
              "   \"\"\"</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_49860368_13a0_11ec_a061_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_49860368_13a0_11ec_a061_0242ac1c0002row4_col0\" class=\"data row4 col0\" >TypeError: add(): argument &#39;other&#39; (position 1) must be Tensor, not numpy.ndarray</td>\n",
              "                        <td id=\"T_49860368_13a0_11ec_a061_0242ac1c0002row4_col1\" class=\"data row4 col1\" >If you want to use a GPU for deep learning there is no difference between CUDA and CUDA...\n",
              "\n",
              "You can use PyTorch's nn.Conv2d library.\n",
              "\n",
              "If you are using pytorch, you can use the following code:\n",
              "\n",
              "import torch\n",
              "from torch.utils import nn\n",
              "\n",
              "def __init__(self):\n",
              "    super().__init__()\n",
              "print(self).__getitem__()\n",
              "\n",
              "\n",
              "This will return a tuple of tensor([[1, 2, 3], [4, 5, 6], [7, 8], [9, 9], [10, 11], [12, 13], [13, 14], [14, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28, 28], [29, 28]], [32, 32], [33, 33], [34, 34, 34], [35, 35, 35], [36, 36,</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fe24ec314d0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}